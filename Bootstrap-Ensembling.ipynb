{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data summary:\n",
      "              ssn         year       month     year_tsi   month_tsi  \\\n",
      "count  924.000000   924.000000  924.000000   924.000000  924.000000   \n",
      "mean    93.807468  1985.583333    6.500000  1985.583333    6.500000   \n",
      "std     71.508209    22.243618    3.453922    22.243618    3.453922   \n",
      "min      1.800000  1947.000000    1.000000  1947.000000    1.000000   \n",
      "25%     28.325000  1966.000000    3.750000  1966.000000    3.750000   \n",
      "50%     84.050000  1986.000000    6.500000  1986.000000    6.500000   \n",
      "75%    149.950000  2005.000000    9.250000  2005.000000    9.250000   \n",
      "max    285.000000  2024.000000   12.000000  2024.000000   12.000000   \n",
      "\n",
      "               tsi  \n",
      "count   924.000000  \n",
      "mean   1363.423637  \n",
      "std       0.354047  \n",
      "min    1362.889401  \n",
      "25%    1363.075220  \n",
      "50%    1363.427315  \n",
      "75%    1363.741120  \n",
      "max    1364.138153  \n",
      "Correlation between SSN and TSI: 0.9065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-20 16:25:43.560897: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M3 Pro\n",
      "2025-03-20 16:25:43.560926: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 18.00 GB\n",
      "2025-03-20 16:25:43.560932: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 6.00 GB\n",
      "2025-03-20 16:25:43.560947: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2025-03-20 16:25:43.560958: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "/opt/anaconda3/envs/ssn/lib/python3.11/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-20 16:25:44.077157: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0630\n",
      "Epoch 1: val_loss improved from inf to 0.01684, saving model to model_checkpoints/model_0.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 44ms/step - loss: 0.0620 - val_loss: 0.0168\n",
      "Epoch 2/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0158\n",
      "Epoch 2: val_loss improved from 0.01684 to 0.00791, saving model to model_checkpoints/model_0.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0157 - val_loss: 0.0079\n",
      "Epoch 3/100\n",
      "\u001b[1m17/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0116\n",
      "Epoch 3: val_loss improved from 0.00791 to 0.00417, saving model to model_checkpoints/model_0.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0114 - val_loss: 0.0042\n",
      "Epoch 4/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0082\n",
      "Epoch 4: val_loss improved from 0.00417 to 0.00362, saving model to model_checkpoints/model_0.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0082 - val_loss: 0.0036\n",
      "Epoch 5/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0072\n",
      "Epoch 5: val_loss improved from 0.00362 to 0.00320, saving model to model_checkpoints/model_0.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0072 - val_loss: 0.0032\n",
      "Epoch 6/100\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0074\n",
      "Epoch 6: val_loss improved from 0.00320 to 0.00268, saving model to model_checkpoints/model_0.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0075 - val_loss: 0.0027\n",
      "Epoch 7/100\n",
      "\u001b[1m18/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0069\n",
      "Epoch 7: val_loss did not improve from 0.00268\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0069 - val_loss: 0.0029\n",
      "Epoch 8/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0076\n",
      "Epoch 8: val_loss did not improve from 0.00268\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0076 - val_loss: 0.0031\n",
      "Epoch 9/100\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0063\n",
      "Epoch 9: val_loss improved from 0.00268 to 0.00233, saving model to model_checkpoints/model_0.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0063 - val_loss: 0.0023\n",
      "Epoch 10/100\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0070\n",
      "Epoch 10: val_loss improved from 0.00233 to 0.00233, saving model to model_checkpoints/model_0.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0069 - val_loss: 0.0023\n",
      "Epoch 11/100\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0057\n",
      "Epoch 11: val_loss did not improve from 0.00233\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0057 - val_loss: 0.0028\n",
      "Epoch 12/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0059\n",
      "Epoch 12: val_loss improved from 0.00233 to 0.00231, saving model to model_checkpoints/model_0.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0059 - val_loss: 0.0023\n",
      "Epoch 13/100\n",
      "\u001b[1m17/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0047\n",
      "Epoch 13: val_loss improved from 0.00231 to 0.00180, saving model to model_checkpoints/model_0.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0047 - val_loss: 0.0018\n",
      "Epoch 14/100\n",
      "\u001b[1m18/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0058\n",
      "Epoch 14: val_loss did not improve from 0.00180\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0058 - val_loss: 0.0021\n",
      "Epoch 15/100\n",
      "\u001b[1m18/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0052\n",
      "Epoch 15: val_loss improved from 0.00180 to 0.00174, saving model to model_checkpoints/model_0.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0052 - val_loss: 0.0017\n",
      "Epoch 16/100\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0046\n",
      "Epoch 16: val_loss improved from 0.00174 to 0.00166, saving model to model_checkpoints/model_0.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0046 - val_loss: 0.0017\n",
      "Epoch 17/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0050\n",
      "Epoch 17: val_loss improved from 0.00166 to 0.00164, saving model to model_checkpoints/model_0.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0050 - val_loss: 0.0016\n",
      "Epoch 18/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0051\n",
      "Epoch 18: val_loss improved from 0.00164 to 0.00162, saving model to model_checkpoints/model_0.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0051 - val_loss: 0.0016\n",
      "Epoch 19/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0049\n",
      "Epoch 19: val_loss improved from 0.00162 to 0.00144, saving model to model_checkpoints/model_0.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0049 - val_loss: 0.0014\n",
      "Epoch 20/100\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0039\n",
      "Epoch 20: val_loss improved from 0.00144 to 0.00137, saving model to model_checkpoints/model_0.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0039 - val_loss: 0.0014\n",
      "Epoch 21/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0040\n",
      "Epoch 21: val_loss improved from 0.00137 to 0.00134, saving model to model_checkpoints/model_0.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0040 - val_loss: 0.0013\n",
      "Epoch 22/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0043\n",
      "Epoch 22: val_loss improved from 0.00134 to 0.00125, saving model to model_checkpoints/model_0.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0043 - val_loss: 0.0012\n",
      "Epoch 23/100\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0035\n",
      "Epoch 23: val_loss did not improve from 0.00125\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0035 - val_loss: 0.0014\n",
      "Epoch 24/100\n",
      "\u001b[1m18/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0041\n",
      "Epoch 24: val_loss improved from 0.00125 to 0.00122, saving model to model_checkpoints/model_0.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0040 - val_loss: 0.0012\n",
      "Epoch 25/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0035\n",
      "Epoch 25: val_loss did not improve from 0.00122\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0035 - val_loss: 0.0012\n",
      "Epoch 26/100\n",
      "\u001b[1m18/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0036\n",
      "Epoch 26: val_loss did not improve from 0.00122\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0036 - val_loss: 0.0015\n",
      "Epoch 27/100\n",
      "\u001b[1m18/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0036\n",
      "Epoch 27: val_loss did not improve from 0.00122\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0036 - val_loss: 0.0014\n",
      "Epoch 28/100\n",
      "\u001b[1m17/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0040\n",
      "Epoch 28: val_loss did not improve from 0.00122\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0040 - val_loss: 0.0013\n",
      "Epoch 29/100\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0033\n",
      "Epoch 29: val_loss improved from 0.00122 to 0.00108, saving model to model_checkpoints/model_0.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0033 - val_loss: 0.0011\n",
      "Epoch 30/100\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0036\n",
      "Epoch 30: val_loss did not improve from 0.00108\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0036 - val_loss: 0.0012\n",
      "Epoch 31/100\n",
      "\u001b[1m18/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0029\n",
      "Epoch 31: val_loss improved from 0.00108 to 0.00098, saving model to model_checkpoints/model_0.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0029 - val_loss: 9.7693e-04\n",
      "Epoch 32/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0035\n",
      "Epoch 32: val_loss did not improve from 0.00098\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0035 - val_loss: 0.0012\n",
      "Epoch 33/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0031\n",
      "Epoch 33: val_loss did not improve from 0.00098\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0031 - val_loss: 0.0010\n",
      "Epoch 34/100\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0031\n",
      "Epoch 34: val_loss improved from 0.00098 to 0.00097, saving model to model_checkpoints/model_0.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0031 - val_loss: 9.7256e-04\n",
      "Epoch 35/100\n",
      "\u001b[1m17/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0034\n",
      "Epoch 35: val_loss did not improve from 0.00097\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0034 - val_loss: 0.0011\n",
      "Epoch 36/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0033\n",
      "Epoch 36: val_loss improved from 0.00097 to 0.00094, saving model to model_checkpoints/model_0.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0032 - val_loss: 9.4351e-04\n",
      "Epoch 37/100\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0030\n",
      "Epoch 37: val_loss did not improve from 0.00094\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0030 - val_loss: 0.0013\n",
      "Epoch 38/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0031\n",
      "Epoch 38: val_loss did not improve from 0.00094\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0031 - val_loss: 9.5639e-04\n",
      "Epoch 39/100\n",
      "\u001b[1m17/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0033\n",
      "Epoch 39: val_loss improved from 0.00094 to 0.00085, saving model to model_checkpoints/model_0.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0032 - val_loss: 8.5082e-04\n",
      "Epoch 40/100\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0035\n",
      "Epoch 40: val_loss did not improve from 0.00085\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0035 - val_loss: 8.9498e-04\n",
      "Epoch 41/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0031\n",
      "Epoch 41: val_loss did not improve from 0.00085\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0031 - val_loss: 9.5898e-04\n",
      "Epoch 42/100\n",
      "\u001b[1m17/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0026\n",
      "Epoch 42: val_loss improved from 0.00085 to 0.00083, saving model to model_checkpoints/model_0.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0026 - val_loss: 8.2685e-04\n",
      "Epoch 43/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0029\n",
      "Epoch 43: val_loss improved from 0.00083 to 0.00080, saving model to model_checkpoints/model_0.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0029 - val_loss: 7.9843e-04\n",
      "Epoch 44/100\n",
      "\u001b[1m17/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0031\n",
      "Epoch 44: val_loss did not improve from 0.00080\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0030 - val_loss: 8.6367e-04\n",
      "Epoch 45/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0027\n",
      "Epoch 45: val_loss did not improve from 0.00080\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0027 - val_loss: 8.2728e-04\n",
      "Epoch 46/100\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0029\n",
      "Epoch 46: val_loss did not improve from 0.00080\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0030 - val_loss: 0.0010\n",
      "Epoch 47/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0025\n",
      "Epoch 47: val_loss improved from 0.00080 to 0.00075, saving model to model_checkpoints/model_0.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0025 - val_loss: 7.5049e-04\n",
      "Epoch 48/100\n",
      "\u001b[1m17/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0029\n",
      "Epoch 48: val_loss did not improve from 0.00075\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0029 - val_loss: 8.5369e-04\n",
      "Epoch 49/100\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0025\n",
      "Epoch 49: val_loss did not improve from 0.00075\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0025 - val_loss: 7.5947e-04\n",
      "Epoch 50/100\n",
      "\u001b[1m17/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0024\n",
      "Epoch 50: val_loss improved from 0.00075 to 0.00072, saving model to model_checkpoints/model_0.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0024 - val_loss: 7.2350e-04\n",
      "Epoch 51/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0024\n",
      "Epoch 51: val_loss did not improve from 0.00072\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0024 - val_loss: 0.0012\n",
      "Epoch 52/100\n",
      "\u001b[1m17/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0026\n",
      "Epoch 52: val_loss improved from 0.00072 to 0.00069, saving model to model_checkpoints/model_0.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0026 - val_loss: 6.9295e-04\n",
      "Epoch 53/100\n",
      "\u001b[1m18/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0033\n",
      "Epoch 53: val_loss did not improve from 0.00069\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0032 - val_loss: 8.2314e-04\n",
      "Epoch 54/100\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0026\n",
      "Epoch 54: val_loss did not improve from 0.00069\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0026 - val_loss: 0.0010\n",
      "Epoch 55/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0024\n",
      "Epoch 55: val_loss improved from 0.00069 to 0.00067, saving model to model_checkpoints/model_0.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0024 - val_loss: 6.7001e-04\n",
      "Epoch 56/100\n",
      "\u001b[1m18/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0026\n",
      "Epoch 56: val_loss did not improve from 0.00067\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0026 - val_loss: 8.7665e-04\n",
      "Epoch 57/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0022\n",
      "Epoch 57: val_loss did not improve from 0.00067\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0022 - val_loss: 0.0010\n",
      "Epoch 58/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0030\n",
      "Epoch 58: val_loss did not improve from 0.00067\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0030 - val_loss: 0.0014\n",
      "Epoch 59/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0026\n",
      "Epoch 59: val_loss did not improve from 0.00067\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0026 - val_loss: 8.0687e-04\n",
      "Epoch 60/100\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0021\n",
      "Epoch 60: val_loss improved from 0.00067 to 0.00064, saving model to model_checkpoints/model_0.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0021 - val_loss: 6.4457e-04\n",
      "Epoch 61/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0022\n",
      "Epoch 61: val_loss improved from 0.00064 to 0.00064, saving model to model_checkpoints/model_0.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0022 - val_loss: 6.3612e-04\n",
      "Epoch 62/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0020\n",
      "Epoch 62: val_loss improved from 0.00064 to 0.00063, saving model to model_checkpoints/model_0.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0020 - val_loss: 6.2617e-04\n",
      "Epoch 63/100\n",
      "\u001b[1m18/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0025\n",
      "Epoch 63: val_loss improved from 0.00063 to 0.00061, saving model to model_checkpoints/model_0.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0025 - val_loss: 6.1126e-04\n",
      "Epoch 64/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0022\n",
      "Epoch 64: val_loss did not improve from 0.00061\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0022 - val_loss: 6.2322e-04\n",
      "Epoch 65/100\n",
      "\u001b[1m17/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0021\n",
      "Epoch 65: val_loss did not improve from 0.00061\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0021 - val_loss: 6.1507e-04\n",
      "Epoch 66/100\n",
      "\u001b[1m18/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0019\n",
      "Epoch 66: val_loss improved from 0.00061 to 0.00056, saving model to model_checkpoints/model_0.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0020 - val_loss: 5.6221e-04\n",
      "Epoch 67/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0020\n",
      "Epoch 67: val_loss did not improve from 0.00056\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0020 - val_loss: 6.6067e-04\n",
      "Epoch 68/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0021\n",
      "Epoch 68: val_loss did not improve from 0.00056\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0021 - val_loss: 8.2803e-04\n",
      "Epoch 69/100\n",
      "\u001b[1m17/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0020\n",
      "Epoch 69: val_loss did not improve from 0.00056\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0020 - val_loss: 5.7884e-04\n",
      "Epoch 70/100\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0019\n",
      "Epoch 70: val_loss did not improve from 0.00056\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0019 - val_loss: 5.9271e-04\n",
      "Epoch 71/100\n",
      "\u001b[1m17/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0020\n",
      "Epoch 71: val_loss did not improve from 0.00056\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0020 - val_loss: 6.5235e-04\n",
      "Epoch 72/100\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0020\n",
      "Epoch 72: val_loss did not improve from 0.00056\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0020 - val_loss: 5.7018e-04\n",
      "Epoch 73/100\n",
      "\u001b[1m17/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0020\n",
      "Epoch 73: val_loss improved from 0.00056 to 0.00054, saving model to model_checkpoints/model_0.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0020 - val_loss: 5.4067e-04\n",
      "Epoch 74/100\n",
      "\u001b[1m18/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0017\n",
      "Epoch 74: val_loss improved from 0.00054 to 0.00053, saving model to model_checkpoints/model_0.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0017 - val_loss: 5.2790e-04\n",
      "Epoch 75/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0020\n",
      "Epoch 75: val_loss did not improve from 0.00053\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0020 - val_loss: 6.1820e-04\n",
      "Epoch 76/100\n",
      "\u001b[1m18/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0018\n",
      "Epoch 76: val_loss did not improve from 0.00053\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0018 - val_loss: 5.5040e-04\n",
      "Epoch 77/100\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0016\n",
      "Epoch 77: val_loss did not improve from 0.00053\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0016 - val_loss: 5.3669e-04\n",
      "Epoch 78/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0017\n",
      "Epoch 78: val_loss did not improve from 0.00053\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0017 - val_loss: 6.8098e-04\n",
      "Epoch 79/100\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0018\n",
      "Epoch 79: val_loss improved from 0.00053 to 0.00049, saving model to model_checkpoints/model_0.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0018 - val_loss: 4.8661e-04\n",
      "Epoch 80/100\n",
      "\u001b[1m18/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0017\n",
      "Epoch 80: val_loss did not improve from 0.00049\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0017 - val_loss: 7.7256e-04\n",
      "Epoch 81/100\n",
      "\u001b[1m18/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0021\n",
      "Epoch 81: val_loss did not improve from 0.00049\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0021 - val_loss: 5.0401e-04\n",
      "Epoch 82/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0017\n",
      "Epoch 82: val_loss did not improve from 0.00049\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0017 - val_loss: 9.9077e-04\n",
      "Epoch 83/100\n",
      "\u001b[1m18/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0019\n",
      "Epoch 83: val_loss did not improve from 0.00049\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0019 - val_loss: 5.0753e-04\n",
      "Epoch 84/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0016\n",
      "Epoch 84: val_loss did not improve from 0.00049\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0016 - val_loss: 7.1470e-04\n",
      "Epoch 85/100\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0020\n",
      "Epoch 85: val_loss did not improve from 0.00049\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0020 - val_loss: 5.2130e-04\n",
      "Epoch 86/100\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0018\n",
      "Epoch 86: val_loss did not improve from 0.00049\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0018 - val_loss: 5.2670e-04\n",
      "Epoch 87/100\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0017\n",
      "Epoch 87: val_loss did not improve from 0.00049\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0018 - val_loss: 5.1706e-04\n",
      "Epoch 88/100\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0018\n",
      "Epoch 88: val_loss did not improve from 0.00049\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0018 - val_loss: 4.9035e-04\n",
      "Epoch 89/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0019\n",
      "Epoch 89: val_loss did not improve from 0.00049\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0019 - val_loss: 5.4935e-04\n",
      "Epoch 89: early stopping\n",
      "Restoring model weights from the end of the best epoch: 79.\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 150ms/step\n",
      "Epoch 1/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.1162\n",
      "Epoch 1: val_loss improved from inf to 0.02045, saving model to model_checkpoints/model_1.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - loss: 0.1137 - val_loss: 0.0204\n",
      "Epoch 2/100\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0195\n",
      "Epoch 2: val_loss improved from 0.02045 to 0.01028, saving model to model_checkpoints/model_1.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0193 - val_loss: 0.0103\n",
      "Epoch 3/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0121\n",
      "Epoch 3: val_loss improved from 0.01028 to 0.00600, saving model to model_checkpoints/model_1.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0120 - val_loss: 0.0060\n",
      "Epoch 4/100\n",
      "\u001b[1m18/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0098\n",
      "Epoch 4: val_loss improved from 0.00600 to 0.00474, saving model to model_checkpoints/model_1.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0098 - val_loss: 0.0047\n",
      "Epoch 5/100\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0088\n",
      "Epoch 5: val_loss improved from 0.00474 to 0.00413, saving model to model_checkpoints/model_1.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0087 - val_loss: 0.0041\n",
      "Epoch 6/100\n",
      "\u001b[1m17/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0091\n",
      "Epoch 6: val_loss improved from 0.00413 to 0.00360, saving model to model_checkpoints/model_1.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0089 - val_loss: 0.0036\n",
      "Epoch 7/100\n",
      "\u001b[1m17/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0065\n",
      "Epoch 7: val_loss improved from 0.00360 to 0.00345, saving model to model_checkpoints/model_1.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0065 - val_loss: 0.0034\n",
      "Epoch 8/100\n",
      "\u001b[1m18/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0066\n",
      "Epoch 8: val_loss improved from 0.00345 to 0.00286, saving model to model_checkpoints/model_1.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0065 - val_loss: 0.0029\n",
      "Epoch 9/100\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0060\n",
      "Epoch 9: val_loss improved from 0.00286 to 0.00271, saving model to model_checkpoints/model_1.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0060 - val_loss: 0.0027\n",
      "Epoch 10/100\n",
      "\u001b[1m18/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0058\n",
      "Epoch 10: val_loss improved from 0.00271 to 0.00267, saving model to model_checkpoints/model_1.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0058 - val_loss: 0.0027\n",
      "Epoch 11/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0057\n",
      "Epoch 11: val_loss improved from 0.00267 to 0.00242, saving model to model_checkpoints/model_1.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0057 - val_loss: 0.0024\n",
      "Epoch 12/100\n",
      "\u001b[1m17/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0062\n",
      "Epoch 12: val_loss improved from 0.00242 to 0.00222, saving model to model_checkpoints/model_1.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0061 - val_loss: 0.0022\n",
      "Epoch 13/100\n",
      "\u001b[1m18/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0057\n",
      "Epoch 13: val_loss improved from 0.00222 to 0.00205, saving model to model_checkpoints/model_1.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0057 - val_loss: 0.0020\n",
      "Epoch 14/100\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0052\n",
      "Epoch 14: val_loss improved from 0.00205 to 0.00193, saving model to model_checkpoints/model_1.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0052 - val_loss: 0.0019\n",
      "Epoch 15/100\n",
      "\u001b[1m18/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0054\n",
      "Epoch 15: val_loss did not improve from 0.00193\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0054 - val_loss: 0.0020\n",
      "Epoch 16/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0047\n",
      "Epoch 16: val_loss improved from 0.00193 to 0.00186, saving model to model_checkpoints/model_1.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0047 - val_loss: 0.0019\n",
      "Epoch 17/100\n",
      "\u001b[1m17/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0050\n",
      "Epoch 17: val_loss improved from 0.00186 to 0.00165, saving model to model_checkpoints/model_1.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0050 - val_loss: 0.0016\n",
      "Epoch 18/100\n",
      "\u001b[1m18/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0046\n",
      "Epoch 18: val_loss improved from 0.00165 to 0.00164, saving model to model_checkpoints/model_1.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0045 - val_loss: 0.0016\n",
      "Epoch 19/100\n",
      "\u001b[1m17/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0046\n",
      "Epoch 19: val_loss improved from 0.00164 to 0.00163, saving model to model_checkpoints/model_1.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0046 - val_loss: 0.0016\n",
      "Epoch 20/100\n",
      "\u001b[1m18/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0042\n",
      "Epoch 20: val_loss improved from 0.00163 to 0.00139, saving model to model_checkpoints/model_1.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0042 - val_loss: 0.0014\n",
      "Epoch 21/100\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0041\n",
      "Epoch 21: val_loss did not improve from 0.00139\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0041 - val_loss: 0.0016\n",
      "Epoch 22/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0044\n",
      "Epoch 22: val_loss did not improve from 0.00139\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0043 - val_loss: 0.0016\n",
      "Epoch 23/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0039\n",
      "Epoch 23: val_loss improved from 0.00139 to 0.00131, saving model to model_checkpoints/model_1.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0039 - val_loss: 0.0013\n",
      "Epoch 24/100\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0045\n",
      "Epoch 24: val_loss did not improve from 0.00131\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0045 - val_loss: 0.0014\n",
      "Epoch 25/100\n",
      "\u001b[1m18/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0042\n",
      "Epoch 25: val_loss did not improve from 0.00131\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0042 - val_loss: 0.0021\n",
      "Epoch 26/100\n",
      "\u001b[1m18/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0044\n",
      "Epoch 26: val_loss improved from 0.00131 to 0.00117, saving model to model_checkpoints/model_1.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0044 - val_loss: 0.0012\n",
      "Epoch 27/100\n",
      "\u001b[1m18/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0034\n",
      "Epoch 27: val_loss did not improve from 0.00117\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0034 - val_loss: 0.0028\n",
      "Epoch 28/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0046\n",
      "Epoch 28: val_loss improved from 0.00117 to 0.00112, saving model to model_checkpoints/model_1.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0046 - val_loss: 0.0011\n",
      "Epoch 29/100\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0037\n",
      "Epoch 29: val_loss improved from 0.00112 to 0.00106, saving model to model_checkpoints/model_1.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0037 - val_loss: 0.0011\n",
      "Epoch 30/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0038\n",
      "Epoch 30: val_loss did not improve from 0.00106\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0038 - val_loss: 0.0012\n",
      "Epoch 31/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0036\n",
      "Epoch 31: val_loss did not improve from 0.00106\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0036 - val_loss: 0.0013\n",
      "Epoch 32/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0033\n",
      "Epoch 32: val_loss did not improve from 0.00106\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0033 - val_loss: 0.0011\n",
      "Epoch 33/100\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0033\n",
      "Epoch 33: val_loss improved from 0.00106 to 0.00099, saving model to model_checkpoints/model_1.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0033 - val_loss: 9.9229e-04\n",
      "Epoch 34/100\n",
      "\u001b[1m18/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0032\n",
      "Epoch 34: val_loss did not improve from 0.00099\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0032 - val_loss: 0.0011\n",
      "Epoch 35/100\n",
      "\u001b[1m18/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0032\n",
      "Epoch 35: val_loss did not improve from 0.00099\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0032 - val_loss: 0.0012\n",
      "Epoch 36/100\n",
      "\u001b[1m18/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0031\n",
      "Epoch 36: val_loss did not improve from 0.00099\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0031 - val_loss: 0.0011\n",
      "Epoch 37/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0036\n",
      "Epoch 37: val_loss did not improve from 0.00099\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0036 - val_loss: 0.0013\n",
      "Epoch 38/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0043\n",
      "Epoch 38: val_loss did not improve from 0.00099\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0042 - val_loss: 9.9599e-04\n",
      "Epoch 39/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0033\n",
      "Epoch 39: val_loss did not improve from 0.00099\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0033 - val_loss: 0.0012\n",
      "Epoch 40/100\n",
      "\u001b[1m18/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0034\n",
      "Epoch 40: val_loss did not improve from 0.00099\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0034 - val_loss: 9.9283e-04\n",
      "Epoch 41/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0034\n",
      "Epoch 41: val_loss improved from 0.00099 to 0.00092, saving model to model_checkpoints/model_1.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.0034 - val_loss: 9.1775e-04\n",
      "Epoch 42/100\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0028\n",
      "Epoch 42: val_loss improved from 0.00092 to 0.00084, saving model to model_checkpoints/model_1.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0027 - val_loss: 8.3774e-04\n",
      "Epoch 43/100\n",
      "\u001b[1m18/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0028\n",
      "Epoch 43: val_loss improved from 0.00084 to 0.00082, saving model to model_checkpoints/model_1.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0028 - val_loss: 8.2250e-04\n",
      "Epoch 44/100\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0028\n",
      "Epoch 44: val_loss did not improve from 0.00082\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0028 - val_loss: 8.4140e-04\n",
      "Epoch 45/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0023\n",
      "Epoch 45: val_loss did not improve from 0.00082\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0023 - val_loss: 8.8736e-04\n",
      "Epoch 46/100\n",
      "\u001b[1m18/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0029\n",
      "Epoch 46: val_loss did not improve from 0.00082\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0029 - val_loss: 8.5320e-04\n",
      "Epoch 47/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0026\n",
      "Epoch 47: val_loss improved from 0.00082 to 0.00078, saving model to model_checkpoints/model_1.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0026 - val_loss: 7.8450e-04\n",
      "Epoch 48/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0026\n",
      "Epoch 48: val_loss did not improve from 0.00078\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0026 - val_loss: 9.5073e-04\n",
      "Epoch 49/100\n",
      "\u001b[1m18/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0026\n",
      "Epoch 49: val_loss did not improve from 0.00078\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0026 - val_loss: 9.6117e-04\n",
      "Epoch 50/100\n",
      "\u001b[1m18/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0026\n",
      "Epoch 50: val_loss did not improve from 0.00078\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0026 - val_loss: 8.6698e-04\n",
      "Epoch 51/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0027\n",
      "Epoch 51: val_loss did not improve from 0.00078\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0027 - val_loss: 9.7965e-04\n",
      "Epoch 52/100\n",
      "\u001b[1m17/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0029\n",
      "Epoch 52: val_loss did not improve from 0.00078\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0029 - val_loss: 0.0012\n",
      "Epoch 53/100\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0027\n",
      "Epoch 53: val_loss did not improve from 0.00078\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0027 - val_loss: 9.5393e-04\n",
      "Epoch 54/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0030\n",
      "Epoch 54: val_loss did not improve from 0.00078\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0029 - val_loss: 0.0012\n",
      "Epoch 55/100\n",
      "\u001b[1m18/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0026\n",
      "Epoch 55: val_loss did not improve from 0.00078\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0026 - val_loss: 8.7802e-04\n",
      "Epoch 56/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0028\n",
      "Epoch 56: val_loss improved from 0.00078 to 0.00070, saving model to model_checkpoints/model_1.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0028 - val_loss: 7.0110e-04\n",
      "Epoch 57/100\n",
      "\u001b[1m17/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0024\n",
      "Epoch 57: val_loss improved from 0.00070 to 0.00066, saving model to model_checkpoints/model_1.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0024 - val_loss: 6.5911e-04\n",
      "Epoch 58/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0025\n",
      "Epoch 58: val_loss did not improve from 0.00066\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0025 - val_loss: 7.7380e-04\n",
      "Epoch 59/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0025\n",
      "Epoch 59: val_loss did not improve from 0.00066\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0025 - val_loss: 7.8748e-04\n",
      "Epoch 60/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0023\n",
      "Epoch 60: val_loss did not improve from 0.00066\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0023 - val_loss: 7.3253e-04\n",
      "Epoch 61/100\n",
      "\u001b[1m18/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0027\n",
      "Epoch 61: val_loss did not improve from 0.00066\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0027 - val_loss: 6.9875e-04\n",
      "Epoch 62/100\n",
      "\u001b[1m18/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0023\n",
      "Epoch 62: val_loss did not improve from 0.00066\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0022 - val_loss: 7.7806e-04\n",
      "Epoch 63/100\n",
      "\u001b[1m18/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0021\n",
      "Epoch 63: val_loss did not improve from 0.00066\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0021 - val_loss: 6.8358e-04\n",
      "Epoch 64/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0027\n",
      "Epoch 64: val_loss did not improve from 0.00066\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0027 - val_loss: 7.7374e-04\n",
      "Epoch 65/100\n",
      "\u001b[1m17/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0024\n",
      "Epoch 65: val_loss did not improve from 0.00066\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0024 - val_loss: 0.0013\n",
      "Epoch 66/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0024\n",
      "Epoch 66: val_loss did not improve from 0.00066\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0024 - val_loss: 6.8664e-04\n",
      "Epoch 67/100\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0022\n",
      "Epoch 67: val_loss did not improve from 0.00066\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0022 - val_loss: 7.5272e-04\n",
      "Epoch 67: early stopping\n",
      "Restoring model weights from the end of the best epoch: 57.\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step\n",
      "Epoch 1/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.1294\n",
      "Epoch 1: val_loss improved from inf to 0.02156, saving model to model_checkpoints/model_2.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - loss: 0.1270 - val_loss: 0.0216\n",
      "Epoch 2/100\n",
      "\u001b[1m18/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0277\n",
      "Epoch 2: val_loss improved from 0.02156 to 0.00909, saving model to model_checkpoints/model_2.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0269 - val_loss: 0.0091\n",
      "Epoch 3/100\n",
      "\u001b[1m17/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0153\n",
      "Epoch 3: val_loss improved from 0.00909 to 0.00376, saving model to model_checkpoints/model_2.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0148 - val_loss: 0.0038\n",
      "Epoch 4/100\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0084\n",
      "Epoch 4: val_loss improved from 0.00376 to 0.00360, saving model to model_checkpoints/model_2.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0085 - val_loss: 0.0036\n",
      "Epoch 5/100\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0097\n",
      "Epoch 5: val_loss improved from 0.00360 to 0.00351, saving model to model_checkpoints/model_2.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0096 - val_loss: 0.0035\n",
      "Epoch 6/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0075\n",
      "Epoch 6: val_loss improved from 0.00351 to 0.00306, saving model to model_checkpoints/model_2.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0075 - val_loss: 0.0031\n",
      "Epoch 7/100\n",
      "\u001b[1m17/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0086\n",
      "Epoch 7: val_loss improved from 0.00306 to 0.00269, saving model to model_checkpoints/model_2.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0084 - val_loss: 0.0027\n",
      "Epoch 8/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0073\n",
      "Epoch 8: val_loss did not improve from 0.00269\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0073 - val_loss: 0.0028\n",
      "Epoch 9/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0077\n",
      "Epoch 9: val_loss improved from 0.00269 to 0.00255, saving model to model_checkpoints/model_2.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0077 - val_loss: 0.0026\n",
      "Epoch 10/100\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0065\n",
      "Epoch 10: val_loss improved from 0.00255 to 0.00235, saving model to model_checkpoints/model_2.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0065 - val_loss: 0.0024\n",
      "Epoch 11/100\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0064\n",
      "Epoch 11: val_loss improved from 0.00235 to 0.00224, saving model to model_checkpoints/model_2.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0064 - val_loss: 0.0022\n",
      "Epoch 12/100\n",
      "\u001b[1m17/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0056\n",
      "Epoch 12: val_loss did not improve from 0.00224\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0056 - val_loss: 0.0024\n",
      "Epoch 13/100\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0065\n",
      "Epoch 13: val_loss improved from 0.00224 to 0.00216, saving model to model_checkpoints/model_2.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0064 - val_loss: 0.0022\n",
      "Epoch 14/100\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0053\n",
      "Epoch 14: val_loss improved from 0.00216 to 0.00191, saving model to model_checkpoints/model_2.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0053 - val_loss: 0.0019\n",
      "Epoch 15/100\n",
      "\u001b[1m17/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0058\n",
      "Epoch 15: val_loss improved from 0.00191 to 0.00191, saving model to model_checkpoints/model_2.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0058 - val_loss: 0.0019\n",
      "Epoch 16/100\n",
      "\u001b[1m18/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0065\n",
      "Epoch 16: val_loss did not improve from 0.00191\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0064 - val_loss: 0.0033\n",
      "Epoch 17/100\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0069\n",
      "Epoch 17: val_loss did not improve from 0.00191\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0068 - val_loss: 0.0020\n",
      "Epoch 18/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0054\n",
      "Epoch 18: val_loss improved from 0.00191 to 0.00153, saving model to model_checkpoints/model_2.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0054 - val_loss: 0.0015\n",
      "Epoch 19/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0056\n",
      "Epoch 19: val_loss improved from 0.00153 to 0.00144, saving model to model_checkpoints/model_2.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0056 - val_loss: 0.0014\n",
      "Epoch 20/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0044\n",
      "Epoch 20: val_loss did not improve from 0.00144\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0044 - val_loss: 0.0016\n",
      "Epoch 21/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0047\n",
      "Epoch 21: val_loss improved from 0.00144 to 0.00144, saving model to model_checkpoints/model_2.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0048 - val_loss: 0.0014\n",
      "Epoch 22/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0051\n",
      "Epoch 22: val_loss improved from 0.00144 to 0.00143, saving model to model_checkpoints/model_2.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0051 - val_loss: 0.0014\n",
      "Epoch 23/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0045\n",
      "Epoch 23: val_loss did not improve from 0.00143\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0045 - val_loss: 0.0014\n",
      "Epoch 24/100\n",
      "\u001b[1m18/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0046\n",
      "Epoch 24: val_loss improved from 0.00143 to 0.00138, saving model to model_checkpoints/model_2.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0046 - val_loss: 0.0014\n",
      "Epoch 25/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0043\n",
      "Epoch 25: val_loss improved from 0.00138 to 0.00121, saving model to model_checkpoints/model_2.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0043 - val_loss: 0.0012\n",
      "Epoch 26/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0044\n",
      "Epoch 26: val_loss improved from 0.00121 to 0.00114, saving model to model_checkpoints/model_2.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0044 - val_loss: 0.0011\n",
      "Epoch 27/100\n",
      "\u001b[1m17/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0044\n",
      "Epoch 27: val_loss did not improve from 0.00114\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0044 - val_loss: 0.0012\n",
      "Epoch 28/100\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0040\n",
      "Epoch 28: val_loss improved from 0.00114 to 0.00110, saving model to model_checkpoints/model_2.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0040 - val_loss: 0.0011\n",
      "Epoch 29/100\n",
      "\u001b[1m17/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0048\n",
      "Epoch 29: val_loss improved from 0.00110 to 0.00109, saving model to model_checkpoints/model_2.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0047 - val_loss: 0.0011\n",
      "Epoch 30/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0046\n",
      "Epoch 30: val_loss did not improve from 0.00109\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0046 - val_loss: 0.0012\n",
      "Epoch 31/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0042\n",
      "Epoch 31: val_loss improved from 0.00109 to 0.00095, saving model to model_checkpoints/model_2.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0042 - val_loss: 9.4616e-04\n",
      "Epoch 32/100\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0041\n",
      "Epoch 32: val_loss did not improve from 0.00095\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0041 - val_loss: 0.0010\n",
      "Epoch 33/100\n",
      "\u001b[1m18/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0043\n",
      "Epoch 33: val_loss did not improve from 0.00095\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0043 - val_loss: 0.0011\n",
      "Epoch 34/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0044\n",
      "Epoch 34: val_loss did not improve from 0.00095\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0044 - val_loss: 0.0011\n",
      "Epoch 35/100\n",
      "\u001b[1m17/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0036\n",
      "Epoch 35: val_loss did not improve from 0.00095\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0036 - val_loss: 9.8849e-04\n",
      "Epoch 36/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0035\n",
      "Epoch 36: val_loss did not improve from 0.00095\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0036 - val_loss: 0.0011\n",
      "Epoch 37/100\n",
      "\u001b[1m17/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0033\n",
      "Epoch 37: val_loss improved from 0.00095 to 0.00084, saving model to model_checkpoints/model_2.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0033 - val_loss: 8.4332e-04\n",
      "Epoch 38/100\n",
      "\u001b[1m18/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0033\n",
      "Epoch 38: val_loss did not improve from 0.00084\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0034 - val_loss: 0.0011\n",
      "Epoch 39/100\n",
      "\u001b[1m17/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0034\n",
      "Epoch 39: val_loss did not improve from 0.00084\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0034 - val_loss: 8.4378e-04\n",
      "Epoch 40/100\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0037\n",
      "Epoch 40: val_loss improved from 0.00084 to 0.00080, saving model to model_checkpoints/model_2.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0037 - val_loss: 8.0403e-04\n",
      "Epoch 41/100\n",
      "\u001b[1m18/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0035\n",
      "Epoch 41: val_loss did not improve from 0.00080\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0035 - val_loss: 0.0012\n",
      "Epoch 42/100\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0038\n",
      "Epoch 42: val_loss improved from 0.00080 to 0.00080, saving model to model_checkpoints/model_2.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0038 - val_loss: 7.9997e-04\n",
      "Epoch 43/100\n",
      "\u001b[1m18/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0032\n",
      "Epoch 43: val_loss did not improve from 0.00080\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0033 - val_loss: 0.0010\n",
      "Epoch 44/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0031\n",
      "Epoch 44: val_loss improved from 0.00080 to 0.00070, saving model to model_checkpoints/model_2.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0031 - val_loss: 6.9575e-04\n",
      "Epoch 45/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0032\n",
      "Epoch 45: val_loss did not improve from 0.00070\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0032 - val_loss: 7.6909e-04\n",
      "Epoch 46/100\n",
      "\u001b[1m17/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0026\n",
      "Epoch 46: val_loss improved from 0.00070 to 0.00069, saving model to model_checkpoints/model_2.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0028 - val_loss: 6.9111e-04\n",
      "Epoch 47/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0028\n",
      "Epoch 47: val_loss did not improve from 0.00069\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0028 - val_loss: 7.7446e-04\n",
      "Epoch 48/100\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0029\n",
      "Epoch 48: val_loss did not improve from 0.00069\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0029 - val_loss: 6.9476e-04\n",
      "Epoch 49/100\n",
      "\u001b[1m18/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0029\n",
      "Epoch 49: val_loss did not improve from 0.00069\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0029 - val_loss: 8.0065e-04\n",
      "Epoch 50/100\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0029\n",
      "Epoch 50: val_loss did not improve from 0.00069\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0029 - val_loss: 7.5743e-04\n",
      "Epoch 51/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0031\n",
      "Epoch 51: val_loss improved from 0.00069 to 0.00063, saving model to model_checkpoints/model_2.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0032 - val_loss: 6.2781e-04\n",
      "Epoch 52/100\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0027\n",
      "Epoch 52: val_loss did not improve from 0.00063\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0027 - val_loss: 6.5126e-04\n",
      "Epoch 53/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0025\n",
      "Epoch 53: val_loss did not improve from 0.00063\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0025 - val_loss: 6.7037e-04\n",
      "Epoch 54/100\n",
      "\u001b[1m18/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0031\n",
      "Epoch 54: val_loss did not improve from 0.00063\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0031 - val_loss: 8.0268e-04\n",
      "Epoch 55/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0025\n",
      "Epoch 55: val_loss did not improve from 0.00063\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0026 - val_loss: 7.2612e-04\n",
      "Epoch 56/100\n",
      "\u001b[1m17/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0027\n",
      "Epoch 56: val_loss did not improve from 0.00063\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0027 - val_loss: 7.6714e-04\n",
      "Epoch 57/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0028\n",
      "Epoch 57: val_loss did not improve from 0.00063\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0028 - val_loss: 6.6401e-04\n",
      "Epoch 58/100\n",
      "\u001b[1m17/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0029\n",
      "Epoch 58: val_loss did not improve from 0.00063\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0029 - val_loss: 8.7865e-04\n",
      "Epoch 59/100\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0024\n",
      "Epoch 59: val_loss did not improve from 0.00063\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0024 - val_loss: 6.4271e-04\n",
      "Epoch 60/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0024\n",
      "Epoch 60: val_loss did not improve from 0.00063\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0024 - val_loss: 7.7411e-04\n",
      "Epoch 61/100\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0028\n",
      "Epoch 61: val_loss did not improve from 0.00063\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0028 - val_loss: 7.4537e-04\n",
      "Epoch 61: early stopping\n",
      "Restoring model weights from the end of the best epoch: 51.\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x373639300> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 119ms/stepWARNING:tensorflow:6 out of the last 6 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x373639300> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step\n",
      "Epoch 1/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0941\n",
      "Epoch 1: val_loss improved from inf to 0.02128, saving model to model_checkpoints/model_3.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - loss: 0.0922 - val_loss: 0.0213\n",
      "Epoch 2/100\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0214\n",
      "Epoch 2: val_loss improved from 0.02128 to 0.00839, saving model to model_checkpoints/model_3.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0210 - val_loss: 0.0084\n",
      "Epoch 3/100\n",
      "\u001b[1m17/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0142\n",
      "Epoch 3: val_loss improved from 0.00839 to 0.00530, saving model to model_checkpoints/model_3.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0138 - val_loss: 0.0053\n",
      "Epoch 4/100\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0087\n",
      "Epoch 4: val_loss improved from 0.00530 to 0.00407, saving model to model_checkpoints/model_3.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0087 - val_loss: 0.0041\n",
      "Epoch 5/100\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0065\n",
      "Epoch 5: val_loss improved from 0.00407 to 0.00384, saving model to model_checkpoints/model_3.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0065 - val_loss: 0.0038\n",
      "Epoch 6/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0065\n",
      "Epoch 6: val_loss improved from 0.00384 to 0.00357, saving model to model_checkpoints/model_3.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0065 - val_loss: 0.0036\n",
      "Epoch 7/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0061\n",
      "Epoch 7: val_loss did not improve from 0.00357\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0061 - val_loss: 0.0041\n",
      "Epoch 8/100\n",
      "\u001b[1m18/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0063\n",
      "Epoch 8: val_loss improved from 0.00357 to 0.00316, saving model to model_checkpoints/model_3.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0063 - val_loss: 0.0032\n",
      "Epoch 9/100\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0053\n",
      "Epoch 9: val_loss improved from 0.00316 to 0.00260, saving model to model_checkpoints/model_3.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0053 - val_loss: 0.0026\n",
      "Epoch 10/100\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0049\n",
      "Epoch 10: val_loss did not improve from 0.00260\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0049 - val_loss: 0.0027\n",
      "Epoch 11/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0056\n",
      "Epoch 11: val_loss improved from 0.00260 to 0.00257, saving model to model_checkpoints/model_3.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0056 - val_loss: 0.0026\n",
      "Epoch 12/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0046\n",
      "Epoch 12: val_loss improved from 0.00257 to 0.00237, saving model to model_checkpoints/model_3.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0046 - val_loss: 0.0024\n",
      "Epoch 13/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0050\n",
      "Epoch 13: val_loss did not improve from 0.00237\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0050 - val_loss: 0.0024\n",
      "Epoch 14/100\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0045\n",
      "Epoch 14: val_loss improved from 0.00237 to 0.00223, saving model to model_checkpoints/model_3.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0045 - val_loss: 0.0022\n",
      "Epoch 15/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0051\n",
      "Epoch 15: val_loss improved from 0.00223 to 0.00202, saving model to model_checkpoints/model_3.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0051 - val_loss: 0.0020\n",
      "Epoch 16/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0045\n",
      "Epoch 16: val_loss improved from 0.00202 to 0.00197, saving model to model_checkpoints/model_3.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0045 - val_loss: 0.0020\n",
      "Epoch 17/100\n",
      "\u001b[1m17/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0039\n",
      "Epoch 17: val_loss did not improve from 0.00197\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0039 - val_loss: 0.0020\n",
      "Epoch 18/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0046\n",
      "Epoch 18: val_loss improved from 0.00197 to 0.00183, saving model to model_checkpoints/model_3.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0045 - val_loss: 0.0018\n",
      "Epoch 19/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0040\n",
      "Epoch 19: val_loss did not improve from 0.00183\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0040 - val_loss: 0.0020\n",
      "Epoch 20/100\n",
      "\u001b[1m17/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0042\n",
      "Epoch 20: val_loss improved from 0.00183 to 0.00175, saving model to model_checkpoints/model_3.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0042 - val_loss: 0.0017\n",
      "Epoch 21/100\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0040\n",
      "Epoch 21: val_loss improved from 0.00175 to 0.00171, saving model to model_checkpoints/model_3.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0040 - val_loss: 0.0017\n",
      "Epoch 22/100\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0038\n",
      "Epoch 22: val_loss did not improve from 0.00171\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0038 - val_loss: 0.0023\n",
      "Epoch 23/100\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0041\n",
      "Epoch 23: val_loss improved from 0.00171 to 0.00158, saving model to model_checkpoints/model_3.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0040 - val_loss: 0.0016\n",
      "Epoch 24/100\n",
      "\u001b[1m18/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0042\n",
      "Epoch 24: val_loss did not improve from 0.00158\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0041 - val_loss: 0.0027\n",
      "Epoch 25/100\n",
      "\u001b[1m17/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0033\n",
      "Epoch 25: val_loss did not improve from 0.00158\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0034 - val_loss: 0.0017\n",
      "Epoch 26/100\n",
      "\u001b[1m18/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0037\n",
      "Epoch 26: val_loss did not improve from 0.00158\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0037 - val_loss: 0.0018\n",
      "Epoch 27/100\n",
      "\u001b[1m18/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0039\n",
      "Epoch 27: val_loss did not improve from 0.00158\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0039 - val_loss: 0.0021\n",
      "Epoch 28/100\n",
      "\u001b[1m17/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0046\n",
      "Epoch 28: val_loss did not improve from 0.00158\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0046 - val_loss: 0.0023\n",
      "Epoch 29/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0036\n",
      "Epoch 29: val_loss improved from 0.00158 to 0.00138, saving model to model_checkpoints/model_3.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0036 - val_loss: 0.0014\n",
      "Epoch 30/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0036\n",
      "Epoch 30: val_loss did not improve from 0.00138\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0036 - val_loss: 0.0015\n",
      "Epoch 31/100\n",
      "\u001b[1m17/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0033\n",
      "Epoch 31: val_loss improved from 0.00138 to 0.00123, saving model to model_checkpoints/model_3.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0033 - val_loss: 0.0012\n",
      "Epoch 32/100\n",
      "\u001b[1m18/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0031\n",
      "Epoch 32: val_loss did not improve from 0.00123\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0031 - val_loss: 0.0015\n",
      "Epoch 33/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0030\n",
      "Epoch 33: val_loss did not improve from 0.00123\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0030 - val_loss: 0.0013\n",
      "Epoch 34/100\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0028\n",
      "Epoch 34: val_loss improved from 0.00123 to 0.00122, saving model to model_checkpoints/model_3.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0028 - val_loss: 0.0012\n",
      "Epoch 35/100\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0029\n",
      "Epoch 35: val_loss did not improve from 0.00122\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0029 - val_loss: 0.0016\n",
      "Epoch 36/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0031\n",
      "Epoch 36: val_loss did not improve from 0.00122\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0031 - val_loss: 0.0016\n",
      "Epoch 37/100\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0032\n",
      "Epoch 37: val_loss improved from 0.00122 to 0.00113, saving model to model_checkpoints/model_3.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0032 - val_loss: 0.0011\n",
      "Epoch 38/100\n",
      "\u001b[1m17/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0026\n",
      "Epoch 38: val_loss did not improve from 0.00113\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0026 - val_loss: 0.0012\n",
      "Epoch 39/100\n",
      "\u001b[1m18/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0024\n",
      "Epoch 39: val_loss improved from 0.00113 to 0.00107, saving model to model_checkpoints/model_3.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0024 - val_loss: 0.0011\n",
      "Epoch 40/100\n",
      "\u001b[1m18/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0023\n",
      "Epoch 40: val_loss did not improve from 0.00107\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0023 - val_loss: 0.0011\n",
      "Epoch 41/100\n",
      "\u001b[1m17/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0028\n",
      "Epoch 41: val_loss did not improve from 0.00107\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0028 - val_loss: 0.0012\n",
      "Epoch 42/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0030\n",
      "Epoch 42: val_loss improved from 0.00107 to 0.00102, saving model to model_checkpoints/model_3.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0030 - val_loss: 0.0010\n",
      "Epoch 43/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0029\n",
      "Epoch 43: val_loss did not improve from 0.00102\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0029 - val_loss: 0.0010\n",
      "Epoch 44/100\n",
      "\u001b[1m17/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0026\n",
      "Epoch 44: val_loss did not improve from 0.00102\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0026 - val_loss: 0.0011\n",
      "Epoch 45/100\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0028\n",
      "Epoch 45: val_loss improved from 0.00102 to 0.00092, saving model to model_checkpoints/model_3.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0027 - val_loss: 9.2387e-04\n",
      "Epoch 46/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0029\n",
      "Epoch 46: val_loss did not improve from 0.00092\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0029 - val_loss: 0.0011\n",
      "Epoch 47/100\n",
      "\u001b[1m17/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0028\n",
      "Epoch 47: val_loss did not improve from 0.00092\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0028 - val_loss: 0.0012\n",
      "Epoch 48/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0025\n",
      "Epoch 48: val_loss improved from 0.00092 to 0.00090, saving model to model_checkpoints/model_3.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0025 - val_loss: 8.9617e-04\n",
      "Epoch 49/100\n",
      "\u001b[1m18/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0023\n",
      "Epoch 49: val_loss did not improve from 0.00090\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0023 - val_loss: 9.7266e-04\n",
      "Epoch 50/100\n",
      "\u001b[1m17/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0020\n",
      "Epoch 50: val_loss improved from 0.00090 to 0.00086, saving model to model_checkpoints/model_3.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0021 - val_loss: 8.5745e-04\n",
      "Epoch 51/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0024\n",
      "Epoch 51: val_loss did not improve from 0.00086\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0024 - val_loss: 9.7388e-04\n",
      "Epoch 52/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0024\n",
      "Epoch 52: val_loss did not improve from 0.00086\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0024 - val_loss: 9.5657e-04\n",
      "Epoch 53/100\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0027\n",
      "Epoch 53: val_loss did not improve from 0.00086\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0026 - val_loss: 0.0016\n",
      "Epoch 54/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0023\n",
      "Epoch 54: val_loss did not improve from 0.00086\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0023 - val_loss: 8.8067e-04\n",
      "Epoch 55/100\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0026\n",
      "Epoch 55: val_loss did not improve from 0.00086\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0026 - val_loss: 0.0011\n",
      "Epoch 56/100\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0023\n",
      "Epoch 56: val_loss improved from 0.00086 to 0.00078, saving model to model_checkpoints/model_3.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0023 - val_loss: 7.8499e-04\n",
      "Epoch 57/100\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0022\n",
      "Epoch 57: val_loss did not improve from 0.00078\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0022 - val_loss: 0.0012\n",
      "Epoch 58/100\n",
      "\u001b[1m18/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0023\n",
      "Epoch 58: val_loss improved from 0.00078 to 0.00077, saving model to model_checkpoints/model_3.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0023 - val_loss: 7.6690e-04\n",
      "Epoch 59/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0020\n",
      "Epoch 59: val_loss did not improve from 0.00077\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0020 - val_loss: 7.7603e-04\n",
      "Epoch 60/100\n",
      "\u001b[1m17/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0021\n",
      "Epoch 60: val_loss improved from 0.00077 to 0.00077, saving model to model_checkpoints/model_3.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0021 - val_loss: 7.6677e-04\n",
      "Epoch 61/100\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0020\n",
      "Epoch 61: val_loss did not improve from 0.00077\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0020 - val_loss: 0.0011\n",
      "Epoch 62/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0022\n",
      "Epoch 62: val_loss did not improve from 0.00077\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0022 - val_loss: 0.0011\n",
      "Epoch 63/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0023\n",
      "Epoch 63: val_loss did not improve from 0.00077\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0023 - val_loss: 7.6802e-04\n",
      "Epoch 64/100\n",
      "\u001b[1m17/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0024\n",
      "Epoch 64: val_loss did not improve from 0.00077\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0024 - val_loss: 8.2894e-04\n",
      "Epoch 65/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0019\n",
      "Epoch 65: val_loss did not improve from 0.00077\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0019 - val_loss: 0.0012\n",
      "Epoch 66/100\n",
      "\u001b[1m18/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0019\n",
      "Epoch 66: val_loss improved from 0.00077 to 0.00070, saving model to model_checkpoints/model_3.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0019 - val_loss: 7.0196e-04\n",
      "Epoch 67/100\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0021\n",
      "Epoch 67: val_loss did not improve from 0.00070\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0021 - val_loss: 7.9091e-04\n",
      "Epoch 68/100\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0022\n",
      "Epoch 68: val_loss improved from 0.00070 to 0.00067, saving model to model_checkpoints/model_3.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0022 - val_loss: 6.6873e-04\n",
      "Epoch 69/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0019\n",
      "Epoch 69: val_loss did not improve from 0.00067\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0019 - val_loss: 7.4628e-04\n",
      "Epoch 70/100\n",
      "\u001b[1m17/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0021\n",
      "Epoch 70: val_loss did not improve from 0.00067\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0021 - val_loss: 7.2507e-04\n",
      "Epoch 71/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0019\n",
      "Epoch 71: val_loss did not improve from 0.00067\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0019 - val_loss: 0.0011\n",
      "Epoch 72/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0020\n",
      "Epoch 72: val_loss did not improve from 0.00067\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0020 - val_loss: 6.7832e-04\n",
      "Epoch 73/100\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0017\n",
      "Epoch 73: val_loss did not improve from 0.00067\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0017 - val_loss: 7.3759e-04\n",
      "Epoch 74/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0022\n",
      "Epoch 74: val_loss improved from 0.00067 to 0.00065, saving model to model_checkpoints/model_3.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0022 - val_loss: 6.4832e-04\n",
      "Epoch 75/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0019\n",
      "Epoch 75: val_loss did not improve from 0.00065\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0019 - val_loss: 6.8206e-04\n",
      "Epoch 76/100\n",
      "\u001b[1m17/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0020\n",
      "Epoch 76: val_loss did not improve from 0.00065\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0020 - val_loss: 8.1642e-04\n",
      "Epoch 77/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0020\n",
      "Epoch 77: val_loss did not improve from 0.00065\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0020 - val_loss: 6.8467e-04\n",
      "Epoch 78/100\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0019\n",
      "Epoch 78: val_loss did not improve from 0.00065\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0019 - val_loss: 7.9399e-04\n",
      "Epoch 79/100\n",
      "\u001b[1m17/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0016\n",
      "Epoch 79: val_loss did not improve from 0.00065\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0016 - val_loss: 9.4822e-04\n",
      "Epoch 80/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0022\n",
      "Epoch 80: val_loss improved from 0.00065 to 0.00054, saving model to model_checkpoints/model_3.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0022 - val_loss: 5.3684e-04\n",
      "Epoch 81/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0015\n",
      "Epoch 81: val_loss did not improve from 0.00054\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0015 - val_loss: 5.6158e-04\n",
      "Epoch 82/100\n",
      "\u001b[1m17/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0018\n",
      "Epoch 82: val_loss did not improve from 0.00054\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0018 - val_loss: 8.4548e-04\n",
      "Epoch 83/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0022\n",
      "Epoch 83: val_loss did not improve from 0.00054\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0022 - val_loss: 7.2045e-04\n",
      "Epoch 84/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0018\n",
      "Epoch 84: val_loss did not improve from 0.00054\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0018 - val_loss: 6.1782e-04\n",
      "Epoch 85/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0014\n",
      "Epoch 85: val_loss did not improve from 0.00054\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0014 - val_loss: 5.7440e-04\n",
      "Epoch 86/100\n",
      "\u001b[1m17/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0018\n",
      "Epoch 86: val_loss did not improve from 0.00054\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0018 - val_loss: 7.5293e-04\n",
      "Epoch 87/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0016\n",
      "Epoch 87: val_loss did not improve from 0.00054\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0016 - val_loss: 6.0516e-04\n",
      "Epoch 88/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0017\n",
      "Epoch 88: val_loss did not improve from 0.00054\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0017 - val_loss: 6.1668e-04\n",
      "Epoch 89/100\n",
      "\u001b[1m17/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0016\n",
      "Epoch 89: val_loss did not improve from 0.00054\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0016 - val_loss: 5.5876e-04\n",
      "Epoch 90/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0017\n",
      "Epoch 90: val_loss did not improve from 0.00054\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0017 - val_loss: 5.7882e-04\n",
      "Epoch 90: early stopping\n",
      "Restoring model weights from the end of the best epoch: 80.\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step\n",
      "Epoch 1/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.1185\n",
      "Epoch 1: val_loss improved from inf to 0.03170, saving model to model_checkpoints/model_4.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - loss: 0.1163 - val_loss: 0.0317\n",
      "Epoch 2/100\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0289\n",
      "Epoch 2: val_loss improved from 0.03170 to 0.01730, saving model to model_checkpoints/model_4.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0285 - val_loss: 0.0173\n",
      "Epoch 3/100\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0180\n",
      "Epoch 3: val_loss improved from 0.01730 to 0.01009, saving model to model_checkpoints/model_4.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0178 - val_loss: 0.0101\n",
      "Epoch 4/100\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0132\n",
      "Epoch 4: val_loss improved from 0.01009 to 0.00673, saving model to model_checkpoints/model_4.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0131 - val_loss: 0.0067\n",
      "Epoch 5/100\n",
      "\u001b[1m18/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0110\n",
      "Epoch 5: val_loss improved from 0.00673 to 0.00483, saving model to model_checkpoints/model_4.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0109 - val_loss: 0.0048\n",
      "Epoch 6/100\n",
      "\u001b[1m18/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0085\n",
      "Epoch 6: val_loss improved from 0.00483 to 0.00434, saving model to model_checkpoints/model_4.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0086 - val_loss: 0.0043\n",
      "Epoch 7/100\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0074\n",
      "Epoch 7: val_loss improved from 0.00434 to 0.00383, saving model to model_checkpoints/model_4.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0074 - val_loss: 0.0038\n",
      "Epoch 8/100\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0068\n",
      "Epoch 8: val_loss did not improve from 0.00383\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0068 - val_loss: 0.0040\n",
      "Epoch 9/100\n",
      "\u001b[1m17/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0076\n",
      "Epoch 9: val_loss improved from 0.00383 to 0.00344, saving model to model_checkpoints/model_4.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0075 - val_loss: 0.0034\n",
      "Epoch 10/100\n",
      "\u001b[1m17/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0068\n",
      "Epoch 10: val_loss improved from 0.00344 to 0.00322, saving model to model_checkpoints/model_4.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0068 - val_loss: 0.0032\n",
      "Epoch 11/100\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0057\n",
      "Epoch 11: val_loss did not improve from 0.00322\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0058 - val_loss: 0.0042\n",
      "Epoch 12/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0067\n",
      "Epoch 12: val_loss improved from 0.00322 to 0.00273, saving model to model_checkpoints/model_4.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0067 - val_loss: 0.0027\n",
      "Epoch 13/100\n",
      "\u001b[1m18/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0055\n",
      "Epoch 13: val_loss did not improve from 0.00273\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0056 - val_loss: 0.0033\n",
      "Epoch 14/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0065\n",
      "Epoch 14: val_loss improved from 0.00273 to 0.00254, saving model to model_checkpoints/model_4.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0065 - val_loss: 0.0025\n",
      "Epoch 15/100\n",
      "\u001b[1m18/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0054\n",
      "Epoch 15: val_loss did not improve from 0.00254\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0053 - val_loss: 0.0031\n",
      "Epoch 16/100\n",
      "\u001b[1m18/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0049\n",
      "Epoch 16: val_loss improved from 0.00254 to 0.00247, saving model to model_checkpoints/model_4.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0049 - val_loss: 0.0025\n",
      "Epoch 17/100\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0050\n",
      "Epoch 17: val_loss did not improve from 0.00247\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0049 - val_loss: 0.0032\n",
      "Epoch 18/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0057\n",
      "Epoch 18: val_loss did not improve from 0.00247\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0057 - val_loss: 0.0028\n",
      "Epoch 19/100\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0054\n",
      "Epoch 19: val_loss did not improve from 0.00247\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0054 - val_loss: 0.0029\n",
      "Epoch 20/100\n",
      "\u001b[1m18/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0048\n",
      "Epoch 20: val_loss did not improve from 0.00247\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0048 - val_loss: 0.0027\n",
      "Epoch 21/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0036\n",
      "Epoch 21: val_loss did not improve from 0.00247\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0036 - val_loss: 0.0026\n",
      "Epoch 22/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0048\n",
      "Epoch 22: val_loss did not improve from 0.00247\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0048 - val_loss: 0.0026\n",
      "Epoch 23/100\n",
      "\u001b[1m18/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0042\n",
      "Epoch 23: val_loss did not improve from 0.00247\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0043 - val_loss: 0.0027\n",
      "Epoch 24/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0051\n",
      "Epoch 24: val_loss did not improve from 0.00247\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0051 - val_loss: 0.0035\n",
      "Epoch 25/100\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0044\n",
      "Epoch 25: val_loss improved from 0.00247 to 0.00210, saving model to model_checkpoints/model_4.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0044 - val_loss: 0.0021\n",
      "Epoch 26/100\n",
      "\u001b[1m18/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0039\n",
      "Epoch 26: val_loss improved from 0.00210 to 0.00182, saving model to model_checkpoints/model_4.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0039 - val_loss: 0.0018\n",
      "Epoch 27/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0042\n",
      "Epoch 27: val_loss improved from 0.00182 to 0.00163, saving model to model_checkpoints/model_4.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0042 - val_loss: 0.0016\n",
      "Epoch 28/100\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0040\n",
      "Epoch 28: val_loss did not improve from 0.00163\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0039 - val_loss: 0.0017\n",
      "Epoch 29/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0037\n",
      "Epoch 29: val_loss did not improve from 0.00163\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0037 - val_loss: 0.0030\n",
      "Epoch 30/100\n",
      "\u001b[1m17/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0032\n",
      "Epoch 30: val_loss did not improve from 0.00163\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0032 - val_loss: 0.0017\n",
      "Epoch 31/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0038\n",
      "Epoch 31: val_loss did not improve from 0.00163\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0038 - val_loss: 0.0022\n",
      "Epoch 32/100\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0031\n",
      "Epoch 32: val_loss did not improve from 0.00163\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0031 - val_loss: 0.0020\n",
      "Epoch 33/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0039\n",
      "Epoch 33: val_loss improved from 0.00163 to 0.00154, saving model to model_checkpoints/model_4.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0039 - val_loss: 0.0015\n",
      "Epoch 34/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0031\n",
      "Epoch 34: val_loss did not improve from 0.00154\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0031 - val_loss: 0.0016\n",
      "Epoch 35/100\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0030\n",
      "Epoch 35: val_loss improved from 0.00154 to 0.00148, saving model to model_checkpoints/model_4.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0030 - val_loss: 0.0015\n",
      "Epoch 36/100\n",
      "\u001b[1m17/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0029\n",
      "Epoch 36: val_loss improved from 0.00148 to 0.00148, saving model to model_checkpoints/model_4.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0029 - val_loss: 0.0015\n",
      "Epoch 37/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0029\n",
      "Epoch 37: val_loss did not improve from 0.00148\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0029 - val_loss: 0.0019\n",
      "Epoch 38/100\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0034\n",
      "Epoch 38: val_loss improved from 0.00148 to 0.00145, saving model to model_checkpoints/model_4.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0034 - val_loss: 0.0015\n",
      "Epoch 39/100\n",
      "\u001b[1m18/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0029\n",
      "Epoch 39: val_loss did not improve from 0.00145\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0029 - val_loss: 0.0018\n",
      "Epoch 40/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0033\n",
      "Epoch 40: val_loss did not improve from 0.00145\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0033 - val_loss: 0.0018\n",
      "Epoch 41/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0034\n",
      "Epoch 41: val_loss improved from 0.00145 to 0.00133, saving model to model_checkpoints/model_4.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0033 - val_loss: 0.0013\n",
      "Epoch 42/100\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0027\n",
      "Epoch 42: val_loss improved from 0.00133 to 0.00125, saving model to model_checkpoints/model_4.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0027 - val_loss: 0.0013\n",
      "Epoch 43/100\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0027\n",
      "Epoch 43: val_loss did not improve from 0.00125\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0027 - val_loss: 0.0013\n",
      "Epoch 44/100\n",
      "\u001b[1m18/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0023\n",
      "Epoch 44: val_loss improved from 0.00125 to 0.00125, saving model to model_checkpoints/model_4.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0024 - val_loss: 0.0012\n",
      "Epoch 45/100\n",
      "\u001b[1m18/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0023\n",
      "Epoch 45: val_loss did not improve from 0.00125\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0023 - val_loss: 0.0013\n",
      "Epoch 46/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0027\n",
      "Epoch 46: val_loss improved from 0.00125 to 0.00119, saving model to model_checkpoints/model_4.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0027 - val_loss: 0.0012\n",
      "Epoch 47/100\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0025\n",
      "Epoch 47: val_loss did not improve from 0.00119\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0025 - val_loss: 0.0012\n",
      "Epoch 48/100\n",
      "\u001b[1m17/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0028\n",
      "Epoch 48: val_loss did not improve from 0.00119\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0028 - val_loss: 0.0031\n",
      "Epoch 49/100\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0035\n",
      "Epoch 49: val_loss did not improve from 0.00119\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0035 - val_loss: 0.0019\n",
      "Epoch 50/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0032\n",
      "Epoch 50: val_loss did not improve from 0.00119\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0032 - val_loss: 0.0015\n",
      "Epoch 51/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0027\n",
      "Epoch 51: val_loss did not improve from 0.00119\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0027 - val_loss: 0.0013\n",
      "Epoch 52/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0025\n",
      "Epoch 52: val_loss did not improve from 0.00119\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0025 - val_loss: 0.0012\n",
      "Epoch 53/100\n",
      "\u001b[1m18/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0026\n",
      "Epoch 53: val_loss did not improve from 0.00119\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0026 - val_loss: 0.0014\n",
      "Epoch 54/100\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0027\n",
      "Epoch 54: val_loss did not improve from 0.00119\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0027 - val_loss: 0.0013\n",
      "Epoch 55/100\n",
      "\u001b[1m18/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0027\n",
      "Epoch 55: val_loss did not improve from 0.00119\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0027 - val_loss: 0.0015\n",
      "Epoch 56/100\n",
      "\u001b[1m17/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0028\n",
      "Epoch 56: val_loss did not improve from 0.00119\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0028 - val_loss: 0.0014\n",
      "Epoch 56: early stopping\n",
      "Restoring model weights from the end of the best epoch: 46.\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step\n",
      "Epoch 1/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1599\n",
      "Epoch 1: val_loss improved from inf to 0.01690, saving model to model_checkpoints/model_5.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - loss: 0.1564 - val_loss: 0.0169\n",
      "Epoch 2/100\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0190\n",
      "Epoch 2: val_loss improved from 0.01690 to 0.00958, saving model to model_checkpoints/model_5.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0188 - val_loss: 0.0096\n",
      "Epoch 3/100\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0125\n",
      "Epoch 3: val_loss improved from 0.00958 to 0.00859, saving model to model_checkpoints/model_5.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0124 - val_loss: 0.0086\n",
      "Epoch 4/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0103\n",
      "Epoch 4: val_loss improved from 0.00859 to 0.00572, saving model to model_checkpoints/model_5.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0103 - val_loss: 0.0057\n",
      "Epoch 5/100\n",
      "\u001b[1m18/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0091\n",
      "Epoch 5: val_loss improved from 0.00572 to 0.00388, saving model to model_checkpoints/model_5.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0090 - val_loss: 0.0039\n",
      "Epoch 6/100\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0067\n",
      "Epoch 6: val_loss improved from 0.00388 to 0.00359, saving model to model_checkpoints/model_5.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0067 - val_loss: 0.0036\n",
      "Epoch 7/100\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0074\n",
      "Epoch 7: val_loss did not improve from 0.00359\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0074 - val_loss: 0.0056\n",
      "Epoch 8/100\n",
      "\u001b[1m17/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0081\n",
      "Epoch 8: val_loss did not improve from 0.00359\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0079 - val_loss: 0.0037\n",
      "Epoch 9/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0053\n",
      "Epoch 9: val_loss improved from 0.00359 to 0.00309, saving model to model_checkpoints/model_5.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0053 - val_loss: 0.0031\n",
      "Epoch 10/100\n",
      "\u001b[1m17/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0063\n",
      "Epoch 10: val_loss did not improve from 0.00309\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0063 - val_loss: 0.0048\n",
      "Epoch 11/100\n",
      "\u001b[1m18/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0062\n",
      "Epoch 11: val_loss improved from 0.00309 to 0.00255, saving model to model_checkpoints/model_5.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0062 - val_loss: 0.0025\n",
      "Epoch 12/100\n",
      "\u001b[1m17/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0054\n",
      "Epoch 12: val_loss improved from 0.00255 to 0.00253, saving model to model_checkpoints/model_5.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0055 - val_loss: 0.0025\n",
      "Epoch 13/100\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0065\n",
      "Epoch 13: val_loss did not improve from 0.00253\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0064 - val_loss: 0.0026\n",
      "Epoch 14/100\n",
      "\u001b[1m17/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0051\n",
      "Epoch 14: val_loss did not improve from 0.00253\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0051 - val_loss: 0.0029\n",
      "Epoch 15/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0049\n",
      "Epoch 15: val_loss improved from 0.00253 to 0.00203, saving model to model_checkpoints/model_5.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0049 - val_loss: 0.0020\n",
      "Epoch 16/100\n",
      "\u001b[1m17/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0050\n",
      "Epoch 16: val_loss improved from 0.00203 to 0.00201, saving model to model_checkpoints/model_5.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0050 - val_loss: 0.0020\n",
      "Epoch 17/100\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0047\n",
      "Epoch 17: val_loss improved from 0.00201 to 0.00189, saving model to model_checkpoints/model_5.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0048 - val_loss: 0.0019\n",
      "Epoch 18/100\n",
      "\u001b[1m18/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0049\n",
      "Epoch 18: val_loss did not improve from 0.00189\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0049 - val_loss: 0.0019\n",
      "Epoch 19/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0044\n",
      "Epoch 19: val_loss did not improve from 0.00189\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0044 - val_loss: 0.0021\n",
      "Epoch 20/100\n",
      "\u001b[1m18/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0039\n",
      "Epoch 20: val_loss improved from 0.00189 to 0.00173, saving model to model_checkpoints/model_5.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0039 - val_loss: 0.0017\n",
      "Epoch 21/100\n",
      "\u001b[1m18/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0053\n",
      "Epoch 21: val_loss improved from 0.00173 to 0.00162, saving model to model_checkpoints/model_5.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0052 - val_loss: 0.0016\n",
      "Epoch 22/100\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0049\n",
      "Epoch 22: val_loss did not improve from 0.00162\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0049 - val_loss: 0.0022\n",
      "Epoch 23/100\n",
      "\u001b[1m18/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0043\n",
      "Epoch 23: val_loss did not improve from 0.00162\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0043 - val_loss: 0.0024\n",
      "Epoch 24/100\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0050\n",
      "Epoch 24: val_loss improved from 0.00162 to 0.00145, saving model to model_checkpoints/model_5.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0050 - val_loss: 0.0015\n",
      "Epoch 25/100\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0035\n",
      "Epoch 25: val_loss did not improve from 0.00145\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0035 - val_loss: 0.0015\n",
      "Epoch 26/100\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0040\n",
      "Epoch 26: val_loss did not improve from 0.00145\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0040 - val_loss: 0.0015\n",
      "Epoch 27/100\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0038\n",
      "Epoch 27: val_loss improved from 0.00145 to 0.00124, saving model to model_checkpoints/model_5.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0038 - val_loss: 0.0012\n",
      "Epoch 28/100\n",
      "\u001b[1m17/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0035\n",
      "Epoch 28: val_loss did not improve from 0.00124\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0035 - val_loss: 0.0015\n",
      "Epoch 29/100\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0037\n",
      "Epoch 29: val_loss improved from 0.00124 to 0.00113, saving model to model_checkpoints/model_5.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0037 - val_loss: 0.0011\n",
      "Epoch 30/100\n",
      "\u001b[1m18/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0033\n",
      "Epoch 30: val_loss improved from 0.00113 to 0.00109, saving model to model_checkpoints/model_5.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0033 - val_loss: 0.0011\n",
      "Epoch 31/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0038\n",
      "Epoch 31: val_loss improved from 0.00109 to 0.00106, saving model to model_checkpoints/model_5.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0038 - val_loss: 0.0011\n",
      "Epoch 32/100\n",
      "\u001b[1m18/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0035\n",
      "Epoch 32: val_loss improved from 0.00106 to 0.00096, saving model to model_checkpoints/model_5.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0035 - val_loss: 9.5966e-04\n",
      "Epoch 33/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0032\n",
      "Epoch 33: val_loss did not improve from 0.00096\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0032 - val_loss: 0.0012\n",
      "Epoch 34/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0040\n",
      "Epoch 34: val_loss did not improve from 0.00096\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0039 - val_loss: 9.6951e-04\n",
      "Epoch 35/100\n",
      "\u001b[1m18/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0034\n",
      "Epoch 35: val_loss did not improve from 0.00096\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0033 - val_loss: 0.0010\n",
      "Epoch 36/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0030\n",
      "Epoch 36: val_loss did not improve from 0.00096\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0030 - val_loss: 0.0012\n",
      "Epoch 37/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0033\n",
      "Epoch 37: val_loss improved from 0.00096 to 0.00091, saving model to model_checkpoints/model_5.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0033 - val_loss: 9.0966e-04\n",
      "Epoch 38/100\n",
      "\u001b[1m18/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0031\n",
      "Epoch 38: val_loss did not improve from 0.00091\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0031 - val_loss: 9.9964e-04\n",
      "Epoch 39/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0035\n",
      "Epoch 39: val_loss did not improve from 0.00091\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0035 - val_loss: 9.4169e-04\n",
      "Epoch 40/100\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0027\n",
      "Epoch 40: val_loss improved from 0.00091 to 0.00087, saving model to model_checkpoints/model_5.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0027 - val_loss: 8.7157e-04\n",
      "Epoch 41/100\n",
      "\u001b[1m17/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0031\n",
      "Epoch 41: val_loss improved from 0.00087 to 0.00082, saving model to model_checkpoints/model_5.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0031 - val_loss: 8.2322e-04\n",
      "Epoch 42/100\n",
      "\u001b[1m17/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0032\n",
      "Epoch 42: val_loss did not improve from 0.00082\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0032 - val_loss: 0.0011\n",
      "Epoch 43/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0033\n",
      "Epoch 43: val_loss did not improve from 0.00082\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0033 - val_loss: 9.4121e-04\n",
      "Epoch 44/100\n",
      "\u001b[1m18/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0033\n",
      "Epoch 44: val_loss did not improve from 0.00082\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0032 - val_loss: 0.0013\n",
      "Epoch 45/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0031\n",
      "Epoch 45: val_loss did not improve from 0.00082\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0031 - val_loss: 8.4980e-04\n",
      "Epoch 46/100\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0025\n",
      "Epoch 46: val_loss did not improve from 0.00082\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0026 - val_loss: 9.2862e-04\n",
      "Epoch 47/100\n",
      "\u001b[1m18/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0029\n",
      "Epoch 47: val_loss did not improve from 0.00082\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0029 - val_loss: 8.6625e-04\n",
      "Epoch 48/100\n",
      "\u001b[1m17/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0035\n",
      "Epoch 48: val_loss did not improve from 0.00082\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0035 - val_loss: 8.6130e-04\n",
      "Epoch 49/100\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0026\n",
      "Epoch 49: val_loss did not improve from 0.00082\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0026 - val_loss: 8.5647e-04\n",
      "Epoch 50/100\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0024\n",
      "Epoch 50: val_loss improved from 0.00082 to 0.00079, saving model to model_checkpoints/model_5.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0025 - val_loss: 7.9134e-04\n",
      "Epoch 51/100\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0024\n",
      "Epoch 51: val_loss improved from 0.00079 to 0.00076, saving model to model_checkpoints/model_5.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0025 - val_loss: 7.5723e-04\n",
      "Epoch 52/100\n",
      "\u001b[1m18/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0030\n",
      "Epoch 52: val_loss did not improve from 0.00076\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0029 - val_loss: 7.9578e-04\n",
      "Epoch 53/100\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0024\n",
      "Epoch 53: val_loss did not improve from 0.00076\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0024 - val_loss: 8.0760e-04\n",
      "Epoch 54/100\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0029\n",
      "Epoch 54: val_loss improved from 0.00076 to 0.00069, saving model to model_checkpoints/model_5.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0029 - val_loss: 6.8894e-04\n",
      "Epoch 55/100\n",
      "\u001b[1m18/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0026\n",
      "Epoch 55: val_loss did not improve from 0.00069\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0026 - val_loss: 8.5556e-04\n",
      "Epoch 56/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0025\n",
      "Epoch 56: val_loss did not improve from 0.00069\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0025 - val_loss: 0.0016\n",
      "Epoch 57/100\n",
      "\u001b[1m18/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0032\n",
      "Epoch 57: val_loss did not improve from 0.00069\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0031 - val_loss: 0.0011\n",
      "Epoch 58/100\n",
      "\u001b[1m17/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0028\n",
      "Epoch 58: val_loss did not improve from 0.00069\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0027 - val_loss: 7.4118e-04\n",
      "Epoch 59/100\n",
      "\u001b[1m18/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0027\n",
      "Epoch 59: val_loss improved from 0.00069 to 0.00068, saving model to model_checkpoints/model_5.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0027 - val_loss: 6.7562e-04\n",
      "Epoch 60/100\n",
      "\u001b[1m18/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0024\n",
      "Epoch 60: val_loss did not improve from 0.00068\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0024 - val_loss: 0.0012\n",
      "Epoch 61/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0024\n",
      "Epoch 61: val_loss did not improve from 0.00068\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0024 - val_loss: 8.7712e-04\n",
      "Epoch 62/100\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0022\n",
      "Epoch 62: val_loss did not improve from 0.00068\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0022 - val_loss: 7.3172e-04\n",
      "Epoch 63/100\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0026\n",
      "Epoch 63: val_loss did not improve from 0.00068\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0026 - val_loss: 0.0021\n",
      "Epoch 64/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0027\n",
      "Epoch 64: val_loss did not improve from 0.00068\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0027 - val_loss: 7.0333e-04\n",
      "Epoch 65/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0023\n",
      "Epoch 65: val_loss did not improve from 0.00068\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0023 - val_loss: 7.2415e-04\n",
      "Epoch 66/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0021\n",
      "Epoch 66: val_loss did not improve from 0.00068\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0021 - val_loss: 6.7788e-04\n",
      "Epoch 67/100\n",
      "\u001b[1m17/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0022\n",
      "Epoch 67: val_loss did not improve from 0.00068\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0022 - val_loss: 7.3378e-04\n",
      "Epoch 68/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0025\n",
      "Epoch 68: val_loss improved from 0.00068 to 0.00066, saving model to model_checkpoints/model_5.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0025 - val_loss: 6.5893e-04\n",
      "Epoch 69/100\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0022\n",
      "Epoch 69: val_loss did not improve from 0.00066\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0022 - val_loss: 6.8875e-04\n",
      "Epoch 70/100\n",
      "\u001b[1m18/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0022\n",
      "Epoch 70: val_loss did not improve from 0.00066\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0022 - val_loss: 9.5448e-04\n",
      "Epoch 71/100\n",
      "\u001b[1m17/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0023\n",
      "Epoch 71: val_loss improved from 0.00066 to 0.00059, saving model to model_checkpoints/model_5.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0023 - val_loss: 5.8800e-04\n",
      "Epoch 72/100\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0022\n",
      "Epoch 72: val_loss did not improve from 0.00059\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0022 - val_loss: 6.3801e-04\n",
      "Epoch 73/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0023\n",
      "Epoch 73: val_loss did not improve from 0.00059\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0023 - val_loss: 7.3128e-04\n",
      "Epoch 74/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0019\n",
      "Epoch 74: val_loss did not improve from 0.00059\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0019 - val_loss: 5.9182e-04\n",
      "Epoch 75/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0021\n",
      "Epoch 75: val_loss improved from 0.00059 to 0.00058, saving model to model_checkpoints/model_5.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0021 - val_loss: 5.8179e-04\n",
      "Epoch 76/100\n",
      "\u001b[1m17/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0018\n",
      "Epoch 76: val_loss improved from 0.00058 to 0.00057, saving model to model_checkpoints/model_5.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0018 - val_loss: 5.6611e-04\n",
      "Epoch 77/100\n",
      "\u001b[1m18/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0020\n",
      "Epoch 77: val_loss did not improve from 0.00057\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0020 - val_loss: 8.6899e-04\n",
      "Epoch 78/100\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0020\n",
      "Epoch 78: val_loss did not improve from 0.00057\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0020 - val_loss: 6.8925e-04\n",
      "Epoch 79/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0019\n",
      "Epoch 79: val_loss did not improve from 0.00057\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0019 - val_loss: 0.0011\n",
      "Epoch 80/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0024\n",
      "Epoch 80: val_loss did not improve from 0.00057\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0023 - val_loss: 5.7379e-04\n",
      "Epoch 81/100\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0020\n",
      "Epoch 81: val_loss did not improve from 0.00057\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0020 - val_loss: 7.8440e-04\n",
      "Epoch 82/100\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0020\n",
      "Epoch 82: val_loss did not improve from 0.00057\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0020 - val_loss: 9.8184e-04\n",
      "Epoch 83/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0026\n",
      "Epoch 83: val_loss did not improve from 0.00057\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0026 - val_loss: 0.0012\n",
      "Epoch 84/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0023\n",
      "Epoch 84: val_loss did not improve from 0.00057\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0022 - val_loss: 6.3957e-04\n",
      "Epoch 85/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0019\n",
      "Epoch 85: val_loss did not improve from 0.00057\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0019 - val_loss: 7.0260e-04\n",
      "Epoch 86/100\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0018\n",
      "Epoch 86: val_loss did not improve from 0.00057\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0018 - val_loss: 6.8455e-04\n",
      "Epoch 86: early stopping\n",
      "Restoring model weights from the end of the best epoch: 76.\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step\n",
      "Epoch 1/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0880\n",
      "Epoch 1: val_loss improved from inf to 0.02279, saving model to model_checkpoints/model_6.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - loss: 0.0864 - val_loss: 0.0228\n",
      "Epoch 2/100\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0212\n",
      "Epoch 2: val_loss improved from 0.02279 to 0.01033, saving model to model_checkpoints/model_6.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0211 - val_loss: 0.0103\n",
      "Epoch 3/100\n",
      "\u001b[1m17/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0119\n",
      "Epoch 3: val_loss improved from 0.01033 to 0.00547, saving model to model_checkpoints/model_6.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0118 - val_loss: 0.0055\n",
      "Epoch 4/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0095\n",
      "Epoch 4: val_loss improved from 0.00547 to 0.00377, saving model to model_checkpoints/model_6.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0095 - val_loss: 0.0038\n",
      "Epoch 5/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0081\n",
      "Epoch 5: val_loss did not improve from 0.00377\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0081 - val_loss: 0.0039\n",
      "Epoch 6/100\n",
      "\u001b[1m17/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0074\n",
      "Epoch 6: val_loss did not improve from 0.00377\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0074 - val_loss: 0.0042\n",
      "Epoch 7/100\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0080\n",
      "Epoch 7: val_loss improved from 0.00377 to 0.00329, saving model to model_checkpoints/model_6.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0079 - val_loss: 0.0033\n",
      "Epoch 8/100\n",
      "\u001b[1m18/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0070\n",
      "Epoch 8: val_loss improved from 0.00329 to 0.00299, saving model to model_checkpoints/model_6.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0070 - val_loss: 0.0030\n",
      "Epoch 9/100\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0063\n",
      "Epoch 9: val_loss did not improve from 0.00299\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0063 - val_loss: 0.0033\n",
      "Epoch 10/100\n",
      "\u001b[1m18/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0064\n",
      "Epoch 10: val_loss did not improve from 0.00299\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0064 - val_loss: 0.0031\n",
      "Epoch 11/100\n",
      "\u001b[1m17/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0063\n",
      "Epoch 11: val_loss did not improve from 0.00299\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0064 - val_loss: 0.0041\n",
      "Epoch 12/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0072\n",
      "Epoch 12: val_loss improved from 0.00299 to 0.00276, saving model to model_checkpoints/model_6.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0072 - val_loss: 0.0028\n",
      "Epoch 13/100\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0052\n",
      "Epoch 13: val_loss improved from 0.00276 to 0.00244, saving model to model_checkpoints/model_6.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0052 - val_loss: 0.0024\n",
      "Epoch 14/100\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0054\n",
      "Epoch 14: val_loss improved from 0.00244 to 0.00231, saving model to model_checkpoints/model_6.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0054 - val_loss: 0.0023\n",
      "Epoch 15/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0054\n",
      "Epoch 15: val_loss did not improve from 0.00231\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0054 - val_loss: 0.0024\n",
      "Epoch 16/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0055\n",
      "Epoch 16: val_loss improved from 0.00231 to 0.00210, saving model to model_checkpoints/model_6.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0055 - val_loss: 0.0021\n",
      "Epoch 17/100\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0052\n",
      "Epoch 17: val_loss improved from 0.00210 to 0.00201, saving model to model_checkpoints/model_6.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0052 - val_loss: 0.0020\n",
      "Epoch 18/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0050\n",
      "Epoch 18: val_loss improved from 0.00201 to 0.00196, saving model to model_checkpoints/model_6.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0050 - val_loss: 0.0020\n",
      "Epoch 19/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0048\n",
      "Epoch 19: val_loss did not improve from 0.00196\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0048 - val_loss: 0.0020\n",
      "Epoch 20/100\n",
      "\u001b[1m17/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0042\n",
      "Epoch 20: val_loss improved from 0.00196 to 0.00192, saving model to model_checkpoints/model_6.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0043 - val_loss: 0.0019\n",
      "Epoch 21/100\n",
      "\u001b[1m18/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0046\n",
      "Epoch 21: val_loss improved from 0.00192 to 0.00159, saving model to model_checkpoints/model_6.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0045 - val_loss: 0.0016\n",
      "Epoch 22/100\n",
      "\u001b[1m17/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0046\n",
      "Epoch 22: val_loss improved from 0.00159 to 0.00155, saving model to model_checkpoints/model_6.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0046 - val_loss: 0.0016\n",
      "Epoch 23/100\n",
      "\u001b[1m18/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0037\n",
      "Epoch 23: val_loss did not improve from 0.00155\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0037 - val_loss: 0.0016\n",
      "Epoch 24/100\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0039\n",
      "Epoch 24: val_loss improved from 0.00155 to 0.00147, saving model to model_checkpoints/model_6.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0039 - val_loss: 0.0015\n",
      "Epoch 25/100\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0047\n",
      "Epoch 25: val_loss improved from 0.00147 to 0.00140, saving model to model_checkpoints/model_6.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0047 - val_loss: 0.0014\n",
      "Epoch 26/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0036\n",
      "Epoch 26: val_loss did not improve from 0.00140\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0036 - val_loss: 0.0015\n",
      "Epoch 27/100\n",
      "\u001b[1m17/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0038\n",
      "Epoch 27: val_loss improved from 0.00140 to 0.00123, saving model to model_checkpoints/model_6.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0038 - val_loss: 0.0012\n",
      "Epoch 28/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0035\n",
      "Epoch 28: val_loss improved from 0.00123 to 0.00116, saving model to model_checkpoints/model_6.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0035 - val_loss: 0.0012\n",
      "Epoch 29/100\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0036\n",
      "Epoch 29: val_loss did not improve from 0.00116\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0036 - val_loss: 0.0016\n",
      "Epoch 30/100\n",
      "\u001b[1m17/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0038\n",
      "Epoch 30: val_loss did not improve from 0.00116\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0038 - val_loss: 0.0023\n",
      "Epoch 31/100\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0043\n",
      "Epoch 31: val_loss did not improve from 0.00116\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0042 - val_loss: 0.0012\n",
      "Epoch 32/100\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0038\n",
      "Epoch 32: val_loss did not improve from 0.00116\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0038 - val_loss: 0.0015\n",
      "Epoch 33/100\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0035\n",
      "Epoch 33: val_loss did not improve from 0.00116\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0035 - val_loss: 0.0023\n",
      "Epoch 34/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0034\n",
      "Epoch 34: val_loss improved from 0.00116 to 0.00106, saving model to model_checkpoints/model_6.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0034 - val_loss: 0.0011\n",
      "Epoch 35/100\n",
      "\u001b[1m17/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0035\n",
      "Epoch 35: val_loss did not improve from 0.00106\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0035 - val_loss: 0.0012\n",
      "Epoch 36/100\n",
      "\u001b[1m17/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0034\n",
      "Epoch 36: val_loss improved from 0.00106 to 0.00098, saving model to model_checkpoints/model_6.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0034 - val_loss: 9.8321e-04\n",
      "Epoch 37/100\n",
      "\u001b[1m17/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0034\n",
      "Epoch 37: val_loss improved from 0.00098 to 0.00084, saving model to model_checkpoints/model_6.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0034 - val_loss: 8.4149e-04\n",
      "Epoch 38/100\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0030\n",
      "Epoch 38: val_loss improved from 0.00084 to 0.00078, saving model to model_checkpoints/model_6.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0030 - val_loss: 7.8015e-04\n",
      "Epoch 39/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0031\n",
      "Epoch 39: val_loss did not improve from 0.00078\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0031 - val_loss: 9.4136e-04\n",
      "Epoch 40/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0031\n",
      "Epoch 40: val_loss did not improve from 0.00078\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0031 - val_loss: 9.9553e-04\n",
      "Epoch 41/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0029\n",
      "Epoch 41: val_loss did not improve from 0.00078\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0029 - val_loss: 9.5277e-04\n",
      "Epoch 42/100\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0025\n",
      "Epoch 42: val_loss did not improve from 0.00078\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0025 - val_loss: 9.5618e-04\n",
      "Epoch 43/100\n",
      "\u001b[1m17/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0035\n",
      "Epoch 43: val_loss did not improve from 0.00078\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0035 - val_loss: 8.4869e-04\n",
      "Epoch 44/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0028\n",
      "Epoch 44: val_loss did not improve from 0.00078\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0028 - val_loss: 9.6782e-04\n",
      "Epoch 45/100\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0031\n",
      "Epoch 45: val_loss did not improve from 0.00078\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0031 - val_loss: 9.0320e-04\n",
      "Epoch 46/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0028\n",
      "Epoch 46: val_loss did not improve from 0.00078\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0028 - val_loss: 7.8051e-04\n",
      "Epoch 47/100\n",
      "\u001b[1m17/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0025\n",
      "Epoch 47: val_loss improved from 0.00078 to 0.00072, saving model to model_checkpoints/model_6.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0025 - val_loss: 7.2232e-04\n",
      "Epoch 48/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0027\n",
      "Epoch 48: val_loss did not improve from 0.00072\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0027 - val_loss: 0.0013\n",
      "Epoch 49/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0027\n",
      "Epoch 49: val_loss did not improve from 0.00072\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0027 - val_loss: 7.6394e-04\n",
      "Epoch 50/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0029\n",
      "Epoch 50: val_loss improved from 0.00072 to 0.00068, saving model to model_checkpoints/model_6.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0029 - val_loss: 6.7537e-04\n",
      "Epoch 51/100\n",
      "\u001b[1m17/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0025\n",
      "Epoch 51: val_loss did not improve from 0.00068\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0025 - val_loss: 0.0011\n",
      "Epoch 52/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0030\n",
      "Epoch 52: val_loss improved from 0.00068 to 0.00062, saving model to model_checkpoints/model_6.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0030 - val_loss: 6.2033e-04\n",
      "Epoch 53/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0024\n",
      "Epoch 53: val_loss did not improve from 0.00062\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0024 - val_loss: 6.4216e-04\n",
      "Epoch 54/100\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0021\n",
      "Epoch 54: val_loss did not improve from 0.00062\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0021 - val_loss: 7.4355e-04\n",
      "Epoch 55/100\n",
      "\u001b[1m18/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0024\n",
      "Epoch 55: val_loss did not improve from 0.00062\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0024 - val_loss: 6.3852e-04\n",
      "Epoch 56/100\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0026\n",
      "Epoch 56: val_loss did not improve from 0.00062\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0026 - val_loss: 6.4860e-04\n",
      "Epoch 57/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0024\n",
      "Epoch 57: val_loss did not improve from 0.00062\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0024 - val_loss: 8.5252e-04\n",
      "Epoch 58/100\n",
      "\u001b[1m17/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0024\n",
      "Epoch 58: val_loss did not improve from 0.00062\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0024 - val_loss: 7.0091e-04\n",
      "Epoch 59/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0023\n",
      "Epoch 59: val_loss did not improve from 0.00062\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0023 - val_loss: 7.3596e-04\n",
      "Epoch 60/100\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0023\n",
      "Epoch 60: val_loss did not improve from 0.00062\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0023 - val_loss: 8.6674e-04\n",
      "Epoch 61/100\n",
      "\u001b[1m17/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0024\n",
      "Epoch 61: val_loss did not improve from 0.00062\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0024 - val_loss: 8.6447e-04\n",
      "Epoch 62/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0029\n",
      "Epoch 62: val_loss did not improve from 0.00062\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0029 - val_loss: 8.1239e-04\n",
      "Epoch 62: early stopping\n",
      "Restoring model weights from the end of the best epoch: 52.\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step\n",
      "Epoch 1/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0879\n",
      "Epoch 1: val_loss improved from inf to 0.01846, saving model to model_checkpoints/model_7.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - loss: 0.0861 - val_loss: 0.0185\n",
      "Epoch 2/100\n",
      "\u001b[1m18/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0221\n",
      "Epoch 2: val_loss improved from 0.01846 to 0.00806, saving model to model_checkpoints/model_7.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0216 - val_loss: 0.0081\n",
      "Epoch 3/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0128\n",
      "Epoch 3: val_loss improved from 0.00806 to 0.00713, saving model to model_checkpoints/model_7.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0128 - val_loss: 0.0071\n",
      "Epoch 4/100\n",
      "\u001b[1m17/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0100\n",
      "Epoch 4: val_loss improved from 0.00713 to 0.00355, saving model to model_checkpoints/model_7.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0097 - val_loss: 0.0035\n",
      "Epoch 5/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0094\n",
      "Epoch 5: val_loss did not improve from 0.00355\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0093 - val_loss: 0.0068\n",
      "Epoch 6/100\n",
      "\u001b[1m18/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0092\n",
      "Epoch 6: val_loss did not improve from 0.00355\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0091 - val_loss: 0.0059\n",
      "Epoch 7/100\n",
      "\u001b[1m18/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0085\n",
      "Epoch 7: val_loss improved from 0.00355 to 0.00237, saving model to model_checkpoints/model_7.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0084 - val_loss: 0.0024\n",
      "Epoch 8/100\n",
      "\u001b[1m17/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0066\n",
      "Epoch 8: val_loss did not improve from 0.00237\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0065 - val_loss: 0.0028\n",
      "Epoch 9/100\n",
      "\u001b[1m17/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0072\n",
      "Epoch 9: val_loss did not improve from 0.00237\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0070 - val_loss: 0.0025\n",
      "Epoch 10/100\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0061\n",
      "Epoch 10: val_loss did not improve from 0.00237\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0061 - val_loss: 0.0045\n",
      "Epoch 11/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0071\n",
      "Epoch 11: val_loss improved from 0.00237 to 0.00232, saving model to model_checkpoints/model_7.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0071 - val_loss: 0.0023\n",
      "Epoch 12/100\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0065\n",
      "Epoch 12: val_loss did not improve from 0.00232\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0064 - val_loss: 0.0051\n",
      "Epoch 13/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0070\n",
      "Epoch 13: val_loss did not improve from 0.00232\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0070 - val_loss: 0.0025\n",
      "Epoch 14/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0049\n",
      "Epoch 14: val_loss improved from 0.00232 to 0.00218, saving model to model_checkpoints/model_7.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0049 - val_loss: 0.0022\n",
      "Epoch 15/100\n",
      "\u001b[1m17/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0058\n",
      "Epoch 15: val_loss did not improve from 0.00218\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0057 - val_loss: 0.0028\n",
      "Epoch 16/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0053\n",
      "Epoch 16: val_loss did not improve from 0.00218\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0053 - val_loss: 0.0027\n",
      "Epoch 17/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0050\n",
      "Epoch 17: val_loss improved from 0.00218 to 0.00204, saving model to model_checkpoints/model_7.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0049 - val_loss: 0.0020\n",
      "Epoch 18/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0043\n",
      "Epoch 18: val_loss improved from 0.00204 to 0.00151, saving model to model_checkpoints/model_7.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0043 - val_loss: 0.0015\n",
      "Epoch 19/100\n",
      "\u001b[1m17/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0049\n",
      "Epoch 19: val_loss did not improve from 0.00151\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0048 - val_loss: 0.0037\n",
      "Epoch 20/100\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0058\n",
      "Epoch 20: val_loss improved from 0.00151 to 0.00150, saving model to model_checkpoints/model_7.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0057 - val_loss: 0.0015\n",
      "Epoch 21/100\n",
      "\u001b[1m17/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0046\n",
      "Epoch 21: val_loss did not improve from 0.00150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0046 - val_loss: 0.0022\n",
      "Epoch 22/100\n",
      "\u001b[1m18/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0046\n",
      "Epoch 22: val_loss improved from 0.00150 to 0.00147, saving model to model_checkpoints/model_7.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0046 - val_loss: 0.0015\n",
      "Epoch 23/100\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0043\n",
      "Epoch 23: val_loss improved from 0.00147 to 0.00144, saving model to model_checkpoints/model_7.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0043 - val_loss: 0.0014\n",
      "Epoch 24/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0045\n",
      "Epoch 24: val_loss did not improve from 0.00144\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0045 - val_loss: 0.0016\n",
      "Epoch 25/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0041\n",
      "Epoch 25: val_loss improved from 0.00144 to 0.00137, saving model to model_checkpoints/model_7.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0041 - val_loss: 0.0014\n",
      "Epoch 26/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0035\n",
      "Epoch 26: val_loss did not improve from 0.00137\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0035 - val_loss: 0.0021\n",
      "Epoch 27/100\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0038\n",
      "Epoch 27: val_loss did not improve from 0.00137\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0038 - val_loss: 0.0014\n",
      "Epoch 28/100\n",
      "\u001b[1m18/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0033\n",
      "Epoch 28: val_loss did not improve from 0.00137\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0033 - val_loss: 0.0015\n",
      "Epoch 29/100\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0035\n",
      "Epoch 29: val_loss improved from 0.00137 to 0.00114, saving model to model_checkpoints/model_7.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0035 - val_loss: 0.0011\n",
      "Epoch 30/100\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0036\n",
      "Epoch 30: val_loss did not improve from 0.00114\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0036 - val_loss: 0.0012\n",
      "Epoch 31/100\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0036\n",
      "Epoch 31: val_loss did not improve from 0.00114\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0037 - val_loss: 0.0013\n",
      "Epoch 32/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0038\n",
      "Epoch 32: val_loss did not improve from 0.00114\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0038 - val_loss: 0.0014\n",
      "Epoch 33/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0032\n",
      "Epoch 33: val_loss did not improve from 0.00114\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0032 - val_loss: 0.0012\n",
      "Epoch 34/100\n",
      "\u001b[1m17/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0033\n",
      "Epoch 34: val_loss did not improve from 0.00114\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0033 - val_loss: 0.0013\n",
      "Epoch 35/100\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0032\n",
      "Epoch 35: val_loss did not improve from 0.00114\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0032 - val_loss: 0.0014\n",
      "Epoch 36/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0035\n",
      "Epoch 36: val_loss improved from 0.00114 to 0.00097, saving model to model_checkpoints/model_7.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0035 - val_loss: 9.7075e-04\n",
      "Epoch 37/100\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0036\n",
      "Epoch 37: val_loss did not improve from 0.00097\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0036 - val_loss: 0.0015\n",
      "Epoch 38/100\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0034\n",
      "Epoch 38: val_loss did not improve from 0.00097\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0034 - val_loss: 0.0010\n",
      "Epoch 39/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0033\n",
      "Epoch 39: val_loss did not improve from 0.00097\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0033 - val_loss: 0.0015\n",
      "Epoch 40/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0036\n",
      "Epoch 40: val_loss did not improve from 0.00097\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0036 - val_loss: 0.0022\n",
      "Epoch 41/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0036\n",
      "Epoch 41: val_loss did not improve from 0.00097\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0036 - val_loss: 0.0012\n",
      "Epoch 42/100\n",
      "\u001b[1m18/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0030\n",
      "Epoch 42: val_loss did not improve from 0.00097\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0030 - val_loss: 0.0012\n",
      "Epoch 43/100\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0032\n",
      "Epoch 43: val_loss improved from 0.00097 to 0.00093, saving model to model_checkpoints/model_7.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0032 - val_loss: 9.3476e-04\n",
      "Epoch 44/100\n",
      "\u001b[1m18/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0027\n",
      "Epoch 44: val_loss did not improve from 0.00093\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0027 - val_loss: 9.4402e-04\n",
      "Epoch 45/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0031\n",
      "Epoch 45: val_loss did not improve from 0.00093\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0031 - val_loss: 0.0013\n",
      "Epoch 46/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0031\n",
      "Epoch 46: val_loss did not improve from 0.00093\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0031 - val_loss: 9.4955e-04\n",
      "Epoch 47/100\n",
      "\u001b[1m18/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0025\n",
      "Epoch 47: val_loss did not improve from 0.00093\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0025 - val_loss: 0.0014\n",
      "Epoch 48/100\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0025\n",
      "Epoch 48: val_loss did not improve from 0.00093\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0025 - val_loss: 0.0011\n",
      "Epoch 49/100\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0026\n",
      "Epoch 49: val_loss did not improve from 0.00093\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0026 - val_loss: 9.8415e-04\n",
      "Epoch 50/100\n",
      "\u001b[1m18/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0028\n",
      "Epoch 50: val_loss did not improve from 0.00093\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0027 - val_loss: 0.0010\n",
      "Epoch 51/100\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0023\n",
      "Epoch 51: val_loss did not improve from 0.00093\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0023 - val_loss: 9.7750e-04\n",
      "Epoch 52/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0028\n",
      "Epoch 52: val_loss improved from 0.00093 to 0.00077, saving model to model_checkpoints/model_7.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0028 - val_loss: 7.7242e-04\n",
      "Epoch 53/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0024\n",
      "Epoch 53: val_loss did not improve from 0.00077\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0023 - val_loss: 0.0012\n",
      "Epoch 54/100\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0026\n",
      "Epoch 54: val_loss did not improve from 0.00077\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0026 - val_loss: 8.1526e-04\n",
      "Epoch 55/100\n",
      "\u001b[1m18/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0027\n",
      "Epoch 55: val_loss did not improve from 0.00077\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0027 - val_loss: 8.3629e-04\n",
      "Epoch 56/100\n",
      "\u001b[1m18/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0023\n",
      "Epoch 56: val_loss did not improve from 0.00077\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0023 - val_loss: 0.0011\n",
      "Epoch 57/100\n",
      "\u001b[1m18/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0026\n",
      "Epoch 57: val_loss did not improve from 0.00077\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0026 - val_loss: 8.8499e-04\n",
      "Epoch 58/100\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0026\n",
      "Epoch 58: val_loss did not improve from 0.00077\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0025 - val_loss: 0.0023\n",
      "Epoch 59/100\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0030\n",
      "Epoch 59: val_loss improved from 0.00077 to 0.00072, saving model to model_checkpoints/model_7.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0029 - val_loss: 7.2046e-04\n",
      "Epoch 60/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0021\n",
      "Epoch 60: val_loss did not improve from 0.00072\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0021 - val_loss: 0.0012\n",
      "Epoch 61/100\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0023\n",
      "Epoch 61: val_loss did not improve from 0.00072\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0022 - val_loss: 7.7184e-04\n",
      "Epoch 62/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0023\n",
      "Epoch 62: val_loss did not improve from 0.00072\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0023 - val_loss: 0.0019\n",
      "Epoch 63/100\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0028\n",
      "Epoch 63: val_loss did not improve from 0.00072\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0028 - val_loss: 7.2283e-04\n",
      "Epoch 64/100\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0022\n",
      "Epoch 64: val_loss did not improve from 0.00072\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0022 - val_loss: 8.8198e-04\n",
      "Epoch 65/100\n",
      "\u001b[1m17/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0019\n",
      "Epoch 65: val_loss did not improve from 0.00072\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0019 - val_loss: 8.8588e-04\n",
      "Epoch 66/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0021\n",
      "Epoch 66: val_loss did not improve from 0.00072\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0021 - val_loss: 7.5142e-04\n",
      "Epoch 67/100\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0021\n",
      "Epoch 67: val_loss did not improve from 0.00072\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0021 - val_loss: 8.5736e-04\n",
      "Epoch 68/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0022\n",
      "Epoch 68: val_loss did not improve from 0.00072\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0022 - val_loss: 0.0017\n",
      "Epoch 69/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0025\n",
      "Epoch 69: val_loss improved from 0.00072 to 0.00069, saving model to model_checkpoints/model_7.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0025 - val_loss: 6.9069e-04\n",
      "Epoch 70/100\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0020\n",
      "Epoch 70: val_loss did not improve from 0.00069\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0020 - val_loss: 7.5389e-04\n",
      "Epoch 71/100\n",
      "\u001b[1m17/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0020\n",
      "Epoch 71: val_loss did not improve from 0.00069\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0019 - val_loss: 0.0011\n",
      "Epoch 72/100\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0020\n",
      "Epoch 72: val_loss improved from 0.00069 to 0.00067, saving model to model_checkpoints/model_7.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0020 - val_loss: 6.6534e-04\n",
      "Epoch 73/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0019\n",
      "Epoch 73: val_loss did not improve from 0.00067\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0019 - val_loss: 0.0015\n",
      "Epoch 74/100\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0022\n",
      "Epoch 74: val_loss did not improve from 0.00067\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0022 - val_loss: 8.5434e-04\n",
      "Epoch 75/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0019\n",
      "Epoch 75: val_loss did not improve from 0.00067\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0019 - val_loss: 6.6717e-04\n",
      "Epoch 76/100\n",
      "\u001b[1m17/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0019\n",
      "Epoch 76: val_loss did not improve from 0.00067\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0019 - val_loss: 0.0010\n",
      "Epoch 77/100\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0021\n",
      "Epoch 77: val_loss did not improve from 0.00067\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0021 - val_loss: 7.6551e-04\n",
      "Epoch 78/100\n",
      "\u001b[1m18/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0018\n",
      "Epoch 78: val_loss did not improve from 0.00067\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0018 - val_loss: 7.7970e-04\n",
      "Epoch 79/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0019\n",
      "Epoch 79: val_loss improved from 0.00067 to 0.00062, saving model to model_checkpoints/model_7.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0019 - val_loss: 6.2271e-04\n",
      "Epoch 80/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0022\n",
      "Epoch 80: val_loss did not improve from 0.00062\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0022 - val_loss: 8.2094e-04\n",
      "Epoch 81/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0022\n",
      "Epoch 81: val_loss did not improve from 0.00062\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0022 - val_loss: 6.8084e-04\n",
      "Epoch 82/100\n",
      "\u001b[1m17/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0020\n",
      "Epoch 82: val_loss did not improve from 0.00062\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0020 - val_loss: 6.4373e-04\n",
      "Epoch 83/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0019\n",
      "Epoch 83: val_loss improved from 0.00062 to 0.00062, saving model to model_checkpoints/model_7.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0019 - val_loss: 6.1617e-04\n",
      "Epoch 84/100\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0020\n",
      "Epoch 84: val_loss did not improve from 0.00062\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0020 - val_loss: 0.0011\n",
      "Epoch 85/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0022\n",
      "Epoch 85: val_loss did not improve from 0.00062\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0022 - val_loss: 8.5712e-04\n",
      "Epoch 86/100\n",
      "\u001b[1m18/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0023\n",
      "Epoch 86: val_loss did not improve from 0.00062\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0022 - val_loss: 7.5184e-04\n",
      "Epoch 87/100\n",
      "\u001b[1m18/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0016\n",
      "Epoch 87: val_loss did not improve from 0.00062\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0016 - val_loss: 7.3637e-04\n",
      "Epoch 88/100\n",
      "\u001b[1m18/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0019\n",
      "Epoch 88: val_loss did not improve from 0.00062\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0019 - val_loss: 6.4386e-04\n",
      "Epoch 89/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0018\n",
      "Epoch 89: val_loss did not improve from 0.00062\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0018 - val_loss: 8.0995e-04\n",
      "Epoch 90/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0018\n",
      "Epoch 90: val_loss improved from 0.00062 to 0.00059, saving model to model_checkpoints/model_7.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0018 - val_loss: 5.8991e-04\n",
      "Epoch 91/100\n",
      "\u001b[1m18/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0017\n",
      "Epoch 91: val_loss improved from 0.00059 to 0.00056, saving model to model_checkpoints/model_7.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0017 - val_loss: 5.5864e-04\n",
      "Epoch 92/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0017\n",
      "Epoch 92: val_loss did not improve from 0.00056\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0017 - val_loss: 0.0013\n",
      "Epoch 93/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0019\n",
      "Epoch 93: val_loss did not improve from 0.00056\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0019 - val_loss: 6.0249e-04\n",
      "Epoch 94/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0017\n",
      "Epoch 94: val_loss did not improve from 0.00056\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0017 - val_loss: 6.0641e-04\n",
      "Epoch 95/100\n",
      "\u001b[1m18/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0017\n",
      "Epoch 95: val_loss did not improve from 0.00056\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0017 - val_loss: 6.0671e-04\n",
      "Epoch 96/100\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0016\n",
      "Epoch 96: val_loss did not improve from 0.00056\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0016 - val_loss: 7.1128e-04\n",
      "Epoch 97/100\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0019\n",
      "Epoch 97: val_loss did not improve from 0.00056\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0019 - val_loss: 6.5899e-04\n",
      "Epoch 98/100\n",
      "\u001b[1m17/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0013\n",
      "Epoch 98: val_loss did not improve from 0.00056\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0014 - val_loss: 6.2784e-04\n",
      "Epoch 99/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0015\n",
      "Epoch 99: val_loss did not improve from 0.00056\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0015 - val_loss: 5.8195e-04\n",
      "Epoch 100/100\n",
      "\u001b[1m18/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0016\n",
      "Epoch 100: val_loss did not improve from 0.00056\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0016 - val_loss: 6.0968e-04\n",
      "Restoring model weights from the end of the best epoch: 91.\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step\n",
      "Epoch 1/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.1096\n",
      "Epoch 1: val_loss improved from inf to 0.01909, saving model to model_checkpoints/model_8.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - loss: 0.1075 - val_loss: 0.0191\n",
      "Epoch 2/100\n",
      "\u001b[1m17/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0240\n",
      "Epoch 2: val_loss improved from 0.01909 to 0.00902, saving model to model_checkpoints/model_8.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0234 - val_loss: 0.0090\n",
      "Epoch 3/100\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0166\n",
      "Epoch 3: val_loss improved from 0.00902 to 0.00462, saving model to model_checkpoints/model_8.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0163 - val_loss: 0.0046\n",
      "Epoch 4/100\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0114\n",
      "Epoch 4: val_loss did not improve from 0.00462\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0113 - val_loss: 0.0048\n",
      "Epoch 5/100\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0100\n",
      "Epoch 5: val_loss improved from 0.00462 to 0.00338, saving model to model_checkpoints/model_8.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0099 - val_loss: 0.0034\n",
      "Epoch 6/100\n",
      "\u001b[1m18/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0093\n",
      "Epoch 6: val_loss did not improve from 0.00338\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0093 - val_loss: 0.0055\n",
      "Epoch 7/100\n",
      "\u001b[1m17/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0086\n",
      "Epoch 7: val_loss improved from 0.00338 to 0.00279, saving model to model_checkpoints/model_8.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0086 - val_loss: 0.0028\n",
      "Epoch 8/100\n",
      "\u001b[1m18/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0088\n",
      "Epoch 8: val_loss did not improve from 0.00279\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0087 - val_loss: 0.0029\n",
      "Epoch 9/100\n",
      "\u001b[1m18/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0079\n",
      "Epoch 9: val_loss did not improve from 0.00279\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0078 - val_loss: 0.0028\n",
      "Epoch 10/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0074\n",
      "Epoch 10: val_loss improved from 0.00279 to 0.00229, saving model to model_checkpoints/model_8.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0074 - val_loss: 0.0023\n",
      "Epoch 11/100\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0064\n",
      "Epoch 11: val_loss improved from 0.00229 to 0.00213, saving model to model_checkpoints/model_8.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0065 - val_loss: 0.0021\n",
      "Epoch 12/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0076\n",
      "Epoch 12: val_loss did not improve from 0.00213\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0076 - val_loss: 0.0032\n",
      "Epoch 13/100\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0074\n",
      "Epoch 13: val_loss improved from 0.00213 to 0.00203, saving model to model_checkpoints/model_8.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0074 - val_loss: 0.0020\n",
      "Epoch 14/100\n",
      "\u001b[1m18/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0067\n",
      "Epoch 14: val_loss did not improve from 0.00203\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0066 - val_loss: 0.0025\n",
      "Epoch 15/100\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0058\n",
      "Epoch 15: val_loss did not improve from 0.00203\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0058 - val_loss: 0.0021\n",
      "Epoch 16/100\n",
      "\u001b[1m17/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0069\n",
      "Epoch 16: val_loss improved from 0.00203 to 0.00196, saving model to model_checkpoints/model_8.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0069 - val_loss: 0.0020\n",
      "Epoch 17/100\n",
      "\u001b[1m17/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0061\n",
      "Epoch 17: val_loss improved from 0.00196 to 0.00176, saving model to model_checkpoints/model_8.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0061 - val_loss: 0.0018\n",
      "Epoch 18/100\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0070\n",
      "Epoch 18: val_loss did not improve from 0.00176\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0070 - val_loss: 0.0020\n",
      "Epoch 19/100\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0058\n",
      "Epoch 19: val_loss did not improve from 0.00176\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0058 - val_loss: 0.0028\n",
      "Epoch 20/100\n",
      "\u001b[1m18/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0056\n",
      "Epoch 20: val_loss improved from 0.00176 to 0.00168, saving model to model_checkpoints/model_8.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0055 - val_loss: 0.0017\n",
      "Epoch 21/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0054\n",
      "Epoch 21: val_loss did not improve from 0.00168\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0054 - val_loss: 0.0018\n",
      "Epoch 22/100\n",
      "\u001b[1m17/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0055\n",
      "Epoch 22: val_loss improved from 0.00168 to 0.00149, saving model to model_checkpoints/model_8.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0054 - val_loss: 0.0015\n",
      "Epoch 23/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0058\n",
      "Epoch 23: val_loss did not improve from 0.00149\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0058 - val_loss: 0.0029\n",
      "Epoch 24/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0056\n",
      "Epoch 24: val_loss improved from 0.00149 to 0.00143, saving model to model_checkpoints/model_8.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0056 - val_loss: 0.0014\n",
      "Epoch 25/100\n",
      "\u001b[1m18/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0050\n",
      "Epoch 25: val_loss did not improve from 0.00143\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0049 - val_loss: 0.0021\n",
      "Epoch 26/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0052\n",
      "Epoch 26: val_loss improved from 0.00143 to 0.00141, saving model to model_checkpoints/model_8.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0052 - val_loss: 0.0014\n",
      "Epoch 27/100\n",
      "\u001b[1m18/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0045\n",
      "Epoch 27: val_loss did not improve from 0.00141\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0045 - val_loss: 0.0021\n",
      "Epoch 28/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0052\n",
      "Epoch 28: val_loss improved from 0.00141 to 0.00121, saving model to model_checkpoints/model_8.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0051 - val_loss: 0.0012\n",
      "Epoch 29/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0048\n",
      "Epoch 29: val_loss improved from 0.00121 to 0.00121, saving model to model_checkpoints/model_8.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0048 - val_loss: 0.0012\n",
      "Epoch 30/100\n",
      "\u001b[1m17/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0041\n",
      "Epoch 30: val_loss did not improve from 0.00121\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0041 - val_loss: 0.0012\n",
      "Epoch 31/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0040\n",
      "Epoch 31: val_loss did not improve from 0.00121\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0040 - val_loss: 0.0017\n",
      "Epoch 32/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0044\n",
      "Epoch 32: val_loss improved from 0.00121 to 0.00105, saving model to model_checkpoints/model_8.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0043 - val_loss: 0.0010\n",
      "Epoch 33/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0043\n",
      "Epoch 33: val_loss did not improve from 0.00105\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0043 - val_loss: 0.0021\n",
      "Epoch 34/100\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0036\n",
      "Epoch 34: val_loss did not improve from 0.00105\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0036 - val_loss: 0.0012\n",
      "Epoch 35/100\n",
      "\u001b[1m17/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0046\n",
      "Epoch 35: val_loss did not improve from 0.00105\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0045 - val_loss: 0.0023\n",
      "Epoch 36/100\n",
      "\u001b[1m18/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0044\n",
      "Epoch 36: val_loss did not improve from 0.00105\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0043 - val_loss: 0.0011\n",
      "Epoch 37/100\n",
      "\u001b[1m18/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0034\n",
      "Epoch 37: val_loss did not improve from 0.00105\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0034 - val_loss: 0.0011\n",
      "Epoch 38/100\n",
      "\u001b[1m18/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0035\n",
      "Epoch 38: val_loss did not improve from 0.00105\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0034 - val_loss: 0.0016\n",
      "Epoch 39/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0032\n",
      "Epoch 39: val_loss improved from 0.00105 to 0.00088, saving model to model_checkpoints/model_8.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0032 - val_loss: 8.7516e-04\n",
      "Epoch 40/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0037\n",
      "Epoch 40: val_loss did not improve from 0.00088\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0037 - val_loss: 8.7654e-04\n",
      "Epoch 41/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0036\n",
      "Epoch 41: val_loss improved from 0.00088 to 0.00081, saving model to model_checkpoints/model_8.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0036 - val_loss: 8.0873e-04\n",
      "Epoch 42/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0029\n",
      "Epoch 42: val_loss improved from 0.00081 to 0.00076, saving model to model_checkpoints/model_8.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0029 - val_loss: 7.6077e-04\n",
      "Epoch 43/100\n",
      "\u001b[1m17/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0035\n",
      "Epoch 43: val_loss did not improve from 0.00076\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0034 - val_loss: 9.9911e-04\n",
      "Epoch 44/100\n",
      "\u001b[1m18/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0029\n",
      "Epoch 44: val_loss did not improve from 0.00076\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0029 - val_loss: 7.6514e-04\n",
      "Epoch 45/100\n",
      "\u001b[1m18/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0032\n",
      "Epoch 45: val_loss did not improve from 0.00076\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0032 - val_loss: 9.7747e-04\n",
      "Epoch 46/100\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0030\n",
      "Epoch 46: val_loss did not improve from 0.00076\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0030 - val_loss: 0.0011\n",
      "Epoch 47/100\n",
      "\u001b[1m17/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0038\n",
      "Epoch 47: val_loss did not improve from 0.00076\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0037 - val_loss: 7.6598e-04\n",
      "Epoch 48/100\n",
      "\u001b[1m18/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0031\n",
      "Epoch 48: val_loss improved from 0.00076 to 0.00068, saving model to model_checkpoints/model_8.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0031 - val_loss: 6.8227e-04\n",
      "Epoch 49/100\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0033\n",
      "Epoch 49: val_loss did not improve from 0.00068\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0033 - val_loss: 7.6369e-04\n",
      "Epoch 50/100\n",
      "\u001b[1m18/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0034\n",
      "Epoch 50: val_loss did not improve from 0.00068\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0034 - val_loss: 6.9843e-04\n",
      "Epoch 51/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0027\n",
      "Epoch 51: val_loss improved from 0.00068 to 0.00068, saving model to model_checkpoints/model_8.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0026 - val_loss: 6.7513e-04\n",
      "Epoch 52/100\n",
      "\u001b[1m17/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0027\n",
      "Epoch 52: val_loss improved from 0.00068 to 0.00063, saving model to model_checkpoints/model_8.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0027 - val_loss: 6.2708e-04\n",
      "Epoch 53/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0025\n",
      "Epoch 53: val_loss did not improve from 0.00063\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0025 - val_loss: 6.2949e-04\n",
      "Epoch 54/100\n",
      "\u001b[1m18/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0025\n",
      "Epoch 54: val_loss did not improve from 0.00063\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0025 - val_loss: 7.8333e-04\n",
      "Epoch 55/100\n",
      "\u001b[1m17/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0031\n",
      "Epoch 55: val_loss did not improve from 0.00063\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0031 - val_loss: 7.3894e-04\n",
      "Epoch 56/100\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0027\n",
      "Epoch 56: val_loss did not improve from 0.00063\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0027 - val_loss: 6.3887e-04\n",
      "Epoch 57/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0022\n",
      "Epoch 57: val_loss did not improve from 0.00063\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0022 - val_loss: 6.9963e-04\n",
      "Epoch 58/100\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0029\n",
      "Epoch 58: val_loss did not improve from 0.00063\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0029 - val_loss: 6.7106e-04\n",
      "Epoch 59/100\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0030\n",
      "Epoch 59: val_loss did not improve from 0.00063\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0030 - val_loss: 0.0012\n",
      "Epoch 60/100\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0028\n",
      "Epoch 60: val_loss did not improve from 0.00063\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0028 - val_loss: 6.3191e-04\n",
      "Epoch 61/100\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0025\n",
      "Epoch 61: val_loss improved from 0.00063 to 0.00055, saving model to model_checkpoints/model_8.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0025 - val_loss: 5.4716e-04\n",
      "Epoch 62/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0023\n",
      "Epoch 62: val_loss did not improve from 0.00055\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0023 - val_loss: 7.3404e-04\n",
      "Epoch 63/100\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0024\n",
      "Epoch 63: val_loss did not improve from 0.00055\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0024 - val_loss: 6.0385e-04\n",
      "Epoch 64/100\n",
      "\u001b[1m18/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0024\n",
      "Epoch 64: val_loss improved from 0.00055 to 0.00054, saving model to model_checkpoints/model_8.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0023 - val_loss: 5.4458e-04\n",
      "Epoch 65/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0028\n",
      "Epoch 65: val_loss did not improve from 0.00054\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0028 - val_loss: 7.4788e-04\n",
      "Epoch 66/100\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0025\n",
      "Epoch 66: val_loss did not improve from 0.00054\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0025 - val_loss: 0.0011\n",
      "Epoch 67/100\n",
      "\u001b[1m18/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0028\n",
      "Epoch 67: val_loss did not improve from 0.00054\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0027 - val_loss: 6.6780e-04\n",
      "Epoch 68/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0024\n",
      "Epoch 68: val_loss did not improve from 0.00054\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0024 - val_loss: 6.3678e-04\n",
      "Epoch 69/100\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0023\n",
      "Epoch 69: val_loss did not improve from 0.00054\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0022 - val_loss: 6.8241e-04\n",
      "Epoch 70/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0023\n",
      "Epoch 70: val_loss did not improve from 0.00054\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0023 - val_loss: 6.9720e-04\n",
      "Epoch 71/100\n",
      "\u001b[1m18/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0027\n",
      "Epoch 71: val_loss improved from 0.00054 to 0.00054, saving model to model_checkpoints/model_8.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0027 - val_loss: 5.4334e-04\n",
      "Epoch 72/100\n",
      "\u001b[1m17/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0020\n",
      "Epoch 72: val_loss improved from 0.00054 to 0.00051, saving model to model_checkpoints/model_8.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0020 - val_loss: 5.0633e-04\n",
      "Epoch 73/100\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0021\n",
      "Epoch 73: val_loss did not improve from 0.00051\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0021 - val_loss: 5.6774e-04\n",
      "Epoch 74/100\n",
      "\u001b[1m18/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0020\n",
      "Epoch 74: val_loss did not improve from 0.00051\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0020 - val_loss: 5.1155e-04\n",
      "Epoch 75/100\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0028\n",
      "Epoch 75: val_loss did not improve from 0.00051\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0028 - val_loss: 5.1050e-04\n",
      "Epoch 76/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0020\n",
      "Epoch 76: val_loss did not improve from 0.00051\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0020 - val_loss: 5.5714e-04\n",
      "Epoch 77/100\n",
      "\u001b[1m18/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0023\n",
      "Epoch 77: val_loss did not improve from 0.00051\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0023 - val_loss: 5.3799e-04\n",
      "Epoch 78/100\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0019\n",
      "Epoch 78: val_loss improved from 0.00051 to 0.00051, saving model to model_checkpoints/model_8.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0019 - val_loss: 5.0548e-04\n",
      "Epoch 79/100\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0021\n",
      "Epoch 79: val_loss improved from 0.00051 to 0.00049, saving model to model_checkpoints/model_8.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0021 - val_loss: 4.9196e-04\n",
      "Epoch 80/100\n",
      "\u001b[1m17/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0017\n",
      "Epoch 80: val_loss improved from 0.00049 to 0.00049, saving model to model_checkpoints/model_8.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0017 - val_loss: 4.9095e-04\n",
      "Epoch 81/100\n",
      "\u001b[1m18/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0019\n",
      "Epoch 81: val_loss improved from 0.00049 to 0.00049, saving model to model_checkpoints/model_8.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0020 - val_loss: 4.8527e-04\n",
      "Epoch 82/100\n",
      "\u001b[1m18/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0020\n",
      "Epoch 82: val_loss did not improve from 0.00049\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0020 - val_loss: 5.9368e-04\n",
      "Epoch 83/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0020\n",
      "Epoch 83: val_loss did not improve from 0.00049\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0019 - val_loss: 5.3602e-04\n",
      "Epoch 84/100\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0017\n",
      "Epoch 84: val_loss did not improve from 0.00049\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0017 - val_loss: 4.9536e-04\n",
      "Epoch 85/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0017\n",
      "Epoch 85: val_loss did not improve from 0.00049\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0017 - val_loss: 5.1506e-04\n",
      "Epoch 86/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0022\n",
      "Epoch 86: val_loss did not improve from 0.00049\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0022 - val_loss: 9.9567e-04\n",
      "Epoch 87/100\n",
      "\u001b[1m18/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0020\n",
      "Epoch 87: val_loss did not improve from 0.00049\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0020 - val_loss: 9.7345e-04\n",
      "Epoch 88/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0021\n",
      "Epoch 88: val_loss did not improve from 0.00049\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0021 - val_loss: 7.3636e-04\n",
      "Epoch 89/100\n",
      "\u001b[1m17/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0022\n",
      "Epoch 89: val_loss did not improve from 0.00049\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0021 - val_loss: 7.9854e-04\n",
      "Epoch 90/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0020\n",
      "Epoch 90: val_loss improved from 0.00049 to 0.00044, saving model to model_checkpoints/model_8.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0020 - val_loss: 4.4019e-04\n",
      "Epoch 91/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0022\n",
      "Epoch 91: val_loss did not improve from 0.00044\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0022 - val_loss: 7.1141e-04\n",
      "Epoch 92/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0018\n",
      "Epoch 92: val_loss did not improve from 0.00044\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0018 - val_loss: 5.4485e-04\n",
      "Epoch 93/100\n",
      "\u001b[1m18/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0018\n",
      "Epoch 93: val_loss did not improve from 0.00044\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0018 - val_loss: 4.5714e-04\n",
      "Epoch 94/100\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0016\n",
      "Epoch 94: val_loss did not improve from 0.00044\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0016 - val_loss: 5.3878e-04\n",
      "Epoch 95/100\n",
      "\u001b[1m18/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0020\n",
      "Epoch 95: val_loss did not improve from 0.00044\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0020 - val_loss: 4.5926e-04\n",
      "Epoch 96/100\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0020\n",
      "Epoch 96: val_loss did not improve from 0.00044\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0020 - val_loss: 5.1291e-04\n",
      "Epoch 97/100\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0019\n",
      "Epoch 97: val_loss did not improve from 0.00044\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0019 - val_loss: 4.4254e-04\n",
      "Epoch 98/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0018\n",
      "Epoch 98: val_loss improved from 0.00044 to 0.00043, saving model to model_checkpoints/model_8.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0018 - val_loss: 4.3068e-04\n",
      "Epoch 99/100\n",
      "\u001b[1m17/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0017\n",
      "Epoch 99: val_loss did not improve from 0.00043\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0017 - val_loss: 4.9832e-04\n",
      "Epoch 100/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0016\n",
      "Epoch 100: val_loss did not improve from 0.00043\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0016 - val_loss: 4.5723e-04\n",
      "Restoring model weights from the end of the best epoch: 98.\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step\n",
      "Epoch 1/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1297\n",
      "Epoch 1: val_loss improved from inf to 0.02469, saving model to model_checkpoints/model_9.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - loss: 0.1271 - val_loss: 0.0247\n",
      "Epoch 2/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0246\n",
      "Epoch 2: val_loss improved from 0.02469 to 0.01210, saving model to model_checkpoints/model_9.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0245 - val_loss: 0.0121\n",
      "Epoch 3/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0152\n",
      "Epoch 3: val_loss improved from 0.01210 to 0.00550, saving model to model_checkpoints/model_9.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0152 - val_loss: 0.0055\n",
      "Epoch 4/100\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0101\n",
      "Epoch 4: val_loss improved from 0.00550 to 0.00529, saving model to model_checkpoints/model_9.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0101 - val_loss: 0.0053\n",
      "Epoch 5/100\n",
      "\u001b[1m18/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0099\n",
      "Epoch 5: val_loss improved from 0.00529 to 0.00446, saving model to model_checkpoints/model_9.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0100 - val_loss: 0.0045\n",
      "Epoch 6/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0084\n",
      "Epoch 6: val_loss improved from 0.00446 to 0.00413, saving model to model_checkpoints/model_9.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0085 - val_loss: 0.0041\n",
      "Epoch 7/100\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0079\n",
      "Epoch 7: val_loss improved from 0.00413 to 0.00410, saving model to model_checkpoints/model_9.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0079 - val_loss: 0.0041\n",
      "Epoch 8/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0078\n",
      "Epoch 8: val_loss improved from 0.00410 to 0.00400, saving model to model_checkpoints/model_9.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0079 - val_loss: 0.0040\n",
      "Epoch 9/100\n",
      "\u001b[1m18/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0082\n",
      "Epoch 9: val_loss improved from 0.00400 to 0.00345, saving model to model_checkpoints/model_9.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0082 - val_loss: 0.0035\n",
      "Epoch 10/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0066\n",
      "Epoch 10: val_loss improved from 0.00345 to 0.00297, saving model to model_checkpoints/model_9.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0066 - val_loss: 0.0030\n",
      "Epoch 11/100\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0065\n",
      "Epoch 11: val_loss improved from 0.00297 to 0.00261, saving model to model_checkpoints/model_9.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0065 - val_loss: 0.0026\n",
      "Epoch 12/100\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0064\n",
      "Epoch 12: val_loss did not improve from 0.00261\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0064 - val_loss: 0.0026\n",
      "Epoch 13/100\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0069\n",
      "Epoch 13: val_loss did not improve from 0.00261\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0069 - val_loss: 0.0027\n",
      "Epoch 14/100\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0060\n",
      "Epoch 14: val_loss improved from 0.00261 to 0.00237, saving model to model_checkpoints/model_9.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0060 - val_loss: 0.0024\n",
      "Epoch 15/100\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0058\n",
      "Epoch 15: val_loss did not improve from 0.00237\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0058 - val_loss: 0.0025\n",
      "Epoch 16/100\n",
      "\u001b[1m18/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0056\n",
      "Epoch 16: val_loss did not improve from 0.00237\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0057 - val_loss: 0.0029\n",
      "Epoch 17/100\n",
      "\u001b[1m18/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0054\n",
      "Epoch 17: val_loss improved from 0.00237 to 0.00217, saving model to model_checkpoints/model_9.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0054 - val_loss: 0.0022\n",
      "Epoch 18/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0054\n",
      "Epoch 18: val_loss did not improve from 0.00217\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0054 - val_loss: 0.0023\n",
      "Epoch 19/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0046\n",
      "Epoch 19: val_loss improved from 0.00217 to 0.00195, saving model to model_checkpoints/model_9.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0047 - val_loss: 0.0020\n",
      "Epoch 20/100\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0058\n",
      "Epoch 20: val_loss did not improve from 0.00195\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0058 - val_loss: 0.0020\n",
      "Epoch 21/100\n",
      "\u001b[1m17/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0050\n",
      "Epoch 21: val_loss did not improve from 0.00195\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0050 - val_loss: 0.0021\n",
      "Epoch 22/100\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0043\n",
      "Epoch 22: val_loss did not improve from 0.00195\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0044 - val_loss: 0.0020\n",
      "Epoch 23/100\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0052\n",
      "Epoch 23: val_loss improved from 0.00195 to 0.00184, saving model to model_checkpoints/model_9.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0052 - val_loss: 0.0018\n",
      "Epoch 24/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0046\n",
      "Epoch 24: val_loss improved from 0.00184 to 0.00165, saving model to model_checkpoints/model_9.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0047 - val_loss: 0.0017\n",
      "Epoch 25/100\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0054\n",
      "Epoch 25: val_loss did not improve from 0.00165\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0054 - val_loss: 0.0017\n",
      "Epoch 26/100\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0041\n",
      "Epoch 26: val_loss did not improve from 0.00165\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0041 - val_loss: 0.0018\n",
      "Epoch 27/100\n",
      "\u001b[1m18/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0047\n",
      "Epoch 27: val_loss improved from 0.00165 to 0.00163, saving model to model_checkpoints/model_9.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0047 - val_loss: 0.0016\n",
      "Epoch 28/100\n",
      "\u001b[1m17/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0050\n",
      "Epoch 28: val_loss did not improve from 0.00163\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0049 - val_loss: 0.0017\n",
      "Epoch 29/100\n",
      "\u001b[1m18/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0039\n",
      "Epoch 29: val_loss did not improve from 0.00163\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0040 - val_loss: 0.0016\n",
      "Epoch 30/100\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0045\n",
      "Epoch 30: val_loss improved from 0.00163 to 0.00143, saving model to model_checkpoints/model_9.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0045 - val_loss: 0.0014\n",
      "Epoch 31/100\n",
      "\u001b[1m18/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0039\n",
      "Epoch 31: val_loss did not improve from 0.00143\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0039 - val_loss: 0.0015\n",
      "Epoch 32/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0039\n",
      "Epoch 32: val_loss did not improve from 0.00143\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0039 - val_loss: 0.0015\n",
      "Epoch 33/100\n",
      "\u001b[1m18/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0038\n",
      "Epoch 33: val_loss improved from 0.00143 to 0.00135, saving model to model_checkpoints/model_9.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0038 - val_loss: 0.0014\n",
      "Epoch 34/100\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0040\n",
      "Epoch 34: val_loss did not improve from 0.00135\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0039 - val_loss: 0.0014\n",
      "Epoch 35/100\n",
      "\u001b[1m18/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0039\n",
      "Epoch 35: val_loss improved from 0.00135 to 0.00129, saving model to model_checkpoints/model_9.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0039 - val_loss: 0.0013\n",
      "Epoch 36/100\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0031\n",
      "Epoch 36: val_loss improved from 0.00129 to 0.00118, saving model to model_checkpoints/model_9.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0032 - val_loss: 0.0012\n",
      "Epoch 37/100\n",
      "\u001b[1m18/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0038\n",
      "Epoch 37: val_loss did not improve from 0.00118\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0039 - val_loss: 0.0012\n",
      "Epoch 38/100\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0033\n",
      "Epoch 38: val_loss improved from 0.00118 to 0.00118, saving model to model_checkpoints/model_9.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0034 - val_loss: 0.0012\n",
      "Epoch 39/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0039\n",
      "Epoch 39: val_loss did not improve from 0.00118\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0039 - val_loss: 0.0012\n",
      "Epoch 40/100\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0035\n",
      "Epoch 40: val_loss did not improve from 0.00118\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0035 - val_loss: 0.0012\n",
      "Epoch 41/100\n",
      "\u001b[1m18/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0029\n",
      "Epoch 41: val_loss did not improve from 0.00118\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0030 - val_loss: 0.0014\n",
      "Epoch 42/100\n",
      "\u001b[1m18/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0033\n",
      "Epoch 42: val_loss improved from 0.00118 to 0.00101, saving model to model_checkpoints/model_9.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0033 - val_loss: 0.0010\n",
      "Epoch 43/100\n",
      "\u001b[1m18/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0033\n",
      "Epoch 43: val_loss did not improve from 0.00101\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0033 - val_loss: 0.0012\n",
      "Epoch 44/100\n",
      "\u001b[1m18/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0036\n",
      "Epoch 44: val_loss improved from 0.00101 to 0.00101, saving model to model_checkpoints/model_9.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0036 - val_loss: 0.0010\n",
      "Epoch 45/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0037\n",
      "Epoch 45: val_loss did not improve from 0.00101\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0036 - val_loss: 0.0011\n",
      "Epoch 46/100\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0031\n",
      "Epoch 46: val_loss did not improve from 0.00101\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0031 - val_loss: 0.0011\n",
      "Epoch 47/100\n",
      "\u001b[1m18/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0029\n",
      "Epoch 47: val_loss did not improve from 0.00101\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0029 - val_loss: 0.0012\n",
      "Epoch 48/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0032\n",
      "Epoch 48: val_loss improved from 0.00101 to 0.00092, saving model to model_checkpoints/model_9.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0032 - val_loss: 9.1627e-04\n",
      "Epoch 49/100\n",
      "\u001b[1m18/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0030\n",
      "Epoch 49: val_loss did not improve from 0.00092\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0030 - val_loss: 9.1871e-04\n",
      "Epoch 50/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0025\n",
      "Epoch 50: val_loss improved from 0.00092 to 0.00085, saving model to model_checkpoints/model_9.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0025 - val_loss: 8.5005e-04\n",
      "Epoch 51/100\n",
      "\u001b[1m18/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0026\n",
      "Epoch 51: val_loss did not improve from 0.00085\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0026 - val_loss: 0.0010\n",
      "Epoch 52/100\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0029\n",
      "Epoch 52: val_loss did not improve from 0.00085\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0029 - val_loss: 0.0012\n",
      "Epoch 53/100\n",
      "\u001b[1m18/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0031\n",
      "Epoch 53: val_loss improved from 0.00085 to 0.00083, saving model to model_checkpoints/model_9.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0030 - val_loss: 8.3448e-04\n",
      "Epoch 54/100\n",
      "\u001b[1m17/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0027\n",
      "Epoch 54: val_loss did not improve from 0.00083\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0027 - val_loss: 9.2858e-04\n",
      "Epoch 55/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0028\n",
      "Epoch 55: val_loss improved from 0.00083 to 0.00076, saving model to model_checkpoints/model_9.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0028 - val_loss: 7.5816e-04\n",
      "Epoch 56/100\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0023\n",
      "Epoch 56: val_loss did not improve from 0.00076\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0023 - val_loss: 0.0012\n",
      "Epoch 57/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0028\n",
      "Epoch 57: val_loss improved from 0.00076 to 0.00075, saving model to model_checkpoints/model_9.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0029 - val_loss: 7.4585e-04\n",
      "Epoch 58/100\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0026\n",
      "Epoch 58: val_loss did not improve from 0.00075\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0026 - val_loss: 7.8929e-04\n",
      "Epoch 59/100\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0024\n",
      "Epoch 59: val_loss did not improve from 0.00075\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0024 - val_loss: 7.9170e-04\n",
      "Epoch 60/100\n",
      "\u001b[1m18/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0025\n",
      "Epoch 60: val_loss did not improve from 0.00075\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0025 - val_loss: 7.9654e-04\n",
      "Epoch 61/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0026\n",
      "Epoch 61: val_loss improved from 0.00075 to 0.00074, saving model to model_checkpoints/model_9.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0026 - val_loss: 7.3654e-04\n",
      "Epoch 62/100\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0024\n",
      "Epoch 62: val_loss did not improve from 0.00074\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0024 - val_loss: 7.4097e-04\n",
      "Epoch 63/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0026\n",
      "Epoch 63: val_loss improved from 0.00074 to 0.00074, saving model to model_checkpoints/model_9.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0026 - val_loss: 7.3536e-04\n",
      "Epoch 64/100\n",
      "\u001b[1m17/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0022\n",
      "Epoch 64: val_loss did not improve from 0.00074\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0023 - val_loss: 9.7425e-04\n",
      "Epoch 65/100\n",
      "\u001b[1m18/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0025\n",
      "Epoch 65: val_loss did not improve from 0.00074\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0025 - val_loss: 8.6055e-04\n",
      "Epoch 66/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0025\n",
      "Epoch 66: val_loss did not improve from 0.00074\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0025 - val_loss: 0.0010\n",
      "Epoch 67/100\n",
      "\u001b[1m18/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0023\n",
      "Epoch 67: val_loss did not improve from 0.00074\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0023 - val_loss: 7.6104e-04\n",
      "Epoch 68/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0020\n",
      "Epoch 68: val_loss did not improve from 0.00074\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0021 - val_loss: 9.4948e-04\n",
      "Epoch 69/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0024\n",
      "Epoch 69: val_loss improved from 0.00074 to 0.00069, saving model to model_checkpoints/model_9.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0024 - val_loss: 6.9459e-04\n",
      "Epoch 70/100\n",
      "\u001b[1m17/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0021\n",
      "Epoch 70: val_loss did not improve from 0.00069\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0022 - val_loss: 8.5934e-04\n",
      "Epoch 71/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0020\n",
      "Epoch 71: val_loss did not improve from 0.00069\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0020 - val_loss: 7.8231e-04\n",
      "Epoch 72/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0027\n",
      "Epoch 72: val_loss did not improve from 0.00069\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0027 - val_loss: 7.5328e-04\n",
      "Epoch 73/100\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0023\n",
      "Epoch 73: val_loss improved from 0.00069 to 0.00065, saving model to model_checkpoints/model_9.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0023 - val_loss: 6.4794e-04\n",
      "Epoch 74/100\n",
      "\u001b[1m17/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0025\n",
      "Epoch 74: val_loss did not improve from 0.00065\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0025 - val_loss: 6.6159e-04\n",
      "Epoch 75/100\n",
      "\u001b[1m18/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0024\n",
      "Epoch 75: val_loss improved from 0.00065 to 0.00064, saving model to model_checkpoints/model_9.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0024 - val_loss: 6.3662e-04\n",
      "Epoch 76/100\n",
      "\u001b[1m18/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0018\n",
      "Epoch 76: val_loss did not improve from 0.00064\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0018 - val_loss: 8.1830e-04\n",
      "Epoch 77/100\n",
      "\u001b[1m18/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0021\n",
      "Epoch 77: val_loss improved from 0.00064 to 0.00061, saving model to model_checkpoints/model_9.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0021 - val_loss: 6.0562e-04\n",
      "Epoch 78/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0020\n",
      "Epoch 78: val_loss did not improve from 0.00061\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0020 - val_loss: 6.1698e-04\n",
      "Epoch 79/100\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0021\n",
      "Epoch 79: val_loss did not improve from 0.00061\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0021 - val_loss: 6.2792e-04\n",
      "Epoch 80/100\n",
      "\u001b[1m18/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0024\n",
      "Epoch 80: val_loss did not improve from 0.00061\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0023 - val_loss: 8.2153e-04\n",
      "Epoch 81/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0024\n",
      "Epoch 81: val_loss did not improve from 0.00061\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0024 - val_loss: 0.0011\n",
      "Epoch 82/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0026\n",
      "Epoch 82: val_loss did not improve from 0.00061\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0026 - val_loss: 8.8971e-04\n",
      "Epoch 83/100\n",
      "\u001b[1m17/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0018\n",
      "Epoch 83: val_loss did not improve from 0.00061\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0019 - val_loss: 7.5821e-04\n",
      "Epoch 84/100\n",
      "\u001b[1m17/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0023\n",
      "Epoch 84: val_loss did not improve from 0.00061\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0023 - val_loss: 7.2250e-04\n",
      "Epoch 85/100\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0020\n",
      "Epoch 85: val_loss improved from 0.00061 to 0.00059, saving model to model_checkpoints/model_9.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0020 - val_loss: 5.8929e-04\n",
      "Epoch 86/100\n",
      "\u001b[1m17/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0020\n",
      "Epoch 86: val_loss did not improve from 0.00059\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0020 - val_loss: 8.9662e-04\n",
      "Epoch 87/100\n",
      "\u001b[1m18/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0019\n",
      "Epoch 87: val_loss did not improve from 0.00059\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0019 - val_loss: 6.8788e-04\n",
      "Epoch 88/100\n",
      "\u001b[1m18/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0022\n",
      "Epoch 88: val_loss did not improve from 0.00059\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0022 - val_loss: 6.5988e-04\n",
      "Epoch 89/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0017\n",
      "Epoch 89: val_loss improved from 0.00059 to 0.00056, saving model to model_checkpoints/model_9.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0017 - val_loss: 5.6142e-04\n",
      "Epoch 90/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0019\n",
      "Epoch 90: val_loss did not improve from 0.00056\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0019 - val_loss: 6.2849e-04\n",
      "Epoch 91/100\n",
      "\u001b[1m18/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0017\n",
      "Epoch 91: val_loss did not improve from 0.00056\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0017 - val_loss: 5.9271e-04\n",
      "Epoch 92/100\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0018\n",
      "Epoch 92: val_loss improved from 0.00056 to 0.00056, saving model to model_checkpoints/model_9.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0018 - val_loss: 5.6064e-04\n",
      "Epoch 93/100\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0016\n",
      "Epoch 93: val_loss did not improve from 0.00056\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0016 - val_loss: 6.0424e-04\n",
      "Epoch 94/100\n",
      "\u001b[1m18/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0017\n",
      "Epoch 94: val_loss improved from 0.00056 to 0.00056, saving model to model_checkpoints/model_9.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0017 - val_loss: 5.5664e-04\n",
      "Epoch 95/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0018\n",
      "Epoch 95: val_loss did not improve from 0.00056\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0018 - val_loss: 5.8601e-04\n",
      "Epoch 96/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0018\n",
      "Epoch 96: val_loss improved from 0.00056 to 0.00051, saving model to model_checkpoints/model_9.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0018 - val_loss: 5.1389e-04\n",
      "Epoch 97/100\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0019\n",
      "Epoch 97: val_loss did not improve from 0.00051\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0020 - val_loss: 6.0525e-04\n",
      "Epoch 98/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0018\n",
      "Epoch 98: val_loss improved from 0.00051 to 0.00051, saving model to model_checkpoints/model_9.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0018 - val_loss: 5.0853e-04\n",
      "Epoch 99/100\n",
      "\u001b[1m17/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0017\n",
      "Epoch 99: val_loss did not improve from 0.00051\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0018 - val_loss: 5.4404e-04\n",
      "Epoch 100/100\n",
      "\u001b[1m17/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0018\n",
      "Epoch 100: val_loss did not improve from 0.00051\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0018 - val_loss: 5.6110e-04\n",
      "Restoring model weights from the end of the best epoch: 98.\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step\n",
      "\n",
      "===== SSN EVALUATION METRICS =====\n",
      "Average RMSE: 7.6426\n",
      "Average PICP: 0.1628\n",
      "Average MPIW: 6.8283\n",
      "==============================\n",
      "\n",
      "\n",
      "===== TSI EVALUATION METRICS =====\n",
      "Average RMSE: 0.0534\n",
      "Average PICP: 0.1860\n",
      "Average MPIW: 0.0518\n",
      "==============================\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABNYAAAK9CAYAAADoluEcAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQABAABJREFUeJzs3QV8U2cXBvBTSd0o7m7DYdiAATMGc2Fj7i7f3N3d3d3dYRtDhg53p7SlhVJ37/d73sstaaikbZIref77ZQltmtzc26bpk3POG1BVVVUlRERERERERERE1CiBjbs6ERERERERERERAYM1IiIiIiIiIiKiJmCwRkRERERERERE1AQM1oiIiIiIiIiIiJqAwRoREREREREREVETMFgjIiIiIiIiIiJqAgZrRERERERERERETcBgjYiIiIiIiIiIqAkYrBERERERERERETUBgzUiIiIiqiEgIEAeeOABt6977bXXen2b7Az7GvuRiIiIrIfBGhEREVlGQkKCCiBqO40ZM0bsbuHChSqEyc7OtsX9zpkzRx27b775ptbPI7Aze+CUkpKi9s2qVav86nuCiIiINMH7z4mIiIgs46yzzpJp06bV+Fjr1q3F7hCiPPjgg3LhhRdKXFyc1+6nqKhIgoODfX6/VoRgDfumW7duMnTo0Cbdxj333CN33HFHk76Wx4aIiMhYDNaIiIjIcoYPHy7nnnuux2+3uLhYQkJCJDDQv4v6w8LCjN4E0ysvL5fKykqP3BZCTOcgk4iIiKzDv181EhERkdvy8vLkhhtuUJU5oaGh0qZNGzn66KNlxYoV1dfZunWrnHbaadKuXTsVznTq1ElmzJghOTk5B83k+uGHH2TgwIHqtgYMGCB//PGHx7Z1x44dMn36dImPj5eIiAjVJvrrr7/W2ob4xRdfqIqhjh07quvm5uaqzy9ZskSOPfZYiY2NVR+fOHGiLFiw4KD72r17t1xyySXSoUMH9Vi6d+8uV111lZSWlqrPZ2Zmyi233CKDBg2SqKgoiYmJkalTp8rq1asPuq2XX35Z7QvcX4sWLeTQQw+Vzz77TH0O7X633nqruoz70Ftg0R5bm5deekmCgoJqtAg+++yz6mtuuumm6o9VVFRIdHS03H777bXOWHP3fr15PJ015vunoWMD2D/4vu7cubO6Tq9eveTJJ5+sEZrpLcjPPPOMvPDCC9KzZ0913ddee01GjhyprnPRRRdV75sPPvhAfWz+/Pnq+7BLly7q+riPG2+8UVUENjRjzZ3HWd+xwffrkCFDat2Hffv2lSlTpjTxCBAREZEzvjVGREREbrnyyivVLCz8sX/IIYdIRkaG/Pvvv7Jx40ZVQYawAn+sl5SUyHXXXafCNQQbv/zyiwovEFDp8HXfffedXH311SrUQQiEQC4xMVFatmzZ4LYUFhZKenp6jY/h9h0Oh+zdu1cOO+wwdZ3rr79e3d6HH34oJ554otr+U045pcbXPfzww6pKDeEXth2XZ8+ercKvESNGyP33368q2N5//3054ogjVFgyatSo6jZAXMbju/zyy6Vfv37qMeN+cP+4LYR8CEcQsCD8wPa9+eabKvjYsGGDCn3g7bffVtt7+umny//+9z9VPbdmzRoV8J199tly6qmnypYtW+Tzzz+X559/Xlq1alVvC+yECRNUOIR9ffzxx6uPYdvxWHCuW7lypeTn58vhhx9e6+24c7/NPZ6N5c79uXNscI7jgI9fccUVKgBDa+Wdd94pqampKkRzhu8BHBfcHoIufC8hcL7vvvvUx7DPAd9/8PXXX6v7QJiH7Vq6dKkKT5OTk9Xnmvs46zs25513nlx22WWybt06Fczp/vvvP/U1CJOJiIjIA6qIiIiI3BAbG1t1zTXX1Pn5lStXVuGlxddff13v7eA6ISEhVdu2bav+2OrVq9XHX3755Xq/dufOnep6tZ3++ecfdZ0bbrhB/Xv+/PnVX5eXl1fVvXv3qm7dulVVVFSoj+H6uF6PHj2qCgsLq69bWVlZ1bt376opU6aoyzpcB7dx9NFHV3/s/PPPrwoMDKz677//DtpW/WuLi4ur79P5cYSGhlY99NBD1R876aSTqgYMGFDv43/66afVNuPrG4L7jImJqbrtttuqt6dly5ZV06dPrwoKClL7BJ577jn1GLKysqq/Fvdx//33u3W/zTme+jGo63sG32+uL1fdvT93js3DDz9cFRkZWbVly5Yan7/jjjvUPkpMTKzxfYf9mZaWVuO6uH187v333z/ofpy/r3SPP/54VUBAQNWuXbuqP4Z93dTHWdexyc7OrgoLC6u6/fbba3z8+uuvV485Pz//oG0jIiKixmMrKBEREbkFg9FRPYVKoNroFWkzZ85UVTr1Oeqoo1Q7nW7w4MGqRRLVXe5AddCff/5Z46S3vf3222+qUmn8+PHV10cLJr4GLXKoEnN2wQUXSHh4ePW/sbojWlpRJYaqPFTG4VRQUCBHHnmkzJs3T1WC4YRKtBNOOEG1bLrSW/tQ2aTPbEPbJW4T24N2POc2WuxfVDKhosgTcJ+onML2AioLcd8Yko/cZtGiRerjqF5DRVNzBt8393h6+v7cPTaoGkOVGdpu9eOME24fx0rfdzpUizVmkQzn7yt8/+C2cUyw/1Ep2NzHWR/8PJ500kmqmk3L6bTvvy+//FJOPvlkiYyMdPtxEBERUd0YrBEREZFbnnrqKdVWhjlRCK4w38n5D3y0OWJ21zvvvKNa0tAW+uqrr9aYr6ZDy50rhBtZWVlubUvv3r1V6OB8wtfDrl27VGjlqn///tWfd4btdoZQTQ/cEKI4n/DY0C6Kx7Rv3z41j825za42CHnQpodtRsiGfYPbQpun877BjDMEbti3uO4111xT60y3xkBotHz5cjXTCwFa+/btVdsuQki9HRTthnoLY1M193h6+v7cPTY41phZ5nqc8f0EaWlp9X6vNAQtm1itE7P+cGxx22g9hdp+Lhr7OBty/vnnq23Qj/Vff/2lWpHRJkpERESewRlrRERE5JYzzjhDBTDff/+9zJo1S55++mk15B0zoDCPTB+OjyDhxx9/VNfBzLDHH39cFi9erBYy0GGofm30yhpfcq4qAn1oPR7f0KFDa/0ahCRYlMAdjz32mNx7771y8cUXq3luCFlQTYaB+c4D8hH8bd68Wc2kQ9jz7bffquH4mN/14IMPNumxoWqvrKxMVachXNEDNJzj35s2bVIhVHODtaYeT331Uddh/jpUPta2Qqmnvn+w/7EAx2233Vbr5/v06VPv90p9UB2G28b3CUJTzHhDlRjmueFnxJ0VRZv7OBFut23bVj755BM1Qw/nmH2oB4dERETUfAzWiIiIyG2oeMIgdZxQzYPqp0cffbQ6WAOsfokThqNjEPy4cePkjTfekEceecQn29i1a1cVULlCiKR/vj566x1a7uoLIFB9hOugiq8+GJY/efJkeffdd2t8HEP19WHzOgQvZ555pjphMQgMp8f+xTB9BEyuK0c2BNVvGNKPEA0nfQVJhCxYLOHvv/+u/nd9Gnu/7tKPRW3HS/94Q8erOccGxxoLNzQnaKpr36xdu1YtEoCFM1A5pkPbsifVd2wQzKGlGauUIgRHeywWNKgrsCMiIqLGYysoERERuVV949q61qZNG7WiJVojAa135eXlNa6DgA3VWfp1fGHatGlq9UV9hpg+3+qtt96Sbt26qRVN64OVQBG4PPPMMyp0cYUKL8Djwqyqn3/+WZYtW1ZnVRFCDNcKI8z2QuWSM8w/c4ZADNuKr0XVGehzsRDKuQNh3MiRI9WcLbQEOlesoUoMq0zisSIwrU9j79dduF9UBaKSyvW20cKKSkfn0NZd7h4bVGHi+wRzAV1he1y/nxuzb/TwyvnY4/KLL77Y6MfTlPvXoe0TraNY9RTfz+eee65H75+IiMjfsWKNiIiIGpSXl6daOU8//XQ1nwutkJjXhEH7aP+E2bNny7XXXivTp09XLXQIJT7++GMVMGDou69gOD+CJAQyaEVF6yWqhnbu3KnaK/WFBOqCz2OWGr5+wIABctFFF0nHjh1VEPbPP/+oSigENnqbJ1peMTcLiyOgnTM1NVUFZ5hdhgUBjj/+eHnooYfU7WBwPSqZPv30U+nRo0eN+z3mmGNUmx4q/NC+h8UGXnnlFTnuuOMkOjq6OvSDu+++W2bMmCEOh0MN6K9vED1CtCeeeEINs0fQqYeimEOHijC0JTakKffrrueee061LCJgw7YgrMVjRxCK4A3Vek3hzrFBBd9PP/2kjhHuG48TISyOESoNsdiFa1WhKwSTuC1UZeI4YZ+MHj1atX7ic7fccov63sH3Db7/PD13rqFjM2zYMDVrDo8b+wBVpkREROQ5DNaIiIioQREREar9E0EFZqphPlSvXr3UDLCrrrpKXQeBGwIShE4IEvA1+Njvv/8uY8aM8dm2IpRCCyrmWr388stSXFysVlPEdiGkcsekSZNUJRNmoiHcQqUPQi8EJqj80SFww0qpmKGGsAxVe/gYQjk8frjrrrtUWPPZZ5+pFRkRbPz6668qAHSG28VtIGjC/SHIRDCIllodqs+wTQhxMIcNxwGBoTvBGkI951ARH0ew5s58tabcr7vQJos2VbQKo4IOIS6OIVoYsUAGQsCmcOfY4Hzu3LkqhEPw9NFHH6kADMEw5trpK93WB0EWglsEgFdeeaUKlN9//30V1OF7Tp8ziOrBU045RYXP+gq2nuDOsUErKubIcdECIiIizwuoMmJKMBERERER+QTaT2+88UZVgVfbSqNERETUdAzWiIiIiIhsCi/1USHXsmVL1cpMREREnsVWUCIiIiIim0H7MebHIUzDzLgff/zR6E0iIiKyJVasERERERHZDNo+u3fvrhZWwHzERx991OhNIiIisiUGa0RERERERERERE1Q/3rzREREREREREREVCsGa0RERERERERERE3AxQtEpLKyUlJSUiQ6OloCAgKM3hwiIiIiIiIiIjIIpqbl5eVJhw4dJDCw/po0BmsiKlTr3Lmz0ZtBREREREREREQmkZSUJJ06dar3OgzWRFSlmr7DYmJixOrKyspk1qxZcswxx4jD4TB6c8hLeJztj8fY/nx1jAsKCtS7bfqbSZGRkV67L6qJP8f2x2NsP67PmSEhITzGNsefY/vjMba/Mg8f49zcXFWApedF9WGwhqVR97d/IlSzS7AWERGhHgufNOyLx9n+eIztz1fHOCgoqPoy7ovBmu/w59j+eIztx/U5E8Eaj7G98efY/niM7a/MS8fYnXFhXLyAiIiIiIiIiIioCRisERERERERERERNQGDNSIiIiIiIiIioibgjDUiIiI/Xka8vLxcKioqjN4UW8/7CA4OluLiYu5nm/KHY4yZY3iM7syZISIi8jcM1oiIiPxQaWmppKamSmFhodGbYvvwsl27dmrlcYYS9uQvxxgDodu3b68G+RMREdEBDNaIiIhsDtUm06ZNq75cWVkpO3fuVJc7dOig/lC2cyBgJOzr/Px8iYqKksBATuCwI7sfYwSHCOL37dunnjd69+5ty8dZ33MmERFRfRisERER2VxYWJj8+uuv1f9GyxrCgM6dO6sqFPIe7GeEEjgGdg8j/JU/HOPw8HBxOByya9eu6sfqT8+ZaPclIiKqiz1/+xMREVGD7BoCEJHn8fmCiIiodvwNSURERERERERE1AQM1oiIiGyuoKBAIiMj1QmXiYiobnzOJCKixmCwRkRE5Aew+qc/rQD6wQcfSFxcnCH3feGFF8rJJ5/ssdt74IEHZOjQoR67PSJqmL89ZxIRUdMxWCMiIiLLqCu0mjNnjlrZNDs7W/37zDPPlC1bthgSwr344ovqNu1q0qRJal/jFBoaKh07dpQTTjhBvvvuu0bfFkNDIiIisjoGa0RERGTLVQzbtGnj0/usqKhQK0TGxsYaVi3nK5dddpmkpqbK9u3b5dtvv5VDDjlEZsyYIZdffrnRm0ZERETkUwzWiIiISKqqMFfI9yfcrze4VqGtXr1aJk+eLNHR0RITEyMjRoyQZcuWqUq3iy66SHJycqqrsFBFBVlZWXL++edLixYtJCIiQqZOnSpbt2496D5++uknFSyheisxMfGgqjqEbU8//bT06tVLXadLly7y6KOPVn/+9ttvlz59+qj76NGjh9x7771SVlbm9mPFdp5zzjnSunVrFSj27t1b3n//ffW50tJSufbaa6V9+/YSFhYmXbt2lccff7z6a/F433nnHTnllFPU/eNr8Xgaguu2a9dOOnXqJGPGjJEnn3xS3nzzTXn77bflr7/+cuuxYf89+OCD6tjo+16v9Hvuuedk0KBBasZV586d5eqrr5b8/Hy39wkRERGRrwT77J6IiIjItDBKKCrK9/eLrCQy0vv3g+Bp2LBh8vrrr0tQUJCsWrVKHA6HHHbYYfLCCy/IfffdJ5s3b1bXjdq/IxCQIUhD0IQwDiHRtGnTZMOGDeprATOYECohnGrZsmWtVXIIjz7++GN5/vnnZfz48arSa9OmTdWfR9iHQKlDhw6ydu1aVQ2Gj912221uPTaEVdim33//XVq1aiXbtm2ToqIi9bmXXnpJbf9XX32lAr2kpCR1ct2+p556SoV/L7/8stpXu3btkvj4+Ebt4wsuuEBuvvlm1RJ61FFHNfjY0K67bt06+eOPP6rDOFT7QWBgoNr27t27y44dO1Swhq957bXXGrVNRERERN7GYI2IiIgs5ZdffqkOv5zbMOuDSrJbb71V+vXrp/6NyiwdwhxUS6ECS6cHagsWLFDhG3z66aeqeuqHH36Q6dOnq4+h+gphz5AhQ2q937y8PFXJhZAIwRP07NlTBWy6e+65p/pyt27d5JZbbpEvvvjC7WANjw2h4aGHHlp9G86fw2PF/eExomLNFQLEs846S11+7LHH1LYuXbpUjj32WGkMhGGoTktISHDrsaG6DscxODi4xr6HG264ocbXPfLII3LllVcyWCMiIiLTYbBGRERkcwg8Jk6cWH25NhERWvWYr+F+Gwstnag8c7ZkyRI599xz6/yam266SS699FJVOYZqKgRjCLjqsnHjRhX4jB49uvpjqEjr27ev+pwuJCREBg8eXO/tlJSUyJFHHlnndb788ksVZmFeGdody8vLVYWcu6666io57bTTZMWKFXLMMceoNlQ9DERodvTRR6vtRlB2/PHHq+s4c95+tF7ivtPS0qQpqqqqVIDX3MeGCja0rKKyLzc3V31dcXGxqhBEWymR0c+ZREREOv6mICIisjlUBmGWGE64XBtkIWjJ9PXJKYNxG8IfzCtzPmFlyvpgbtr69evluOOOk9mzZ6uZaN9//700F/anc5BU2+frs2jRItV6iRZTVOKtXLlS7r77bjUbzV2Y/YbWzRtvvFFSUlJUiIfKMBg+fLjs3LlTHn74YdUeesYZZ8jpp59e4+v1tlYdHg/mwjUWqgZR6Yf2zeY8NlS8IQBE4IeFEZYvXy6vvvqq+lxj9guRN58ziYiIdAzWiIiIyC+gTRHh06xZs+TUU0+tHvCPqjPXVtL+/furKilUwukyMjLUHDaEcu5CGyb+MP/7779r/fzChQtVeyYCJ7Ry4voIyRoLCxeg1fSTTz5RM+Peeuut6s+hQgzzzLCwACrIEFZlZmaKp3344YdqIQVUz7n72Grb9wjSEOw9++yzamEEHDcEhkRERERmxFZQIiIisjVUamG+Giq1UE2VnJws//33X3UAhBleaFNE+IVZafrqmCeddJIato8ZaRi4f8cdd6jKOHzcXViJ83//+5/6WlweN26c7Nu3T1XPXXLJJep+MAcNc8dGjhwpv/76a6Mr6bDwAlY5HTBggGo7RXUYgkF9dU2sCIoZbGhp+/rrr9U8M+cVU5sCLZl79uxR4SP2J7YZizOgLRWtuuDOY8O+R0UdFpPACqPYz6hAxOw6LKRwwgknqDl3b7zxRrO2l4iIiMhbWLFGRERkcwUFBaqiCSdc9jdYBRTVZueff76qfkI7JNonsRomYB4ZBuOjqgv7CCtkAiraEFihLXHs2LFqfthvv/12UOtkQxDqYcYbAjAEXrgffYbZiSeeqKrorr32Whk6dKiq8sIqn42Bqq8777xTtU4efvjh6vEizAIEVXg8qBhDuIU2SzyG5s6NQvUbAjvMqUP1H1YlRTWc8+IC7jw2hJuY/YYwDvv+888/V+EmAkGstjpw4EC1aATmrRH5ir8/ZxIRUeMEVOFVop/DUFysCJaTk9OoYcFmhXd58aIZM00a++KfrIPH2f54jO3PV8cYfxjqq2iiMgvBC6qEUL2FKiryHrQ04nUGXl9wCLo9+csxxuIR/vK84fqcifCav4/tja+57I/H2P7KPHyMG5MT2fe3PxERERERERERkRcxWCMiIiIiIiIiImoCLl5AREREREREZEKlFaVSVFYkJRUlEhgQKI5Ah4QFh0locKjRm0ZE+zFYIyIiIiIiIjKRvJI8ScpJkpS8FBWqlVWUiQSICtZCg0KlfXR7aRfVTlqEt1CBGxEZh8EaERERERERkQlUVlXKtsxtsjN7pxSWFkpcWJy0DGkpjiCHWp26vLJcisqL1HV2ZO2QTjGdpFd8L4kOjTZ604n8FoM1IiIim8NKhYceemj1ZSIiqhufM8nIUG1LxhbZtG+TxIbFSqvYVjU+HxAQoAI2nGJCY6SkvER25eyS9MJ06d2yt3SJ7cLqNSIDMFgjIiKyufDwcPnvv/+q/11cXGzo9hARWek5s6yszNDtIf+AarQdmTtkc/pmiQ+Pl8iQyAa/BnPWOsd0luzibFm1Z5VqH+3Xqp8K3ojIdxhnE5HpPP20yFVXiZSWGr0lRERERETel5qfKpsyNqnWT3dCNWf4mtYRrWVr5lZZs3eNWuyAiHyHFWtEZCoZGSK334537UTathV54AGjt4iIiIiIyHsKywplS/oWCQ4IlqiQqCbdBlYK7RjdURJzEtUctiHthqiPEZH3sWKNiEzlr7+0UA0efVRk1aqan09MFMHYk5deMmTziCypsLBQunXrpk647O8mTZokN9xwQ/W/sV9eeOGFer8Gc21++OGHZt+3p27HXznvv4SEBPXvVa6/KBrBE7dB9sPnTPJ1CygWIsgqzpJWETVnqjVWcGCwdIjuILvzdsv6tPVSWsH2DyJfYLBGRKYya5Z2HhoqUl4ucuGFNVtCn39eZPlyraotNdWwzSSy3Iv2Xbt2qRMuW9UJJ5wgxx57bK2fmz9/vgpI1qxZ0+jbxSylyy+/XDzpgQcekKFDhx708dTUVJk6darYCfa7foqNjZVx48bJ7NmzvX6/nTt3Vvtz4MCBbl3/wgsvlJNPPrlZt0H+wS7PmWSdFtCdWTulTWQb9TzaXAjXULmGRQ027NsgFZUVHtlOIqobgzUiMg28dp05U7v8zjsiLVuKrF6tzVwDzFv/6KMDl/WPE5F/uOSSS+TPP/+U5OTkgz73/vvvq1X8Bg8e3Ojbbd26tURERIgvtGvXTkLxzoHNYP8joFqwYIG0atVKjj/+eNmxY0et1/XUIPigoCC1P4ODgw29DSKipkJF2daMrRIaFOrRtk2Ea+0i28mOrB2qGo4BMZF3MVgjItPYsEFk926RsDCR004TefFF7eOPPy6yZ4/I99+LZGaK6H//vv669nEi8gC86EZ5qK9PjXixj7AGIdgHH3xQ4+P5+fny9ddfq+AtIyNDzjrrLOnYsaMKywYNGiSff/55vbfr2gq6detWOfzwwyUsLEwOOeQQFea5uv3226VPnz7qPnr06CH33ntvdWCE7XvwwQdl9erVKrhp0aJF9Ta7toKuXbtWjjjiCLUKYcuWLVXlHB6Pa5XVM888I+3bt1fXueaaa+oNp3C/kydPlujoaImJiZERI0bIsmXL1OdQgYPKP2xTZGSkDBgwQH777Tf1uTlz5qjt+/vvv1VIicd22GGHyebNmxs8NnFxcSqgQuXX66+/LkVFRdX7DbeJj5144onqPh9Fn7+I/PjjjzJ8+HC1n7EPsc/KUars5nGorY1z/fr16vsEjxuPf8KECbJ9+3ZVQfjhhx+q+9Sr6/B4a7uNuXPnyqhRo1QAin1+xx131NgutBJff/31ctttt0l8fLx06NBBnnjiierP4w9Y3F+XLl3UbeDzuD4Rkau9+XslsyhTrQLqaVgxtGV4S9mcsVlS8lI8fvtEdADfniMi07WBTpyIpe5Fzj5b5OWXRZYs0RYx2LJF+/ytt2qVbYsXizz1lMhzzxm62UT2gKDmscd8f7933SUSEuLWVVFVdP7556uQ6u67765umUGoVlFRoQI1hFIIkhB8IVz59ddf5bzzzpOePXuqsKQhlZWVcuqpp0rbtm1lyZIlkpOTU2Memw6hDbYDoQnCscsuu0x9DGHLmWeeKevWrZM//vhDZs2aJXl5edKpU6eDbqOgoECmTJkiY8eOVe2oaWlpcumll8q1115bIzz8559/VMCD823btqnbR5sp7rM255xzjgwbNkyFWQj2EBo5HA71OYRypaWlMm/ePBVybdiwQaKiag7Kxr599tlnVYh55ZVXysUXX6wq0dyFkBBwPzoETQifEGDiOKJ1F8fypZdeqg6/9Hbc+++/3+3j4Gz37t0qiEPwhVZUHH9sN0KxW265RTZu3Ci5ubmqug4QiqWkpBx0G9OmTVOB5kcffSSbNm1S+xnhHh6DDiHdTTfdpLYN94F9hDATx/Pbb7+V559/Xr744gsVXO7Zs0eFnUREzsoqyiQhO0HCg8MlKDDIK/eBhRBKyktk/b71EuGIkBbhLbxyP0T+jsEaEZmG3gZ6zDHaOf5mfuYZkQkTRN5+G3/wah+7+GKRsWNFMGrpjTdEHnpIxOXvQiKyKQQYTz/9tKoqQoACCEpOO+00Nd8LJ4Qouuuuu05mzpwpX331lVvB2l9//aXCFHwNQjN47LHHDpqLds8999SoeMN9IkhBsIZgCWEVAiRUcaHySw+bnH322WdSXFysAhyEXPDKK6+oirInn3xShUqA6jJ8HCFZv3795LjjjlNVZXUFa4mJiXLrrbeq60Lv3r1rfA77CpV8gEoxV6gom4h3OERUtRbuD9uJcKkhGPSOfYNt1W8Dzj77bLnoootqHEfc9gUXXFC9HQ8//LDafwjW3D0Ozl599VV1/HEc9CARVYU6HIOSkhJ1TOry2muvqblr2N8IbrEPEb4hqL3vvvskMFBr9kDLMbYTENq+/PLLKsxDsIZ9jPs46qij1Hagcs2d7z0i8i9pBWmSXpiuFhvwppYRLVXF2qb0TTKiwwgJCXLvzSwich+DNSIyBcxMmztXuzxlyoGPjx8vglnTeucUwrQuXTBwWjslJYmgw2n/39dE1FQIIlA9ZsT9NgKCDrQnvvfeeypYQwUXqp8eQsIuoirXEMAgSEP1EaqmEKa4O0MNVU0IVvQwB1BR5urLL79U1VaotEKVHKqiUCHVGLivIUOGVIdqgMH/qNZC+6UerKHqCUGVDtVrqJKrCyqpUPn28ccfq3Bn+vTpKvwBtCReddVVqpIOn0PI5jqXzvnfuC9ANR0CorqgWhDbiBZQVLq9++67NW4HraXOUMGFSi+9LVQ/dgjwEM65exycoTIP1W96qNYUuF/cj/MAcRwTHGPM9tP3ges+w7HCPgLsb1TmISzEYhuogENYyjluRKQrryxX1WqYq4Z5aN7WNrKtJOclq5lr/Vppb7oQkedwxhoRmSJU+/hj7bxjR5FDDqn5+SefRAuYdlkv0MDfPGPGaJfREkpEdUNIgBlVONW54hg+jpZMX5+asAIaZqmh3Q4tlqhWQ2ikV0ehmu3FF19UFUZonUTYgioi57bE5lq0aJFqt0Rg8ssvv8jKlStV+6Qn78OZa1CEY4jwrS5oWcSsMVSaoYoKx/17DKkUUYEbFhVAeyzCOQReqLaq6/7075f67g/Q+oh9jbZHnPRKNJ1zeAgIqjBTDV+jn7A9mKvmTmVcbWqrCvSW+o4JAkEEo6h+wzZdffXVqkXVU4s2kEmeM4maAZVq6UXpXpmtVhu0mmLe2vbM7apSjog8i8EaERkGf4NceSWGXovsH62j2kBdX8Oik+fDD0XuvVfkxBMPfFwP1jCDjYjqhmotBC04+Wr1S28644wzVEseWinRRom2Qv2PX1RBnXTSSXLuueeqajBUDW3RBzS6oX///pKUlKRWuNQtdknvFy5cKF27dlVhGoIptFpiUQBnISEhqgKroftC5RZmremw/Xhsffv2leZAC+SNN96oKtMwq0yfK6YHP5id9t1338nNN98sb6PXvpnQ+tirVy9VreYOLFqA8Alf43rC43fnOLhCFRmqF+sKsNw9JghOnVfQwzHB/Lza5uTVBYEaqtRQ1YhFEnCb9VUZkrnY7TmTzGdP/h4JqArwSbWa87w12Jy+Wc1dIyLPYbBGRIZ55x2RN98UKSlBG43IjBlaeFYbLGSATi+nbigZPVo7x99aXEWcyH9gfhkG+N95550qeMGgeR1CLqweifALbX1XXHGF7N271+3bRnskQilUXCH0QlCDAM0Z7gNztDDLC62gCE/0ijDnuWs7d+5UlVhYqRTtqK5Q9YbqLNwXFjtAhR1mwqGaTG8DbSy0YmLxA4Q5CPsQCmFhBARGgAUAMLcM27ZixQp1n/rnfAnzyhCKomoN4QWOFfanPrvOnePgCo8bixPMmDFDrYKK6je0w+qrmuKYrFmzRv07PT291gAO1WUI9HAcMOMNq4hilhraa/X5ag3BwhNohcUxRXXgJ598ooI2hLFERIVlhapqLDYs1uf33Sayjewr3Cc7s3f6/L6J7IzBGhEZAkUIt92mXcbKnvj355+LdO/u/m0MH661iO7Zg4HcXttUIjIhtINmZWWpNk/nOVwIZlANhY9jBhsqqU7GoEY3ITxBSIaACgPn0TrpPAcMTjzxRFUNhiAHq3MixLvX5V0BzC7DfK0jjzxSVWF9jic4F6iEQciVmZkpI0eOlNNPP11dH4PzmwpzzhDkYcVNBFOo7sPAfwRYgIotrAyKMA3bh+ugZdHXcHzQRouKOjz2MWPGqHZSPXxy5zi4atmypWp9RZspWoOxOiyq8fS2TSz2gEpAVBmisq62lU47duwov/32myxdulRVPKKyD99rzotVNCQuLk7dL2azoYoOCzH8/PPPavuIiDKLMqWgtEAiHTVb5H0hMCCwuiUU7ahE5BkBVc617n4K725iFSks5d7YwcNmhHdg8aIQs1+aM8CXzM3qx/n000W+/RYDrbWKM+dKtMYYOVJbvOCLL0TOPFNsxerHmMxzjDEMHuEFoHoJoQUqlrp3797keVbkHszdwusMvL5wt+KJrMVfjjEWlvCX5w3X50w8P/P3sb356vcx/vRelrJMVay1i6p7hWJvwyqhrSJayaEdDhVHkH98T/N1tf2VefgYNyYnMvS3/7x589T8CbzTjNkoP+jL/u2Hj9V2wmBiHcr6XT//xBNPGPBoiMhdv/yihWoI09AO2tRQzbkdlHPWiOp/Ib9hwwZ14vtpRET143MmeUt+ab6qFIsN9X0bqGtLaGp+quzKrjkflIiaxtBgDcN6UWb/6quv1vp5zE1xPr333nsqOEN7hbOHHnqoxvUwF4OIzOujj7Rz/KgOGdK82+LKoERERERkBRlFGVJUXiThDt+tYlwbLJoQFxon27O3S05xjqHbQmQHvluGpBaY+YFTXTAXxRkGyE6ePFmt8OUMKzW5XpfIX2E+9vnnazPL/vgDM3zEdPTqMucVPpsbrK1YoT320NDm3yYRERERkSeh+hEtmBHB5nhxjsUTknOTZXvWdhnabqiav0ZEFgzWGgMrev3666/y4YcfHvQ5tH4+/PDD0qVLFzn77LPVQOFgTDSvA1bmcl6dC72zek9uXUu0W4n+GOzwWKhxx7miAqtnBsn332u/GL/9tlxmzDBXC0NKChYacEhgYJUMGVIuzf027dIFA6uDJSMjQJYvL5eRI831eJuDP8v256tj7Hz7uIyZUHiBj3OcyHv0NjJ9f5P9+Msx1p838ByCRTLszPU5Ex0zrh8ne/HF7+O80jzJLsiW6NBoqawwx3NFq7BWkpSZJK1CW0n76PZiZ3xdbX9lHj7GjbkdywRrCNRQmXbqqafW+Pj111+vVv+Kj49Xq3Ldeeedqh30ueeeq/O2Hn/88erVsZxhZSqs0GUXf/75p9GbQD48znhd//rrQ2TWrG7Vn3v55X0SE7NUzGTxYvzSHiVduuTK/PlzPHKb3bqNloyMdvL++xtl374dYjf8WbY/bx9jDB3XYRXKqKgoVemN1RNLS0u9et+kycvLM3oTyMvsfozxXIFVWjEjuby8XOzM9TlTX6yBv4/tzxfHOFMyxWxWblsp+M8f8OfY/v700DHGQjaWWxUU7wRhWfWTTz651s/369dPjj76aHn55ZfrvR3MYbviiivUHwuhdfSE1Vax1rlzZ0lPT7fNqqD4ZsL+4oon9uV6nD/+OEAuuSRYAgKq5L77KuXBB4PE4aiSpKRyiY8/8HU7dohcdVWQXH55pZx2mu9//O+8M1CefTZILr20Ql57zTPv1j36aKB6vNOnV8qnn1aIXfBn2f58dYwx07RFixbqclZWlqo2SUpKUgsA2X11P6PhZRYCF7w5qFe9kL34yzFG2JSQkKBeM9v9ecP1OTMkJIS/j23OF7+PV+9ZLXvy90jbqLZiJpVVlbI7d7cMbDNQurfoLnbF19X2V+bhY4ycqFWrVm6tCmqJirX58+fL5s2b5csvv2zwuqNHj1bvouEXf9++fWu9DgK32kI37Hw7/ZDZ7fFQ/cd51izt37ffHiAPPBAk330nsnZtgPz8s0MuvfTA9W+9VeSff0SWLw+UyZNF2vr4d/uyZdr52LEI/jzTSnLEESIoQp07N1CCgwPFbn/X8GfZ/rx9jPFHYdeuXasvBwbi5yRAneNE3qO3Bur7m+zHX46x/rzhD7+TXJ8z9cfrD4/d33nrGBeVFUlWaZZEh0dLYJC5nicCJVBiI2IlKT9JOrXoJBEO+3Rw1YY/x/bn8NAxbsxtmOunug7vvvuujBgxQq0g2pBVq1apX/xt2rTxybYRmcXS/R2fRx2lnZ91lnb++ecHrrNggcjPP2uXMVrwjjt8u43oHPnvv5qLDnjC6NEi4eEiaWkiGzZ47naJ7AJjDvCGE052GnlAROQNfM4kT8spyZGCsgLThlaxobFqG1NyU4zeFCJLMjRYQ7smgjCcYOfOnepyYmJijfK7r7/+Wi51LrnZb9GiRfLCCy/I6tWrZceOHfLpp5+qhQvOPffc6vJtIn+wbx9+frTLI0Zo5zNmaOeoTsMKoWj61oO0CRO08w8+wMwz323nunXoVRdBJW2/fp67XRSgjh+vXZ4923O3S+SXMHMNP6i+OHG+GxER+YHMwkytqtWkK29i2+JC42Rn9k4pKC0wenOILMfQVtBly5bJZPSi7XfTTTep8wsuuEA+wF/8IvLFF1+o2RVn6eU3TtDOic8/8MADamZa9+7dVbCm3w6Rv9DbK9H9HBenXe7eXasKQ3CGXHroUJF//xXBWBRUsd1zjxasXXedyJIlaPHw/nbifvQKM0/fH9pBMacSwRoeExE1AYIulL/m5/vm/qKiREaNQq+Vb+7P4vB65/XXX5e0tDQ1l/aHH36Q7OxsdV6XSZMmydChQ9UbkeRdRxxxBPc1ER2kvLJc9hbslShHlJhZTGiMJOYmSmJOovRv3d/ozSGyFEMjc7zYQ2jmetJDNbj88svVagyxsbEHfT1WA128eLF6UYlVijZs2KBWBa1r0QIiu7eBjhxZ8+MXXqid//abyGOPaZevv16kY0eRJ57QKscQys3xzOKcDdKr4xCseRqCNcBjqbDP+gVEHoHfkSNHjlQnXK63XxuhGoKu6GjvnnAfuK9Gri6IIfE33HCDmn8UHh4uhx12mPyn95jvh9cS9913n7Rv315d56ijjpKtW7dWfx5vxp133nlqEG2fPn3kr7/+qvH1Tz/9tFznZkKPyvq7775bLbKEge5YbRX3991336nt8JSNGzeqFc3ffPNNtfr51KlT5cUXX6zxmsnKUC1RX0DoCo87Tn8nicio50wiN+QU50heaZ5EhUSZ/nm4ZXhLVbWWUZhh9OYQWYolFi8govrpf1Oi8MPZZZeJdOumVXHNm6f9Hau3g2LRgqlTRbAmCCrJ9GDKF8GaJ+er6YYP14LC7GzMWjzQEktE2nB1VInrl7EqaL3wBpUvVv1rQisoRkOsW7dOPv74Y+nQoYN88sknKsjCm2sd8a6BiDz11FPy0ksvyYcffqiq2e+9916ZMmWKug7Cr7feekuWL1+uRkr8/vvvcvbZZ8vevXvVHxUYS/H2229X76/64I298ePHq9WiHnnkEfVHeHBwsMydO1duu+02VcHkqdXGt2/frs5POumk6pUn+UZi81VUVNh+0QFq/nMmUXPkluRKRWWFBAea/09vhH/Y3m2Z2yQ2LNYS20xkBnwVQWRxKIioq2INfydMmSLy5JOYSYhVM0Wcxw/q13cp9vAKBF6bNnmvYi04WGTiRO0y56wR2RMqR7799lsVnB1++OHSq1cv1R6Jc7RIAqrE0Ip3zz33qBBq8ODB8tFHH0lKSkp1RRSqv0488UQZMGCAXHPNNbJv3z5JT09Xn7vqqqvkySefdCsQu+uuu9Rw8yVLlqgxFocccoiqgLvsssvUzNgotLruD+Dwecx/xSB0VJs5V9Dp1VczZ86U/v37q6879thjVWUa4DGecMIJNVZmhAsvvFBOPvnk6tspKCiQ888/X309qvWeffbZg7YZ1Xq33HKLCiEjIyPVaupznMqWG9oW3Xvvvaf2H8I93Ne1115b/Tk8XgSgrVu3VvsRASPm4boL+xSPEVV/GBmCfYYFrBCEArb3oosuUoEmrocT9lFjHt9PP/2kjhe2/5133lGBK7bb2f/+9z+17ZCRkaHGkuB2sT2DBg2Sz51XByIiqkN6YbqEBlnnjZA2kW0kJS9FdufuNnpTiCyDwRqRxWGtDyxegGAJc9Qaw5fBmv43FSroWrXyzn3oVXcM1ojsqby8XFUYIQRxhnbPfzFEcv9CSHv27FFVbDqMk0DAogczCGlwfQR1CJAQDLVq1UotgoTbPuWUUxrcFlSxYM7rOeecoyrnXCGQQvUaXH311apCDmEOtgHh37Rp06SsrKz6+hh78cwzz6hKvHnz5qmFnBAQAc7ff/99dRkBl2vIpbv11ltVtdyPP/4os2bNUoHSihUralwHARi2Adu+Zs0amT59ugrOnIO++rYFEGIikMS4jrVr16rHhXBTh9vEHDhUA+JxY3THkUceKZmZmdIYaLHF/SKkRGCJYAvfA2j/RXiK0E7fH/r2ufv4EJ4iUFu/fr06hgjbENrq8H325Zdfqs9BcXGxWqH+119/VRWTeOxoJ16qv7NFRFSLkvIS1QoaGRIpVoEqteiQaNmasVXyS300c5XI4ljbSWRx//2nVS4MHtz4zi20T6LwITlZZM8ekXbtxGvWrtXOBw3y3n3owRraXtFhxnnoRPYSHR0tY8eOlYcfflhVU7Vt21ZVDSFI0YMdhGqAzznDv/XPXXzxxSp0QcUSArWvvvpKsrKy1Fw2hFGodkMw07NnT1WZpbeYOkOFG74Gs9Xqg0AHAdP8+fNV2yggwOvcubOqoEPwAwjZ3njjDXWfekD00EMPVYd0+jwxzHCra6X1d999V7XGIsQCtMJ26tSp+joIyBDQ4VwPAxFI/fHHH+rjj+0fxlnftgDaXm+++WZV0aVDGywgsETYhGBNb1VFSIfH+s0336hAyl3YtuOOO05dxnw5VMht27ZN7XOEpahUc94fjXl8r732mgpYdTNmzJDPPvtMLrnkEvXvv//+W1WwnXbaaerf+B5wDhcxgw+hLL53Dj30ULcfExH5F8xWKygvkPah7cVKWoS3UIsY7MjaIYPaDKqulCai2jFYI7K4ZcsCam0DdQe6lPr3F9mwQata299p5BXr1nk/WBs4UGt1zcrS7g/BIRHZC6qoEIwh6MCsOFRDoZIJlVHucjgc8uqrr9b4GFoLr7/+elm5cqUKgdC6iJZTfMy5kknn7sIEaDtF5Roq5nQtW7aUvn37qs/p0F6oB1mAKjqEU42ZwVZaWlrjfuLj49X96FBdhkosVH85Q/sktsmdbcE52mr18M4V9htCPufbA1QH6nPi3IU2Xudt0O+/rjDT3ccXEhJS47YBlWljxoxRjw2hHMJPhHp6oInbRTCHIG337t1qX+N2sa+IiOqCii812zSwgdmmJm0J3ZW9S9pGtpW2UTXfrCKimhisEdkkWHNduMBdCOR8EazpFWsIv7wFM+WGDdNaQbGAAYM1IvtB4IN2R8wTw4qcCFzOPPNM6dGjh/q8XsGExQj0MEb/99A6+uX/+ecf1RKI1kC0U6JNE/O5zjjjDHnllVdq/RrMD0PoskkfHtlMCPucoTrAk6uKAgIvhJEIIV0XsNDnwTW0LWi7beg+sN+d55rpGruKp/N26NUS9Q2Sd/fx4TG4Vl+g4g7fW6hUxJy977//vsaKq1gpFquwogUV89Xw/YHVaRGwERHZZb6as7DgMAkMCFQLGcSHx4sjqObvBiI6gDPWiCwMf1+sXKn9cdDUThRfzFnD32O+qFgD/e9mBGtEdABaHnGyCwQbCHDQjomWPCxUAFgFFOEaWvl0COCwwADaSF1hdhbmhb355psqjEFlkj77DOf4d22wiADaB1HZhCqn2kIezANDyyrOcf86DMLfvHmzakX1FIRCCKKc7wf7ZsuWLdX/HjZsmHo8qPpC66zzqa4W09racbt161Zj/zpDBSFablGl53ofnvz+Q9WZ67Fp7uND1RqO588//6yOr96GCgsWLFDfY+eee65qIUWQ67xvyX7s9pxJxsxXyy7KlgiHdStbW0e0lr0Fe1VbKBHVjcEakYXt3RsheXkBapYYWjqbG6x5uDiiWlIS/rDVFlhw6dDxOFSsAYM1opohFFa+xAmXG1RSgsTJuyfcRxMgRMPMLCxS8Oeff6pVI9EaiFZOQCUSKokwBwxD9dEeiJUy0d7nvIKmDvPaUKGGUAbGjRunVqPEDDZUq+HfdXn00UfVrDS0X2Ll0Q0bNqiZapjLhttDuNa7d291+1dccYWaP4ZWSYQzaGXVw0BPQEUW5oOh4m727NlqwD5WDUVApEOLJMIj7A88RuxDzEN7/PHH1VB+d2EFTqw4+tJLL6nHiwUSXn75ZfU5LBqBABP7GgsoYIXPhQsXqoUIli1b5rHHi3AP+xcBH+bdYUGC5j4+fC0eC47r6aefXj0jDnAc8f2Gx4IWXhxPVEGSPTX6OZOojjZQzFezcrCGFtbY0Fg1a40LGRDVja2gRBaWkBCrzgcMQMtM024Ds5vxtRkZuD1Ue4jH6dVqGIvj7QUFnCvWUNHn9DclETUE6Tda5vLztRVAvA33tX/lTHfl5OTInXfeKcnJyWqGGIbLIwhxbhu87bbbVKsoBuVjAD0WDUAY57qaKMInzMzCqpM6BCpoY5wwYYKaT4aB9nXB/S9evFieeOIJFeTt2rVLWrRooVoF0TqIAftoocQ8t3vvvVeOP/541Tp4+OGHy2+//XZQy2Vz4T4RNp1wwgmqsgwLDGB/OcMQf33xAcwKQ0UOZoth29x1wQUXqEq/559/Xg30x21gv+nBJh4bgjSEnQgmUC2Gx+y6oERzYGXQK6+8UrUBowLw/vvvV4Ffcx4fKttGjRqlwji0fDrDghY7duyQKVOmqLlq+N5CeOi6f4mInBcuwO8AK85XcxYXFqcq1nZm7ZRBbb3cekJkUQFVnh7gYUFoEcGLX7w4wtLtVofWFbyoxTvknn7RTuY6zuedt12+/LKfXHgh/lhq+m2hjRRzv7/6SmT/AnUe9eSTInfcgVXXRD7/XLwKHVzR0VoxzLZtaI8Sy+LPsv0ZdYwRiqCaB22TrmGTCtTKy32zIQjVbL58L2aC4XUGXl84V4+RffjLMa73ecPm+PvY/rxxjJelLJO0/DRbDP4vLCuU3JJcGdNpjLSMqLk4jVXw59j+yjx8jBuTE9n3tz+RH9i5M7a66qw5vD1nzVfz1QDPofoCCWwHJTqwIuOkSZPUCZfrhaALKx364mTzUI2I/OA5k8im89Wc4XFUVFWoltDKqroXkSHyVwzWiCwsISHGo8Ha0qVi2RVBnXEBA6KDK2qwkiZO9a2qSEREfM4kz7SBFpRZe76aqzYRbSQlL0XSCtKM3hQi02GwRmRRGOuSlhbpkWBt9OgDFWue7gDD7W3c6LuKNWCwRkRERERGQdskKrusPl/NmSPIIcGBwWrWWkVl7StmE/krBmtEFrV2bYA679SpSuLjm3dbWFE0Lk6ksFBk9WrxqK1btZFNWFSra1fxCQZrRERERGQUzFYLDw4Xu2kV0UpVrLFqjagmBmtEFrVmjRasDR7c/PVHMGt57Fjt8sKF4pX5amgD9dVM58GDtfPkZJH0dN/cJxERERERBv3nlObYqg1Uh4o1R6BDErITWLVG5ITBGpHFg7VBgzyzsO9hh2nnCxaIpeerARZt6dVLu+zpCjwiIiIiorrkleRJUVmRLYM1wKqgqFjbW7DX6E0hMg0Ga0QWtWaNeKxiDcaN807F2sqVNavIfIXtoERERETka9nF2RKA/wK0N8HthlVrRAdjsEZkQRUVIuvXe64VFEaNEgkKEklK0k6eUFUlsmiRdnnMGDEkWNODPSJ/FxERoU5ERNQwPmdSU1RVValqrvrmq2FRg3Vp6yQxJ1GsXLW2r2AfZ60R7ResXyAi68CCAEVFARISUl7d8thcWFwAYdTy5Vo76IwZntnOjAyRsLADQZevDBignW/e7Nv7JTKjyMhIKSgoqP53cXGxodtDRGSl58yysjJDt4esI780X51iQmNq/fym9E3y1IKnZE2a1nrSr1U/mdZrmpwx4AxVCWYV2FacULXWJrKNrVY/JWoKVqwRWZA+N6xr1zxVZeYp+pw1T7WD6tVqI0aIhISIT/Xpo51v2aJVzhERkXddeOGFcvLJJ1f/e9KkSXLDDTc06zY9cRtERL6SV5onJRUlEhYcdtDnPl7zsZz3/XkqVAsNCpWggCAVtD23+Dm5f879qpLNSlqGa7PW9hXuM3pTiAzHYI3IgmbN0s579sz26O3qc9Y8tYCBHtDpK476Us+eIhhtkZsrksYqdSJbhTeYW+N62rZtm1tf729BjfP+CgkJkV69eslDDz0k5eXlXr/v7777Th5++GG3rjtnzhy1jdnZ2U2+DSIio9U1c2xb5jZ5ZekrUiVVckzPY+T7M7+XP875Q24ac5MK2GZunynPLnpWtZJahSPIoarWdmXvslwoSORpDNaILAZB0RdfaJcnTEj26G3rFWuoiMvP91zFmhHBWmioSLduB6rWiPwZWj+PO+44dbJDG+ixxx4rqampNU7du3f36TaUlpaK1fbX1q1b5eabb5YHHnhAnn76aa8/rvj4eImOjjb8Noj8/TmTjIWw7MkFT0pFVYVM7jZZHjviMdU+2SK8hZw96Gx5cNKD6npfrv9SPlj9gVhJfHi8Wh00vTDd6E0hMhSDNSKLQahWWIhWxyo55JBMj952587aCYsjNLcdFAHgunXGBWuu7aBE/qyiokJ+++03dcLlul74F5QW+PzUlHfnQ0NDpV27djVOQUFBB7UiAqrTUKUG+PzcuXPlxRdfrK7iSkhIkA8++EDi4uJqfN0PP/xQY0U3hFFDhw6Vd955R4V4YRgeidXfsrPl0ksvldatW0tMTIwcccQRslrv168juLr22mulffv26ja6du0qjz/+ePUxwP106dJFPcYOHTrI9ddfX/213bp1k8cee0wuvvhiFTbhem+99Zbb+wv3ddVVV8lRRx0lP/30U/U+wT579NFH1f317dtXfTwpKUnOOOMMtV8Qbp100klqX+nwfXTTTTepz7ds2VJuu+22g46la3VgSUmJ3H777dK5c2e1Taiee/fdd9XtTp48WV2nRYsWar9ju2q7jaysLDn//PPV9TBYfurUqSow1OnHcubMmdK/f3+JioqqDhadq+NGjRql5mjhuuPGjZNdu3Y1uB/Jf7jznEnkrl+3/ior96xU7aE3j735oM8f2+tYuWXsLeryG8veUBVgVhESFKJWQE3KSbJUtR2Rp1lnQiIRKW+/rZ1ffHGlanX0tKlTRfB32mefiRxzTNNvZ+lSbbYZqsbatxfDgrWZMxmsEbmjsKxQoh6P8vn95t+ZL5EhkT65LwRqW7ZskYEDB6p2SEAg5i60m3777beqPRFBHkyfPl3Cw8Pl999/l9jYWHnzzTflyCOPVPeDQMrVSy+9pEKtr776SgVjCLBwAtz2888/L1988YUMGDBA9uzZc1BI9+yzz6rWyLvuuku++eYbFZRNnDixOhBzB7Y3AyvL7Pf333+rUPDPP/+sHtQ+ZcoUGTt2rMyfP1+Cg4PlkUceUQHVmjVrVEsptgMh1nvvvacCLPz7+++/V8FiXRCILVq0SO2DIUOGyM6dOyU9PV0FbXjsp512mmzevFltC7axNgjcEKRhH+J6COqmTZsmGzZsEIfDoa5TWFgozzzzjHz88ccSGBgo5557rtxyyy3y6aefqhZYBImXXXaZfP755yroXLp0aY0QlYjIU/JK8uTFJS+qy5cOu1TaRbWr9XozBs6QJbuXyPzE+fLqslflqaOeEitVre3J3yPZxdmqCo/IHzFYI7KQVatEli0Twd8O551XKf/95/n7QJEAgrVvvhF55RWRqCjrzVfTsWKNyJ5++eUXVYmkQ9XS119/3eDXIfhCKIRKJ1RwNRZCmI8++qg6jPv3339VKJOWlqYqsACBDqrdEHpdfvnlB91GYmKi9O7dW8aPH6/CHFSROX8O24WKMoRECN5QWeUMIdLVV1+tLiNUQhD3zz//uBWsoZoAIRqqua677rrqj6NyC5V42DfwySefSGVlpfqYHji9//77qroL1V7HHHOMvPDCC3LnnXfKqaeeqj7/xhtvqNutC4JGhIkI7/D4oEePHtWf10PINm3aHFQ9qNMDtQULFshh+2cXICxDMId9jpBTDwaxPT0xbFNEVQjqQWpubq7k5OTI8ccfX/15BINERN7w85afJas4S7rFdZNzBp1T73WvHXmtLEhaILN3zpa1e9fKoLaDxApQiVdWUSbJuckM1shvMVgjMrm8PK39E39D7u/cEXQ6NaLIolHGjNECKYRR+Dv1oousN19Nx2CNyH0RjghVPWbE/TYW2gZff/31GsGQLyAEc65wQzVZfn6+aoV0VlRUJNu3b6+z4uroo49WQRgqwBDwIKgCBEMIrBA44XMI0U444QRVMaYbPHhw9WWEXgjiEOy5E0QicEJgdvbZZ6uWU92gQYOqQzX9caE6z3W2GWZN4XEhmEJr5ejRo6s/h2089NBD62wFWrVqlaryQ3VdU23cuFHdj/P9Yt9jX+JzOgSnemgGaLvV9xECPBwDVOThOCDkQ8srrkNE5Gl/7tAqgacfMl0N+69Pz/iecnzv4+WnLT/JS0tfkreOf8sy1bQI1FLyUlSAGB3KuZjkfxisEZncs8+KPKjNNK122WXeuz/8/kbV2l13YVZN04K1ykqRxYvNE6xhsUCMSNnfuUVEtcCLd1+1ZDYXgjTM53KFtj/XYAdhUkPc/TrXAA+hGgIZVHG5qqvqavjw4aoFEq2jf/31lwp1EO6gwg2VV2iFxMdR2YXKNCwygLlwepujfu583BCWuRNEIjzDHDXnoK6uxzVixAhVDeaqMa2zzupq7fSG2vaR8/FF9R1m1/3xxx/y5Zdfyj333KP29xi8s0RE5CGpeamyNm2tmkF2ZPcj3fqaK0ZcoVYIxUy2RcmL5LDO+1cWM7mokCjJLMpULaEM1sgfcfECIpPT2z3xN2SXLlq12pHu/W5usvPO0wK2efNE6ii6qBcKB7Kz8YeUyJAhYhgsxIDuLCxyl5ho3HYQkW8g9HEeUq9XSjlDuOQ6jBxfl5eXJwUFBXV+XV0hGeagIahC0Od8atWqVZ1fh9lgZ555prz99tsq2MF8sczMzOoAClVqmEOGwA4zydauXSueCCLRWuoaqtX1uNB2ibZM18eFdlqcECguWbKk+mswu2z58uV13iaq4hAAIiSsjV4xV9+geLRs4n6c7xez4hBGHnLIIdIYw4YNU62sCxcuVDP3PsNgUSIiL1SrDW8/XFpF1P07wVnbqLZy+iGnq8vvrXxPrCQmNEYScxKlpLzE6E0h8jkGa0Qmp6+s+f77Ili07PvvUV3h3fvs1Enk6KO1y6haa6zZsw9Uq7kUDvgUKtT0oha2gxLZHwbnL1u2TM1BQzB0//33yzr9SdRpZU0EM1iJEoPzEfagtRDtg1gQAK2OCFkwmL8hqDTDgH8Mw581a5a6TQQ1d999t9qO2jz33HNqaP6mTZvU3DHMhkM7JyrccJ9YJRPbvGPHDjXrDEGb8xw2XzjnnHNUMIiVQLF4ASrsEPKhyis5OVld53//+5888cQTarYZHguq67BCal2w3y+44AK1oim+Rr9NzF0DPEZUlqFtdd++fapqzhVm02GbsPAA5tuhZRULE3Ts2FF93B24XwRqCCyxEiiOG75XOGeNiLwVrB3dY/+LajedO+hccQQ6ZNXeVbIydaVYKVjLLcmVfYX7jN4UIp9jsEZkYrm5ByqtBgzw7X2jHRQefVTk7LO1KjR3/fWXdq6Hc0binDUirWIJrXA4+WoemREwN+vee++V2267TUaOHKmq0LASpTOsDolZX6hwQqUaFgzA3C2EWL/99puqrELw5TyDrC4IgvA1hx9+uFx00UXSp08fmTFjhgps2rZtW+vXYG7ZU089peaRYRsRxuE20I6KcA1VbOPGjVOz1NAS+vPPPx80w83bEDLOmzdPVbhhcQKETpdccomasYZqO7j55pvlvPPOU2EZwkU8rlNOOaXe20U76umnn65CuH79+qmATK8SRDj24IMPyh133KH2HRYcqA3aONGmitl0uF98T2P/ubZ/1vfYEARiBVIcLywwcc0118gVV1zR6P1E9uUvz5nkPUk5SbIxfaMEBQS53Qaqax3ZWk7oc4K6/N4q61StBQYESmhQqHrslVX1jyggspuAqrqmzPoRrBCFtgYM49VfMFoZ5sLgRSaGHrv7QpPMCQsAYOGzjh1F9hcJ+Ow4Y7wQ5qvpI3bQpYO2VKe52bUqL8dwaG3RBVz/0EPFUHfcIfLkk1gVTuTll8VS+LNsf0YdYwQkqNzp3r27hIWF+ex+/REq4vA6A68vEJ6R/fjLMfbn5w3+PrY/Tx1jhErLU5fLn9v/lNeWvSajO46WV6e92ujb2Z27W0796lSpqKqQj07+SA5p3bh2d6OUVpRKemG6jO081u32V1/hz7H9lXn4GDcmJ7Lvb38iG9DH6gwc6Pv7xnPRJ5+IrFyJeTvanLIff2z465Yu1UI1hGvDhonhWLFGRERERF6Dd6NTUrTz/WYnzG5SG6iuY0xHmdJzirr8/qr3xSpCgkJUtRoWbiDyJwzWiExMHw00aJBx2zB0qMi552qX3ZjlXd0GesQR5liFk8EakVZpMn36dHXCZSIiqhufM6lREKhh4Zz9wVpBaYFsTt+sLo/vMr7JN3vBkAvU+dxdc2Vv/l6xiriwOEnJT1H7gchfMFgjskCwZkTFmmu4BqheczdYO+ooMQU9WMPCD3xtTP4KKy1+88036lTfqotERMTnTGqeDekbpEqqpEtsl2a1Q/aM76lWFEUF2A+bfxCriAqJUqEaFzEgf8JgjcjEzBas7dwpUs+ib6oFFHPhzLJwAbRuLRIbK4Jpktu2Gb01RERERGRnG/ZtUOfD2w1v9m2d1v80df7Dph+kvLJcrCLKESW7sndZapuJmoPBGpFJpaWJ7NuHVedE+vc3dltatBDp2lW7vGZN3debN09bvKB7d5EePcQUsP969dIub99u9NYQERERkZ1tSNOCtWHtmz9seHK3ydIirIWq/pq/a75YRWxYrGQXZ0tGYYbRm0LkEwzWiExerdazp0hEhNFbc6Bqrb45a2ZrA9VhHwKDNSIiIiLyFrRAbsvSWiRGtB/hkcUATup7krr87cZvxSqCA4MlMCBQUvJSjN4UIp9gsEZkUmZpA21MsLZ8uXY+YYKYCoM1IiIiIvK25anL1Uy09lHtpV1UO4/c5in9TpEACZDFuxdLcm6yWAUq7fbk75HcklyjN4XI6xisEZnU2rXWC9b0lTeNbl11pbeCcsYaEREREXnL0t1L1fmwds1vA9V1jOkoYzuNVZd/3PyjWEW4I1yKy4sttaIpUVMFN/kricgnFWuDBompgrX160VKS0VCQmp+PjdXZO/+35u9e4upsGKNyH2lFaU+GzaMVhG0uRAREdnBkt1L1DlW8/Skk/udLAuTF8pPm3+SK0ZcoX5/WkF0SLQk5SZJt7hu4ghyGL05RF5jjZ9IIj+DFSzN1gqKxQuwumZOjsjGjSJDhtT8/Nat2nnbttr1zBis7dolUlYm4uDvdfIzERERkp+fX325pKSkzlBtafJSyS/TruuLVcNGdRrFcM1P7NmzR8477zxZuHChOBwOyc7OloCAAPn+++/l5JNPrvVrEhISpHv37rJy5UoZqr/DQ17BfV33c2Y5VmYiagCqs1btWeWVYG1ClwkSHx4vGUUZsiBpgUzsOlGsICY0RlLzUyW9MF3aR7c3enOIvIatoEQmlJIigtdzQUHmqf7C6pr1tYPqbaBm2V5nHTqIhIZqK5YmJhq9NUS+h/AiMjJSnXC5LqhUQ6gWEhii3mX25gn3gftqbHXchRdeqB6D62mbm73ekyZNkhtuuEGMtGLFCjn66KMlLi5OWrZsKZdffnn1H/G6xMREOe6449Qf9W3atJFbb721xh/3CD+GDRsmUVFRcsIJJ0hmZmb153C9ESNGyNKlWktSQ3Bb06dPl7Zt20pYWJj07t1bLrvsMtmiP7F7yPPPPy+pqamyatWq6tvGv6dOnSpW99lnn0l8fHyjvsYM34vUvOdMImdLU5dJSUWJmi3WOaazR28b1V7H9T5OXf5h0w9iFUGBQWoRA8xaI7IzBmtEJpSaeqD6y0zVVe4Ea336iOkEBrIdlKgxQoNDJSw4zKsn3EdTHXvssSqQcT6h0saXStET3wQpKSly1FFHSa9evWTJkiXyxx9/yPr161VgqKuoqFChGu4D1V0ffvihfPDBB3LfffdVX+fSSy+VI444QoV0OTk58thjj1V/7tlnn5Vx48bJqFGjGtyeX375RcaMGaOqGD/99FPZuHGjfPLJJxIbGyv33nuveNL27dtV4IfgDmEhtGvXTkLxzgf5/HuRiDxrXvICdX5I60O8Esjqq4OiYi2tIE2sIi4sTvYW7JW8kjyjN4XIaxisEZmQPqusnWcWE/KYYcOsGawBgzXyZwhNENzgVFcbqJUgiEEg43wKCgpSj8+1pRAVQagMAnx+7ty58uKLL1ZXuqH9DaEVqsec/fDDDzX+MHrggQdUe9w777yjQjxUdgHaGRFytW7dWmJiYlTYtXr16nqDLLRBvvrqq9K3b18ZOXKkvPHGG/Ltt99WV93NmjVLNmzYoAIu3Ccquh5++GH1NXqIggAMVWV9+vSRs846S/0bduzYIe+++648+uijDe7HwsJCueiii2TatGny008/qcAPj2306NHyzDPPyJtvvll9Xew3BHXY9+3bt5c77rijRgUd9vH1118vt912m6rcwjHBPtN169ZNPcaPPvpI7Vc9SMRl7GsdquxQiYf9e+ihh6pqOlfr1q1T+wTVeqiyQ3tpenq629uiH7crrriiukpv4MCB6tjo/v33X5kwYYKEh4dL586d1e0VFBSIu/Tvl48//lg9dgSVM2bMkLy8vHq/F919fNdee6363m7VqpVMmTJFzj77bDnzzDNrbENZWZn6PPY5IMQdP358daXk8ccfr8JOsv9zJvnGZYMvlFenvSpTe3mnChdzyrAoAlYd/WXLgecrs4twREhhWaFqByWyKwZrRCYO1lCxZib6XLXa/mZksEZkXghAUPWEkz/PCkKIMXbsWBVI6ZVuCE3cheAL4dB3332n2hkBLZRpaWny+++/y/Lly2X48OFy5JFH1mjNdIY/0kNCQiQQpbT7IbzRwxxYtGiRDBo0SIUqOoQnubm5qroNhgwZIn/++ac6nn///bcMHjxYffzKK6+Up556SqKjoxt8PDNnzlSBDQKo2uhh4+7du1X4hhAQoeHrr7+uwrtHHnmkxvXx/YXWOVTiYRseeughtY3w33//qUrDM844Q+13HAtXaIdF2HPIIYeofYlw6pZbbjkoEEN4ifBt2bJlKizau3evul13t6WyslIFVwsWLFDhJULMJ554QoWzgLAJ23raaafJmjVr5Msvv1THBmFWY+B2EBoisMMJQRrup77vxcY8Pnwf4TEgmD3nnHPk559/rtFSjOOL8PSUU05R/0YweNNNN6nbxfcMvgfxOewPqonPmdQUbSPbygl9TpABbQZ47T70qjWsDlqFocwWEemIlOTcZKmorDB6U4i8gosXEJmQWYM1PTTLyhLJyBBp2VL7N36v64sXmDVY69VLO3dzDBMRmRhCClTz6BCSfP311w1+HaqGEEZgbhmqmBoL1WKo/kF1GiBsQYUVgjW9nRGVXghTvvnmGzU7zRVCE4QbTz/9tPzvf/9TYQeqvwDhij7k3zlUA/3f+Bygcu7qq69W94e2zzvvvFNVR+GxIQBDEIdgB1VSrgGYbuv+J+5+/frV+7hfe+01Ffq88sorqrIK10dL6+23367aU/WQEOHe/fffry6j3RPXR4CDeXLYZ9hHCBHr2veYU4aQB6EdqsgGDBggycnJctVVV1VfB7eJ0Mm59fW9995T24e5bajga2hb/vrrL3XcUOWnX79Hjx7Vt/f444+roEqff4avf+mll2TixIkqVNSrFRuCx4JqSD3kROUZtgHVhHV9L7r7+LBNCAx1PXv2VEEiFoLA/ej788QTT6y+fwSFznC7OC4IFlGxR0Tmd2T3I+WphU/J7rzdsiZtjQxp67KamMnbQTOLMqV1pPY7lMhOWLFGZEL7/24yXStoRIRIp04HB1T79mmrhaJrSq8MMxtWrBHZx+TJk1XFmH5C6OELXbt2rQ7VANVbqBBCWx2CPv20c+fOOlvsEBahCgZz0PRQBe2XCM6cq9gagttBBdSuXbtUgIK2PwRJCGauu+46Oeyww9T2oboOlUy1cbfaAQEUqqucW2MR5uGxI/jS6VVzOrSMInR0F+4Ht+EcXOF+neEx/fPPPzX2tx4MOu/z+rYF3zOdOnWqDqlc4T4QiDnfB4JKBGU4tu5CC6hz5aA7+8Pdx4dZdc6Cg4NVVRvm5AEC2x9//FEFhM5BKtqGESKibRnbpy+UQUTWEO4Il8ndJqvLv239TawiODBYqqSKixiQbbFijciEzFqxpld+4e8oFDqMHl2zDbRLFxE338g3LFjbsUOrsOMiX0TWhcocDP93hWDKNSxC4NQQd78O9+sMwRLCkjlz5hx0XdeZbc4wDwsntPjpqw4+99xz1VVTCNtcV/TEdfXP1QZVcKiwQmCE7UGVGm4biyDg31g51JUeLG3atOmgAKspMDvOGR6Xp9sMsc/xWJ588smDPodj4c626K239d0H5q9hrpqrLvhF58X94e7jc/1eBIRoqKpDeIe2VzxOtLTqcLsIh99++23p0KGD2hZUqnHxAyJrmdZ7mvy69Vf5c8efcvPYmyUkKESsIC40TlLzU6VnfE81d43IThisEZmQ2YM1/A3pXLFm9vlq0LWrtjpoYaFWEej09wkR2QSqyTD43Rmqk5wDDrTfYdVN16/DUHlU+eiBhT5DrT6Yp4bWTFQL6dU/jaG3d6IlD1VaaFMEhFxoF0RAoq+eiaAEVUaYP+YK7YWo9nr//ffVv/H49GCwvmDxmGOOUcPt0VKIFkJXmPeFgLB///5qthzCR71qDbO9UI2FIM9TcD9oZy0uLq6uWlu8ePFB+xzbgv2N/d4UqGZDpZ1za6XrfaA9srbw1pNq+15szuNDlSJaRjETDjP/MP9P/97PyMiQzZs3q1ANizI4z/QjIms5tP2h0jqitewr3CcLkxbKpG7aAj1WmLOGVlAsYtAl1v03KYisgK2gRCZk5mCtd2/tXJ+pZpVgLSREC9eAc9aI6ldSXiLF5cVePeE+PA3zyzCYHXPQ0PaG1kjXoA2BBQbaYwVGDO5H1Q5WwURb5l133aXa7dBaiVbAhmAVTYRgWIkUK3niNhcuXCh333232o66oF1zxYoVKtjBSp8Yio+5XnqVGwIvBGiYlYXWQAyhv+eee+Saa66pnuWmQwiFr3/rrbeqW0nRponbxdcipMG/a4MQEbPafv31VzWLC7PH8Biw7VjQAAshAGa5JSUlqRZTVLehxRD7FlVyjWlfbQiq+BDcYaA/gq3ffvtNzZBzhn2AhSHQ0ogFEXC8sH+wuqlrSFUXVHUdfvjhauYYAku0dyKIwkIBgNlxOI7YrwhY8b2Ex9zYxQsaUtv3YnMfH/YhFjPA43JuA23RooVqWcb3CRbhmD17tjp+RNQMeOMiJUU796GgwCA5tpdWjYrKNavA83tYcJjszt2tVjYlshMGa0QmZNYZa3UtAmD2hQt0nLNG1PAMlChHlJRWlkpeaZ5XT7gP3Bfu01MwB+vee+9VoRAG+KMK7fzzz69xHawyidUfEVyhUg3zpeLj49XqkAhysBrn559/rlakdOePBHwNQhoEH6h+wmIBmHvmuviAM7R5ojoN94Wg480336zRdojtwwINOEdwd+6556rHgZUtXT344IOq3XPo0KHVH8PMOQRC2C60/7kOrXd20kknqRAJlU0IZTDPC6FOTk5O9aIHHTt2VI8T243VSBG4XXLJJSrs8yTME8M8uLVr16oB/ggoXVsi0cKIajmETAggsQ/RAotQsjEhHwJHfI/gseJ7Ad8zenCFijbMr0PwieoubAsWacB9e1Jt34vNfXwI0xBK4pg5B6r42i+++EKttor2zxtvvFEtoEFEzYBADYvO+DhYg2m9pqnzfxP/ldySXLEKLGKQUZgh2cXZRm8KkUcFVFlpnV4vwfL1WJ0JLyLRZmF1aPvAC+Bp06YdNN+DzA+jTvSChPT0AytvmuU4r12LPzrw7rdIZqb2sUGDRFAU8vvvIk7jXEwHxRdvvimCvwUfflhMjz/L9uerY4xf9aiIAbT+lZSUqCodDM13XeGwtKJUyivLxRcQqlllNkxToQoJrzPw+sKT1V1kHv5yjFEdWdfzht24PmeWl5fz97HNNen3MeaLbNyotUTs2oV+dkkqy5Dlqculc0xnb2+yzPh2hmzL3CZ3jr9TTutf9xsoZpOUkyT9WveTfq3qX5Ha0/i62v7KPHyMG5MTccYakcnoC4ZhtArCK7NWfWVlacEaOpesVrHGVlDyN6iscl7Nsj4IuuwedhEReeo5k8gox/U+Tl5c8qJaHdRKwVpMaIxqB+0e111Cg2uONyCyKvu+rUZk8TZQzKs24xvfERFoC9IuI1BLShIpKcHqZ9qqoGamt7GyFZSIiIiIPCEv35il5o/teawEBgTK6r2rJTk3WawiOjRa8kryJKMow+hNIfIYE/7ZTuTf9IULzDhfrbY5a2vWHKgGa+ICbT7DGWvkr9D6iaHoOOEyERHVjc+Z1BgTT4yVQ8/rJ2vW+jZgax3ZWkZ3HG25RQwQBjqCHKpqjVOpyC4YrBGZjJlXBK1tZdD9i6jJJAus9N2jh3aOFla0shL5C8wHeu2119QJl4mIqG58ziR3rd8eJivXBsuareHSsUPtIRFWws4q8s4Lz2m9tUUM0A5qpZAqNjRW0gvT1WJGRHbAYI3IZKwQrOkVawjWfvtNuzxN+71ualFRByoBWbVGRERERM3x8W/aKmPTxuXWuuAYQrW0gjSpqKpQQZKnTeo6SSIcEbI7b7dqCbWKcEe42jf7CvYZvSlEHsFgjcikM9asULH2558iCQkiISEiRxwhlsB2UCIiIiJqrspKkU//iFeXz5t28LwwrLKNUK1XfC8Z2GagCteyi7M9HlAd2f1Iy7WDQqQjUs2G89VK5ETexGCNyGSsNGNt3/43mSZOFImMFEtgsEZEREREzTVnXqAk7w2RuNhKOX5CTo3PoS0zNT9VurfoLv1b95eOMR1VuFZQViAFpQUeXx0U/tzxp5SUW2cmYGxYrAoaM4syjd4UomZjsEZkMlZoBdXDKd3UqWIZDNaIiIiIqLk+/lxbtevMk0skNKTmfLOi8iJVkYVqteBA7XqdYzpLt7huklXi2Xlrw9sPl7aRbSW/NF/+TfpXrELtlwBRVX1EVsdgjchkrBCsoTqtQ4cD/7bCfLXaVjQlIiIiImqswkKRb34IUpfPm35wlRhCLlRkIVzTBQQESJvINiJVIpVVlR5dZfPYXsdWL2JgJdGOaNmbv9dSlXZEtWGwRmQyVpix5hxQde8u0qePWAYr1oioIQkJCeoPoFWrVhm9KUREZEI//SSSnx8gPTqWyGGjDp4RhsH8qCLD7xJnLcJaSFRIlArePGlaL+1d7gVJCzw+x82bokOj1cqgWcXeWTWVyFcYrBGZSGmpSFaW+WesQf/+B6rVXF4zWCJY271bpKjI6K0h8o3w8HDZuXOnOuGy1e3Zs0euu+466dGjh4SGhkrnzp3lhBNOkL///lvMYs6cOXLSSSdJx44d1Wn48OHy6aef1nn9L774Qv0BdvLJJ9d7uxUVFfLEE09Iv3791LGMj4+X0aNHyzvvvFN9nUmTJskNN9zgscfSrVs3eeGFFzx2e0RmZ7fnTPK8v/7Szk87Iuug18EYxo82R1SsuQoNDlVVa7mluR7dnp7xPaVvy77qvv/asX/jLADVdjihao3IyrSGbyIyhbT9IwaCg0VatBBTu/NOkehokdtvF0vBUuixsSI5OSI7dogMGGD0FhF5X2BgoApH7FJNNm7cOImLi5Onn35aBg0aJGVlZTJz5ky55pprZNOmTWIGCxculMGDB8utt94qkZGRMnfuXDn//PMlNjZWjj/++IMe0y233CITJkxo8HYffPBBefPNN+WVV16RQw89VHJzc2XZsmWSpb8r40GlpaUSgmWfifz8OROBNpGzhQu18wnDUHkWV+NzWP0TVWkxoTG1fm3ryNayI2uHagdFqOQpU3tNlc0Zm1U76OmHnC5WERMSI/sK9qkqv7DgMKM3h6hJWLFGZMI20DZt8KJOTK1rV5GnnxZp1UosBe8qsh2UqG4FBQV1noqLi92+bpFLSWht12mKq6++WlV2LV26VE477TTp06ePDBgwQG666SZZvHixus7FF198UHiF8K1Nmzby7rvvqn9XVlbKU089Jb169VJVb126dJFHH320zvtdt26dTJ06VaKioqRt27Zy3nnnSXp6ep3Xv+uuu+Thhx+Www47TLp37y7XX3+9HHvssfLdd9/VuB7+YD/nnHNUYIYKvIb89NNPah9Mnz5d3e6QIUPkkksuUcEcXHjhhSrEe/HFF9V+wgnBHe4H18PXoAKnb9++6jrO8LWomMN+6NChg7oOqt927dolN954Y/XtERH5s8xMkY0btctjBx/c0hkgAaoNVF+0wJW32kExZw1B3Zq0NZKcmyxWERkSqfZFVhHbQcm6TP6nO5F/scLCBXbAYI38DSqPUDmFEy7XB8FRXScEWc4QVNV1XYRQzlD94XqdxsrMzJQ//vhDVaahCswVqtjg0ksvVddLTU2t/twvv/wihYWFcuaZZ6p/33nnnaql8t5775UNGzbIZ599pgKz2mRnZ8sRRxwhw4YNU9VhuO29e/fKGWec0ajtz8nJUa2bzh566CG1HxF6uaNdu3Yye/Zs2bdvX62fR1g2duxYueyyy9TjxwmtsggSO3XqJF9//bV6vPfdd58K/7766qsaX4922s2bN8uff/6p9hmCQHwdtlO/PSK7a8xzJvlvtVrfPpXSKu7gasaI4AiJj6j5XO+LdtBWEa1kdMfRllvEAGFgUGCQ7C1gOyhZl6HB2rx589RMFLwrindAf/jhh4PeOdXfHdVPeLfX9UU23umNiYlRL6jxwjQ/37PpP5GvgzWzz1ezOgZr5G9QrfXMM8+oEy5b1bZt26SqqkrNF6sPqsRQbfXxxx9Xf+z9999XVV4I9PLy8lQAhYq1Cy64QHr27Cnjx49XgVxt0HaJUO2xxx5T943L7733nvzzzz+yZcsWt7YdAdZ///0nF110UfXH/v33X1VB9/bbb7u9D5577jkVqiFgQ6vplVdeKb///nv159FqivbNiIgIdR2cgoKCxOFwqKo4tI+iag2vnbAtrsEaAkvMa0MVIE4IAvH10dHR1bdHZHd2ec4k71iwQDsfN6b2lT2jQqMkNvTg+Wqu7aD4fYaTJ03pOUWdz9w+0+O37U1om0WwVlDatGp2Ir+esYY2ELQwoGXj1FNPrfU6CNLwYliHdg1neGGId0/xzip+8eFF4uWXX67eeSayGlas+XZF023bjN4SIvOp780pBCzO0vTBkHXMKHKGdsTmaswfCQjJ3nrrLbnttttUdRnCJ1R6wcaNG6WkpESOPPJIt25r9erVKkSrrcpu+/btqh21PvPnz1dv/CFAQ1gFCPfQToqPtWpET/0hhxyi2lKXL18uCxYsqH6TEm9GOi9gUJtXX31VBYKJiYmqVReVOEOHDq1xHcys41w1IqKGK9bGjTm4Wg2VV/Hh8RLuqH/Ri+iQaDVPDHPFGrpuY0zqNklC/w2VXTm71Ly1fq3qfyPKLCIdkZJRlCHphemqNZTIagwN1tAm4toq4gpBWl3vjuKFMdox8A4w3oGFl19+WaZNm6beYUIlHJEVZ6wxWPMuVqwR1a22FktfX7cuvXv3VtXr7ixQgIUC7rjjDlm0aJFaSABVWvriAI1d5Q9hI8KrJ5988qDPtW/fvt6vxbyzs846S5599lm1Tc6BHMJG3K4O7ZoQHBys2jFRSVdXaDly5Eh1wuqfn3zyiQrp7r77bvU461p1FHPYsB1oFUUFGhZ/WLJkicePExGRXaEzeOlS7fJhqFhzKVrDbLXWEa0bvJ0IR4QKkwrLCj0arGF227gu42T2ztmqas0qwRp+t6OFdnfebukc29mjizoQ+YLpVwXFcvWYPdKiRQs13+SRRx6RlljWT0S9WEb7px6qwVFHHaVecOKF4imnnFLrbeJdapx0WFELUPFmh3Jv/THY4bH4m+RkVIMEStu2FVJWVnt5uY7Huem6dMH/HZKQUCVFReVqFVYz4jG2P18dY+fbx2UEOKj+wrke5lgBfucfc8wxqvLq2muvPSgEwiw0fc4aXjecdNJJqkILixqgokt/rAisEK6h2r229k/9evr+QesnZo1hgQOEXnVdv7bXMCeeeKLcf//9auaZ8/VQ5YZKOGeY94YQ7/nnn5eOHTu6fWz01lhUweFr0PZZXl5e4+vRdooWWbSOOod7ztuvtyW53i8q2Fxvjw6upKxt39mJ/ryB5xDX6lW7cX3O1Bft4O9j+3L39/F/iyqkuDhMWraskh49yqRsS6VIeTl+QLTzCod2O5UNf6/Eh8bLtoJtUhnq2eeNY7ofo4K1WdtnyTUjrrFMSBXtiJaMvAxJz09XCzx4Gl9X21+Zh49xY27HpH9OHmgDRYso3n3Fiz8M2UWFGwI1/ELfs2ePCt2c4QUv5oHgc3V5/PHH1ZwRV7NmzVIzSewCfzCQtaxfj2qKeNm7d7n89pt7A6J5nBsPr30cjuOlrCxIPvpojrRrVyhmxmNsf94+xs6rec6cOVO1NKIaHCGO1QZzY8EBvD4YNWqUWoAArZUIfRBiIURzrsBCpdiMGTPUiph4s01/Iw3+97//ye23367CgtGjR6sVPlEJh8ovvR0WIyvwNXrLJhYrwOqeCO127NihwraXXnqp1pAB7Z+47yuuuEKFa5gPp4dU+HpAUOcMQSEeCz6OY+a6CitgJhy2F48fr4HQ1omFBbC6KSr1sb0I5fBaCS2juE3cHxYw+Oijj+T777+Xrl27ypdffqlWVsVl5zcYcf/O+wmweAHaaNERgE4C/Q1OqgnBpp3huQItxGg/xveJnbk+Z4aFhanL/H1sfw0d4x9/RCXxQOnRY4/8Pmd/6VpKSs3zRkqRpn1dXbpXdpeIwAg1s2z2/NlySNQhYiWLti7y6u3z59j+/vTQMcaiV7YI1vCC1HnmB4b04l1mvHh2dy5KbfBC/Kabbqr+N15A4gUn3gXHIghWhxfG+GY6+uij1bvWZB3XXqv9SJ544nAZObL+WUI8zs3Ts2egoJusS5fJctRR5hzuymNsf746xgiIdFOmTFFBUFJSkgrY9D8YrQKvBTBfDAsJYGVLzFlt3bq1DB8+XF5//fUav8cRaKFVE3PJsJiBs4cffliFTgjqUlJS1PUQguHr9Vlq+Dz+jRMqvtBaipVRUfWOQAr7EhVyejWLs2+++Ua9IEP1GU66iRMnVs96c4XvAbxBWN9rEYRbCMVeeOEFtcooAtLJkyerqjh9xVFsJ2bOjhkzRgUheHMSgSBGaGDWG7YXr7GuvvpqNVJDv7+67h/dAldddZXax3jsCCrpAFRxIVRDe21t3wt2CptQ6Xn44Ydb7nmjuc+ZCMT5+9je3P19/MG72vnJx7WQaZMni2zeLNK5s0hSkgh+zzRi1EBeaZ4sTFwocWFxaqVQT5pcOFl+3farrAheIUcNP0qsIqc4R52P7TxWQoI8O++Tr6vtr8zDx9j1jUbLBmuuevTooQb84l1fBGt4Mek6OBnvoGGl0PpWrcK7ra6LIAB2vp1+yOz2eOwOb/6m7i9S69YtWNw9dDzOTdO7t6hgLSHB/X1tFB5j+/P2MXa+bVxGsIYAAKMTXBcZsAJUZKEdFKf6oPIsKytLtXu6Pk78+5577lGn2l5vuC6UgGAO1V7u+vDDD9UJFXF4YYawqqF9jes3BOEfTg21hqJizdUHH3xw0McQLDZ0/2ghdW1bpQP09k/9Z8qu8NjwGP3hd5Lrc6b+b3947P6uvmOMXwuLl2q/GyYcJuLAaAD8zDufN+L7IzYoViLDIqWkqkTCgzw3Zw2O7XWsCtb+Tvhbbhl3iwQHWuPP/tiIWDVnLbcsV9qH1T/DtKn4c2x/Dg8d48bchqV++ycnJ0tGRkb1oGAM38U8FbxzrcO7wHpbB5HVVgRFEQA6irh4ge9WBt261egtIfI+VJmgLRCnxg7utyK8DsAbb6hKQ0UZKteIiNzlb8+Z5B68Ab5nb4AEBVXJocObPxdNX0EUCxh42siOI9VtZxVnyZLdNRepMTPMgwsKCJI9+XWPdSIyI0Oja7yTrM8cgZ07d8qqVatUKwNOmIOGlgtUn6GN4bbbblMzRFCSDf3791dzVjAQ+I033lClfxhmjPYGrghKVpOcrJ3jW9fmM4FNU7EGTk9BRLauNMEsMn+BuWOYz4rZYKjSqm3BASIid58z2f5MsHatdt67M9qiPXObLcJbyM7sneJpqFA7usfR8uX6L+X3rb/LuM7jxCpiQ2MlrSBNCkoLJDKEK1WTNRhasbZs2TK10hZOgLlnuIyZKWhTWbNmjXqXGStnYSbIiBEj1DBg5zbOTz/9VLU8oDUUc0fGjx8vb731loGPiqh5wVqnTkZviX8Fa6xYI7Kfbt26qVZOzJFrzkxWIiIi12BtUK8ij91mVEiUqtAqr/T8giBTe01V53N2zfFKVZy3IEzD9mYUZRi9KURuM/Qt3EmTJh00w8QZVuFpCCrbPvvsMw9vGZHv7d6tnXfsaPSW+Fcr6I4dB1pwiey8mh+G/QNW2CYiIvefM+28KAW5b9067XxgT6waG+axYC3CESFFZUUSHRotnjSg9QDpHNNZknKTZE7CHJnWe5pYRVhwmOzO3a22nz9/ZAWWmrFGZGesWPMtLOAUEoIXz9pCTkR2hlEJGK+AEy4TEVHd+JxJvqpYw8qXMaExXqkoQyCFRQzgj21/iJWgHTSzKFOyi7ON3hQitzBYIzIJBmu+hQq1Hj20y5yzRkRERER1QXfDhg3a5YE9PResQYuwFlJaUSreoLeDLt69WDIKrdNaGRocKmUVZZbaZvJvDNaITILBmu9xzhoRERERNWT7dpHiYqwYWyU9OpZ49LbVgH4vdTt2ie2iWkIrqyrlzx1/ipVgv+zO260CNiKzY7BGZBIM1nyPwRoRERERuTtf7ZB+lR6fy4sZa45Ah9cCJL1qbdb2WWIlaJFFKyhaQonMjsEakQlUVh5YvIDBmu8XMGArKBE5S0hIULNpVq1aZfSmEBGRmearDah74b2mCneEq2H9xeVYFMHzjux+pARIgKxJWyMpeSliFcGBwep3cWp+qtGbQtQgBmtEJpCerg3Rx6I37dsbvTX+gxVrRNa0Z88eue6666RHjx4SGhoqnTt3lhNOOEH+/vtvMYs5c+bISSedJB07dlSn4cOHy6efflrjOh988IH6o8H5FBZW/0pzFRUV8sQTT0i/fv0kPDxcrY4+evRoeeedd2qsun7DDTd47LF069ZNXnjhBY/dHhGRVYO1gYdUHvxJh0N7AY/zJi5gEOmI9Fqw1jqytQxvP1xdtlo7KBYx2FuwVwpKC4zeFKJ6BRu9AUR0oA20TRttpUrybcXajh3aUFpPl/YTkXeqycaNGydxcXHy9NNPy6BBg9SqfTNnzpRrrrlGNm3aJGawcOFCGTx4sNx6660SGRkpc+fOlfPPP19iY2Pl+OOPr75eTEyMbN68ufrfCNfqg1UK33zzTXnllVfk0EMPldzcXFm2bJlkZWV5/DGUlpZKCH8pERFVt4IOGlBHsNahQ7Nuv0V4C9lbuFe85Ziex8jy1OUqWLtgyAViFQgc0QqaUZShzaIjMilWrBGZANtAjdG5sxZkolowKcnorSHyHlRBLV26VJ0aqogyu6uvvlqFT3gsp512mvTp00cGDBggN910kyxevFhd5+KLL64RXgHCtzZt2si7776r/l1ZWSlPPfWU9OrVS1W9denSRR599NE673fdunUydepUiYqKkrZt28p5550n6Sg3rsNdd90lDz/8sBx22GHSvXt3uf766+XYY4+V7777rsb18FjatWtXfcJt1+enn35S+2D69OnqdocMGSKXXHKJ3HLLLerzF154oQrxXnzxxeoqOISRqHTD9fA1qHTr27evuo4zfO3JJ5+s9kOHDh3UdVD9tmvXLrnxxhurb4/I7uz0nEnNV1R0oLthoBdaQSEqJEqqqrxz23o7aFBAkGxK3ySJOYliFfidEx4cLsm5yWoBBiKzYrBGZAJcuMAYqFDr2VO7zDlrZGdBQUEycuRIdcLl+hQUFNR5KsaSaG5etwh/iTRw3cbKzMyUP/74Q1WmoQrMFarY4NJLL1XXS009MJfll19+kcLCQjnzzDPVv++8807VUnnvvffKhg0b5LPPPqsz1MrOzpYjjjhChg0bpqrDcNt79+6VM844o1Hbn5OTo1o3neXn50vXrl1VOytaR9evX1/vbSB8mz17tuzbt6/WzyMsGzt2rFx22WXq8eOE20aQ2KlTJ/n666/V473vvvtU+PfVV1/V+Hq006KC7s8//1T7DEEgvu6hhx6qvj0iu2vMcybZHwqhMQ8ZT9/t23kn/MKcNQRf5ZXlXrn9uLA4GdVxlCUXMYgNi5XMwky1kAGRWTFYIzIBBmvGt4NyzhqRBhVZdZ1QIeYMFWB1XRfVXa5zulyv01jbtm1T7+hjvlh9UCWGaquPP/64+mPvv/++qvLC/ebl5akAChVrF1xwgfTs2VPGjx+vArnaoO0Sodpjjz2m7huX33vvPfnnn39ky5Ytbm07Aqz//vtPLrroouqPYRtxOz/++KN88sknKvzCtifrvxRq8dxzz6lQDQEbWk2vvPJK+f3336s/j1ZTtG9GRERUV8EhGHA4HKqNFO2jqFo755xz1La4BmsILDGvDVWAOCEIxNdHR0dX3x4RkV/OVxuozUP2BqwMGhoc6rU5a3o7qBWDNcygK6ssk7SCNKM3hahODNaITIDBmnG4gAH5A8zKwjwynHDZqhrTJoOQDGEaoLoM4RNaRGHjxo1SUlIiRx55pFu3tXr1ahWiOYeCeri3ffv2Br9+/vz5qg3z7bffVmGVDpVlmLs2dOhQmThxoqoOa926tZqhVpdDDjlEtaWi7RWPJy0tTS3cUFco6OzVV1+VESNGqPvAY3jrrbckMbFmSxBm1nGuGvk7uzxnkpoDIJKSIlJYqJ3j3420fLl2PniweA1WBY0IjpCS8hKv3cekrpPEEeiQHdk7ZFumtVo1YkJjZHfubimt4M8jmRMXLyAyAQZrxlessRWU7AzzxW677TZ1GfO56mttQmtiXVy/DqFOXQIDa753hzlfzdW7d281b8WdBQoQWN1xxx2yaNEitZAAqrQmTJigPocZY42BfYLw6sknnzzoc+0bWMoZ887OOussefbZZ9U21QdVZaiGQ2VefbBv9TY1rP6JajfMfLv77rvV46zNF198oeawYTsQ6KECDaHBkiVLalyvthZbIn9/zmTYbGEI0tDCjmOIc4wMaOTqnX/9pZ1PnCheFR8erwb1e0t0aLSM6zxO5uyaIzO3z5Re8ftfBFtAdEi0pOSnSEZhhrSPrv/3LpERWLFGZAIM1oyjz1jDyqBEpAUrdZ1ch3jXd13X8Kq26zQW2hKnTJmiKq9qm9GGWWi6li1bqkH8qFr74IMParRgIqDD9mGemDuGDx+uZp+hnRWLHTif6nscc+bMUYHc/fffL5dffnmD94MFBtauXdtgWFdbFRvo+wQhAG7L2YIFC1SbKUIChHfYdneq7eq6PSIif4Aitw0b0AJaJZP7pTap4q0xwVeleHdA/5SeU9T5zG0zvbpYgqcFBQapGXR78vcYvSlEtWKwRmQw/E5jsGYcfZ/rK7MSkbkhVEPIM2rUKPn2229l69atqrXzpZdeUpVYztAe+eGHH6rPY5aaDgHh7bffripSPvroIxUwobVSXzHUFRZLwMIJqDzDnDRcf+bMmSqsqytwQuvocccdJ9ddd52ceOKJsmfPHnXC7eiwIMCsWbNkx44dsmLFCjn33HPVCpz1tXWefvrp8vzzz6tKM1wX4R22D6uj6u2pCADxeVQJYuVSzG5DmIiFF7DdmAuHRRvwWNyB25s3b57s3r273pVQiYgs1R7qRkimv/8yYliltCxpWitpYxYwCJAAr65+OaHrBDXPDdVfa9P2D4+ziNjQWDVnLb+07sp6IqMwWCMyGAosMPYBOnY0emv8j77PnY8DEZlXjx49VAg1efJkufnmm2XgwIFy9NFHq+qz119/vcZ1jzrqKFX9hSq3Dh061PgcgiV8PVbH7N+/v1ottK7WVnwtKr4Qoh1zzDFqDhlaMLEKqWvLqw6BHlYhxcqjCLw6duyotuXUU0+tvk5WVpZavRP3P23aNMnNzVVtq3oFWm3wWH7++WdVCYcwDYEhbh8BXXCwNuEDLZ9o28XtYJ4a5qhdccUV6r7xOEePHi0ZGRmqes0dCAAR0mGRB9weEZEt2kPdCMn0NtCjJnu3kgzCg8PVAgbenCOGWW4Tu2o9rWgHtZLIkEgpKCtQ7aBEZsMZa0QG08cOtWyJuT9Gb43/iYlBixpaqLQ3L/WZa0RkXgiosFInTvVBayTCKywc4AqBGGaS4VRbhZZriwwqvrC4gLvQfooTqsUQmMXExBwUwqHyDKfGQBCHU30QuGG2nCu0xeoLOugef/zxGttcmzFjxqgFHIiILAGB2b59Is18IwC/Bv78U7t81GTvt8Mj9MIKmFjAAJe92Q76+7bf5a8df8mNY26U4EDrRAJY4GF33m7pHNtZAgNYI0Tmwe9GIoOtX6+d11OgQF6EZdP1qjW2gxLZA8IsVJ89/PDDqqoMrZhEROQnGlGRVp+NG7WbwXjRcWMrfTJHDFVZ3l75ckynMaqtMqMoQ5an7l/y1CJiw2JVxVpWUZbRm0JUA4M1IoOtW6edDxxo9Jb4L71DjMEakT2g9bFt27by2WefyXvvvVfdIklEROQuvQ0UC0q7rN3jNQi8SipKvHofqFA7svuR6vIf2/4QK0FFX0VlhezN32v0phDVwFeaRAZjsGY8VqyR3WFYP4bp65fLvDh82Qxqa+UkImrqcyaqYMnGixjU0TJaPV/tKN9tEhYW8MXvrym9psh3m76TOQlz5M7xd6rAyipiQmMkJS9FesT38GrLLFFjMFgjMhiDNfMEa3htRWRHGGQ/adKk6n/bPVgjIvLkcyaDNZu3jMbFiTgcB31qzhzt8tFH+26T9KAI4VoA5pV4ydC2Q6V1RGvZV7hPFicvlsO7Hi5WER0aLUm5SaoltGMMV34jc2ArKJGBcnNFdu3SLjNYMw4r1oiIiIhsUoHmgTePtmwRycsTiY4WGTJEfBqsOYIcUlZZ5vV5bkf10ErxZm2fJVaCRQtCg0IlOTeZ1elkGgzWiAy0YcOBGV/x8UZvjf9isEZ2hwq1V199VZ2cq9VYhUFE7vKn54u6njPJPxYtcO4oGTQIq0iLT4M1hEbeXsBAXx0U5u6aK8XlxWIlcWFxkl6YLjklOUZvCpHCVlAiA7EN1By4eAHZXWlpqVx77bXq8oUXXijh4eESGBgoKSkp0rp1awkJCfFqy4m/hxHY/8XFxWqfk/3Y/RijIgSPb9++ferx4fnC354z/eExUxNeo6N9tH37g9pImwOzzhCuFZYVSlRIlHjTgNYDpENUB0nJT5F/E/+trmCzAuwjhI9YxAAhG5HRGKwRGYjBmvlmrOENeRv+XURUA/447t69u6SmpqpwjbwbShQVFakwk+GlPfnLMY6IiJAuXbrYMjwkqus1+oAB9VwJgZr+7qwHxYTFSHZxtngbnq+O6XmMfLD6A5m5faalgjV9EYPdebule4vullp8geyJwRqRgRismQPebMTfQugcyMioc3EoIltBBQb+SC4vL5eKigqjN8e20EY2b948Ofzww8XhwaoGMg9/OMYY5h8cHGzr4JD8nN4+inOHw9DX6NEh0VJeVe6T+9KDtQVJCyS/NN/rVXKeDtYwZw0toR2iPR9wEjUGgzUiA61dq50zWDMW/g5q00Zk716tHZTBGvkL/JGMIMCuYYBZAgmEl2FhYdzPNsVjTGQD5fuDrPJyKSwU2b7duNfo+sqgvtA7vrd0ie0iiTmJsihpkRzd04dLoHpgEQNHoEN25+6W9lHtGfyToVjLTWSQtDTtBIccYvTWEBcwICIiIqKNG9HijTdaq6RNuWdWGW1ssBYUECTlld6vWkMYNbHrRHV5XuI8sZoW4S1kX+E+yS3JNXpTyM8xWCMyyPr12nmPHiKRkUZvDXEBAyIiIiKLQeiV4tnwq7oNtH+lx1YZbWywFhIc4pOVQUEP1rCAgS/CPE/vq5LyEtlXsM/oTSE/x2CNyCCcr2YurFgjIiIishiEXh4Ov6pHtQyoFCOEBodKaFCoz4K1QW0GSWxorOSV5smqPavEajCTLjE3UcoqfBuAEjljsEZkEAZr5l0ZlMhuQkND5ZdfflEnXCYiorrxOdO/rVurBWoD+5YZNjssJiRGisuLfXJ/QYFBMqHLBHV5fuJ8sRosYoBWUCxiQGQUBmtEBs1H/f137fKwYUZvDQEr1sjOsJrfcccdp064TEREdeNzpsVhEREs+Y5z58uNffO7t28qxmoTGxbr07bMw7sers7n7porVRgwZyEIBjGTLjUv1ehNIT/GYI3IAN9+K5KUpK0+efzxRm8NAYM1IiIiIhtAiIbhuXqwpl92Q1aWyO4U7U/kAf0qxMjZYb4MuMZ0GqNW2EzOTZaE7ASxmriwOEkrTJO8kjyjN4X8FIM1Ih/D78hnn9UuX3ONSJjvVtSmenDxArKzsrIy+eCDD9QJl4mIqG58zvRfGzYFqfPObUslNsa4yq1wR7gEBgZKRaVvwr0IR4SM7DhSXZ6za45YDba/qKyIixiQYRisEfnYwoUi//2H+R0iV11l9NaQa8VaRoZIsW9GWhD5TGlpqVx00UXqhMtERFQ3Pmf6r/UbtD+PB/YsMnQ7woPD1SIGJRUlPrvPyd0mq/PZO2eLFUU6IiUpN8lyK5uSPTBYI/Kx55/Xzs87T6RNG6O3hnQtWhyoHsTiUkRERETkXzZv1f487t/d2HdZfb0yKEzqOknNKtuYvlG1hFoN5tJlF2dLZlGm0ZtCfojBGpEPYa7a999rl2+4weitIWcBAZyzRkRERGRLbi5isG279udxny7GBmtYGTQ2NNZnK4NCi/AWMqL9CMtWrQUHBktAQAAXMSBDMFgj8qF//hGprBQZM0ZkwACjt4bqmrOWbL036YiIiIioLm4uYrB1f7DWu4vvWjDrEhMaI2UVvp3xd0T3I9T5Xzv/EitCGLknf4/kl+YbvSnkZxisEfnQokXa+bhxRm8J1aZXL+1882ajt4SIiIiI6oRFJVJStPNGVqXVpbw8QBJ27Q/WOtdRKdbM+2jsAga+hjlrqJbbsG+DJSu/okKipKCsgIsYkM8xWCPy8cIFMHas0VtCtRk0SDtfu9boLSEiIiKiOiFQw1Bc12DNjaq0uqSlRahwLSysSjq2qaNSrJn30RhhwWFqZVBfDuNvGdFShrUbpi7/vfNvsaIoR5Qk5iRyEQPyKQZrRD6Slyeybp12mcGaOQ0cqJ3rx4mIiIiI/ENKSqQ6792zSgJN8FeyvjKoLxcwgKN6HGXpYE1fxCCjMMPoTSE/Emz0BhD5i6VLtflqXbocmOVF5qxY27pVpKhIJNz3FfhEXhEaGipfffVV9WUiInL/ObOqqsroTSIfSE2NUue9e1WKGaBiLSwoTErKSyTCEeHTdtCnFjwla9PWyt78vdI2qq1YbREDtLOm5KVYbtvJukyQxRP513y1ww4zekuoLm3birRsqQWgGzcavTVEnhMcHCzTp09XJ1wmIqK68TnTP6WmHqhYMwOscIkFDEoqfLuQQquIVjK47WB1eV7iPLGiuLA4tYhBbkmu0ZtCfoLBGpGPgzW2gZpXQMCBqjW2gxIRERHZUB0LEKSkmKtiTW9r9PXKoDCp2yR1PidhjlgRKvyKy4u5iAH5DIM1Ih9ABdTixdplBmvWmLPGBQzITsrLy+Xrr79WJ1wmIqK68TnT5upYgMBsFWt6O2iV+H57JnadqM6XpSyzbNUXVghNykkyJJgk/8PaZiIf2LJFJDNTJCxMZMgQo7eG6sOKNbKjkpISOeOMM9Tl/Px8tjYRETXiOTMkJMToTSIvKykR2bdPm2PWu2elSLaYAhYwwMwwrHCJc1/pEttFerToITuydsiCpAUytddUsZrY0FhJzU+VjKIMaRfVzujNIZtjxRqRD9tADz1UhK/NzI0Va0RERET+ZUdCoFRWBkhUVJW0M1EGg4q1kOAQn68Mqi9iYOV20KDAILWIwe7c3UZvCvkBBmtEPsCFC6wXrO3eLZKVZfTWEBEREVFj56U11rbt2p/FvXpUqpm7ZqGvDGpEsDapqzZnbWHSQrUyqRW1CGshaQVplm1nJetgsEbkAytXauejRhm9JdSQmBiRrl21y2wHJSIiIrLevLQmB2toAzURfWVQDOL3tX6t+knbyLZSVF4k/6X8J1YU7ghX25+Wn2b0ppDNMVgj8oHkZO28Wzejt4QaU7XGYI2IiIjI/tVuZg3WAMEaZqwZEerpixj8k/CPWFVMSIwk5iYaUvVH/oPBGpGXlZWJ7N2rXe7Y0eitocYsYMA5a0RERET2r3ZrMFjzUMtpU9tBK6uMCfz0OWtzd82VisoKsaLYsFjJLc6VjMIMozeFbIzBGpGX7dkjUlUlgkX42rQxemuoMRVra9YYvSVEREREVP1udUqKdu5h23YEHlgR1Istp01tZ8QgfiOCrWHth6nVNbOLs2XV3lViRVjAwBHkkOS8/S1ERF7guzV7ifwUhuAD3uQKZJRtCaNHH1h0Yvt2kZ49jd4iouYJCQmR999/v/oyERHVjc+ZJoVALTVVJC7OozebliaSlOxcsRYkZoKKtdCgUNXKGB4Y7tP7Dg4MlgldJsgvW39Rq4OOaD9CrLqIQUY+K9bIe/hnPpGPgjW2gVpHr14iU6eKVFaKPPec0VtD1HwOh0MuvPBCdcJlIiKqG58z/cuzz2rnvXtnSetWVWI2KlgLDpWSCmNW5pzUbVL1nLUqtOFYEPafUe205B8YrBF5GYM1a7r1Vu38vfdE9u0zemuIiIiIyNPS00VefVW7fMYZm7XZLSZsZYwOiZaScmOCtTGdxqhwb0/+HtmcsVmsCrPWoLC00OhNIRtisEbkZQzWrGnSJJFDDxUpLj7wgovIqsrLy+XXX39VJ1wmIqK68TnTfzz/vEhBgciwYVVy6KF7DZmh5u7KoGWVnp8t5w6Eaod1Pkxdnr1ztlhVhCNCne8r5Dvm5HkM1oi8jMGaNQUEiNx2m3b5lVe0F11EVlVSUiLHH3+8OuEyERHVjc+Z/iEzU+Tll7XLd99doV77mTkUMrKVUV8dFHPWrCpg/wFOzk2WsgpjQkqyLwZrRF7GYM26Tj1VpEcPkYwMka++MnpriIiIiMhTXnhBJC9PZMgQkRNOcJodhqo1rDoWEaGdm6CKDVVjgYGBhoVr4zuPVwsZ7MjeIbuyd4mVYYXT9MJ0ozeDbIbBGpGXMVizrqAgkRkztMsLFhi9NURERERUI/xqYuiVnS3y4ova5Xvv1ToVatx2hw5asIZzkwRr+sqgRogOjZbh7Yery/MT54uVISBE1ZpVF2Igc2KwRuRFeL5msGZto0dr50uWGL0lRERERFQj/Gpi6PXSSyK5uSIDB4qccoqYnh6sFZcXG7YNh3c5XJ3PS5wnVoZFDNIK0iSrOMvoTSEbYbBG5EU5OSKF+xeeYbBmTSNHaufr12vtAkRERERk7dfnWLRAr1YLtMBfxEGBQRIVEmVYxRoc3lUL1lbvWS05xTliVQgpMWMtNS/V6E0hG7HA0wiRdenVanFxWjU5WQ+6DDp31qoPV6wwemuIiIiIqDmwKBVaQfv3FzntNLGMuLA4Q4O1DtEdpFd8L6moqpCFyQvFyrAvU/JSpKisyOhNIZtgsEbkRWwDtYdRo7RztoMSERERWVdRkchzz2mX77lHm6drFUavDAoTukxQ5/N2WbsdFNV/eaV5sq9wn9GbQjYRbPQGENlZSop2zmDN+nPWvv1WZOlSo7eEqGlCQkLkFbxFv/8yERHVjc+Z9jV/vkhmpvba/MwzxVLCHeGqJbSiskKdGzVn7f1V78vCpIWqndIRZPzCDk0REBAgEcERahGDTjGdJDCA9UbUPAzWiLyIFWv2qlhjsEZW5XA45JprrjF6M4iILPmcWVZWZuj2kOf8+ad2PmWKtarVIDw4XEKDQ6WkokQiAo2ZMTOgzQCJD4+XzKJMWblnpYzquP9FskXbQdMK09RjaRXRyujNIYtjNEvkRQzW7GHECG2wbVKSSCrnnBIRERFZ0l9/aedHHSWWHLofFhQmJeUlhm0DKrvGdx6vLs/dNVesDNV2VVVVXMSAPILBGpEXMVizh6gokUMO0S6zao2sqKKiQubMmaNOuExERHXjc6bJoGIQ81WaWTm4b5/IqlXa5SOOEEu2L6LKChVrRtJXB8WcNQRTll/EID9FCkoLjN4UsjgGa0RexGDNXnPWgMEaWVFxcbFMnjxZnXCZiIjqxudMk0GghpaBZgZrs2dr54MHi7RtK5YUExojZZXGtiaP6TRGQoNCJTU/VbZmbhWrL2KAUG1P/h6jN4UsztBgbd68eXLCCSdIhw4dVAL/ww8/1JhlcPvtt8ugQYMkMjJSXef888+XFH0a/H7dunVTX+t8euKJJwx4NEQHY7BmH1wZlIiIiMj689WOPlosCwsYSJXxLamjO422RTsoRIdES1JOkpRWlBq9KWRhhgZrBQUFMmTIEHn11VcP+lxhYaGsWLFC7r33XnX+3XffyebNm+XEE0886LoPPfSQpKamVp+uu+46Hz0CorrhTbW9e7XLDNbsE6z995+IxaveiYiIiPwKXrvpwZoV56s5L2CA2WBYkdNIE7tOtE2whnbQrOIsSStIM3pTyMIMXRV06tSp6lSb2NhY+VN/9tsPy16PGjVKEhMTpUuXLtUfj46Olnbt2nl9e4kaY88e7Ze4wyHSurXRW0PN1a+fdp6bK5KVJRIfb/QWEREREfm3++8X+fFHkddeEznssLqvt327SGKi9rp8wgSxdMUa2jAxZw0Bm1EmdJkgARIgm9I3qTbKdlHW/VscCzJgn6JqrUN0B/VvIksFa42Vk5OjDW2Mi6vxcbR+PvzwwypsO/vss+XGG2+U4OC6H1pJSYk66XLxl/L+9lM7LKetPwY7PBYrS0gIUD9i7dtXSUVFuXh69i2Ps29hSfZWrYIlPT1Adu4sk+ho798nj7H9+eoYO9++XX7XWQV/ju2Px9h+XJ8z8feH68fJh8rLRSorMb1fpE0b7WNlZfL55wHy0EPa33xHHFElH35YIaeeWntbwcyZCEuCZOzYSgkJqThoXJtVfo4RZmFl0PySfIkIijBsO+JC4mRwm8GyOm21zN05V6YfMl3MrrKissa56+NJy0uTPbl7pHUEKyKsqszDP8eNuR3LBGsYHIqZa2eddZbExMRUf/z666+X4cOHS3x8vCxcuFDuvPNO1Q763HPP1Xlbjz/+uDz44IMHfXzWrFkSEWHcE5SnuVb8kW99910vERkgrVqlyW+/Lfba/fA4+05U1CRJT4+VH39cJsnJvisX5zG2P28fY+fh2zNnzpSwsDCv3h8djD/H9sdjbB91PWfyGBvMadb27t1RcvPNWjti27YFsndvpJx1VpBMnbpTjjwyUXr0QEGGdt2MjDB55JFxeCUnnTptlt9+21LnXVjpGKdIzdnjvjY0eKisltUya/0sGVeM/WsNe1bXvVDBf1v/8+m2kHd46ucY48ncFVBlkjVy8U7Q999/LyeffHKtSeFpp50mycnJatlr52DN1XvvvSdXXHGF5OfnS2hoqNsVa507d5b09PR6b9sqsL/wzXT00UeLA/XOZIhJk4Jk4cJAeemlCrnyyoPfGWkuHmffO+mkIPn990B5441yufhi7z918hjbn6+OMWaatmjRQl3OyspSiwKRb/Dn2P54jO3H9TkzJCSEx9hIRUUimzeL9O0rEh6u/jluXLCsWxcgkyZVyi+/VMittwbK668HVX9J//5VcvbZlaqS7YILgmTbtgDp1q1K5s8vr3VFUCv9HCfnJsvq1NXSMdbYIc67cnbJ9G+nS1BAkMw6e5ZEh/qgnaMZUKmGUK3dkHYSGHRwu2dRWZHkl+arhRmw+ipZT5mHf46RE7Vq1Up1TjaUEwVbYeecccYZsmvXLpk9e3aDD2j06NFSXl4uCQkJ0hdPvrVA4FZb6Iadb/Yn0saw2+OxkrQ0kUWLtMunnBIkDseBX/SexuPsO507a+epqcFqRoev8Bjbn7ePMaqxn3rqqerL/H7yPf4c2x+PsX24PmfqraA8xgZBO1ZgoAhG/Tgccu+9IuvWoVJN5PPPAyUyMlCwFh7WuHv/fW3m2saNAXLvvUHqutCtm8icOQHSqVP9x88KxzgqLEoCggMkIDCg+nvTCN3ju0u3uG6SkJ0gi1MXy5SeU8QKEKrVFqxFBkVKZkmmpBenS8uoloZsG3mGp36OG3MbwVYI1bZu3Sr//POPtGzZ8Df4qlWrJDAwUNro/fdEBvj1V23hguHDRTp1MnpryFP01V137zZ6S4gaB9UWt956q9GbQURkyedMs8/d8ifr14s8+6x2+a23RPT165AvHXusdsrJEfnmG5GPPxaZO1ekRw+R2bNFunYVW8ACBiFBIWoBg7DgMMNXB0WwNm/XPMsEa/VBpRoWMega19XwfUvWYmiwhnbNbdu2Vf97586dKhjDvLT27dvL6aefLitWrJBffvlFKioqZA+WWRSsxhevfuEtWrRIlixZIpMnT1Yrg+LfWLjg3HPPrS7fJjLCTz9p53jnjOyDwRoRERGRMfCm9VVXaWsZnHRS3a+zY2NFLrlEO6GLJCoKlYdiG+HB4RIaHCrF5cWGhz+Hdz1cPlz9oSxIWiDlleUSHGjquh23grXE3ERJK0iTLrFdjN4cshBDv/OXLVumQjHdTTfdpM4vuOACeeCBB+Sn/enE0KFDa3wdqtcmTZqk2jm/+OILdV3MTOvevbsK1vTbITIC5j7MmqVdxi99sl+wlpxs9JYQNQ7enMIbVYAFf4KwzC0REbn1nEnm8OEnQTJ/vhaSvfSSe19jxyamoMAgFQCl5ftuIa26DGw9UOLD4yWzKFNWpK6QUR1HiZWhtTbSESm7sndJh+gOlg8KyXcM/U5BOFbf2gkNrauAX3SLF3tvtUWixkBBJToFVq/GCiLaPK4hQ4zeKvIkva2XFWtkxRXuRo0aVV0tzsULiIjcf85EpwwZq6Q0QO56QJt39MADIl38vJgoLjROdufuNkXIN77zePlpy0+qHdTqwRrEhcXJnvw9kl6YLu2i9vcaEzXg4Kl9RNRoKDPv3Vv7JT9jhvYxlKcbOE+UvFixlpmpVSYSERERkfd98lu8pO4JVK/F/vc/o7fGeBEhEQ0WofiyHRTm7pprmm1qDlSpYaXTxJxEWzwe8g0Ga0Qe8O+/eEdTu1xQoJ2fdpqhm0ReEBenVnlXWLVGRERE5CVoA0lJUeeVlSLPfNJWffjGG7G4hNEbZ445a6gWw1wzo43pNEZCg0IlNT9VtmUemJ9uZWhv3Zu/VzKKMozeFLIIBmtEHrBsmXZ+1lkiP/wg8v33Ik7jA8kmUIHIdlAiIiIiHwRrqanq/Jffg2RTQrjExFTJZZcZvWHmEOGIUAsXYAEDo2E79BZQVK3ZARaHqJRKSc7lYGVyD4M1Ig8GaxMnagsWnHyy0VtE3sKVQYmIiIh85+kXtLHgV11aLjExRm+NOYQEhaiqtZLyEjGDiV0nqnPMWbOL+LB4Sc1LlZziHKM3hSyAwRpRM6H1fvly7fKhhxq9NeRtXBmUiIiIyDeW/Bco/y4MkpCQKrn+eqO3xlyrV8aFx0lJhTmCtfFdxqvzDekb1NB/u1QFoiLQDItEkPkxWCNqpoQEbZi9wyEycKDRW0PexlZQIiIiIt/46dcgdX766QHSoau2KihpokOipaKqQsygVUQr6d+qv7q8MGmh2AVWCN2dt1sKywqN3hQyOa2uloiaTK9WGzxYJDTU6K0hb2MrKFmRw+GQ+++/v/oyERHVjc+Z5rFwiVYHwtnFBwt3hItUoXumSlWwmaFqbWP6RpmfOF9O7Hui2CW8TMxNlD15e6RHfA+jN4dMjMEakYfmq7EN1D+wFZSsKCQkRB544AGjN4OIyJLPmWUYpE8+V1YusnSZFqwddpjRW2POVkUM2Uc7KBYQMEOw9vaKt2XJ7iVSVlEmjiDrh9IILFW4lpMonWI7qdl2VLeS8hIJDgxWK9b6G7aCEnkoWBsxwugtIV9gKygRERGR963ZGiGFhQESFyfSr5/RW2M+WLxABWsmWcAAraAtw1uqtskVe1aIndpBs4qzJK0gzehNMb2N6RtlX+E+8UcM1oiagQsX+G/FGlaArzDHWAuiBlVWVsr69evVCZeJiKhufM40h4WrI9X52LEigfyr9SCoCooJjVED9s0gMCBQDuuslRb+m/iv2AUeFyoCUbVWUckX/3UpKS+RvJI8qazyz+dMPkURNcOOHSLZ2WgZEBkwwOitIV9o21Z7cYdQbe9eo7eGyD1FRUUycOBAdcJlIiKqG58zzWHhmih1zjbQusWFxklpRamYxYQuE2wXrEF8eLzsK9hnmxVPvaGwrNA0Ia8RGKwRNYNerTZkiBaukf0FB4u0b69dZjsoERERkQdhnl1KijpfuEarWGOwVrfIEG0fmcXojqPVjK2k3CRJyE4Qu1BzwwKCZFfOLr+tyGpIQVmBFJX77xsRDNaImoELF/gnLmBARERE5KVgLTVVkndVSOKeUAkMrJJRo4zeKHMHa1gkwCxVa9ieEe21wdNYHdRuVWt78/dKRmGG0ZtiSvml+VJabo7vQyMwWCNqhtWrtfPhw43eEvKlLl208127jN4SIiIiIvtZ9F+wOh8yqEqitI5QqmNlUMz/MlML3uFdD1fn83bNEzvBQhFVUiXJuclShUHbVK2qqkrSC9LV/vFXDNaImkGvWOre3egtIV/q2lU7Z7BGRERE5HmLljnU+WFjOCy+oRZFLGBQVGaeFrzDu2jB2uq9qyW7OFvsBKuepuSlqFVC6YCSihIpLC8Uf8ZgjagZ9BlbHToYvSXkSwzWiIiIiLxnyXKtYm3sKM6zakiLsBamaQWF9tHtpU98HzWLzG6LGKA6sLyyXFWt0QEFpdp8tUA/Xr7Xfx85UTMVFIjk5NScuUX+oVs37ZzBGhEREZFnVVaKrN6gBWvDRvDPVastYAATu01U53N3zRW7way13bm7Jad4/x+CJFgRFO2gWODBX2nPWETUaFiwCCIjRaKjjd4a8iVWrJHVOBwOueWWW6ovExFR3ficaawdu0OloCBAQkNF+gzg/m/MAgYhQSFilnbQt1e8LYuTF0tJeYmaT2anuXYZRRmqai02LNbozTGFnJIcCZRAqRT/rTBlsEbUzGANbaABAUZvDRkRrGVkaJWLCFeJzCwkJESefvppozeDSDZtEmnTRiQ+3ugtIXL/ObMMK1WSz6zeEq7OBw4UCeZfq24vYIA5a2YJ1vq16ietI1rLvsJ9six1mYzrPE7s1n6LYK1zbGc1486foVItsyhTwh3hUlBWIP6KtbVEzQzW2Abqf2JjtROwao2IyD0rVmh/KE+YIFJqnnFARGQyq7dqwdqQIUZvibUWMDDTyqABAQG2XR0UokKiVPsjFjLwd5itVlRWpMJdf8ZgjaiJuHCBf9Or1hISjN4SooZVVlZKQkKCOuEykRFee02kokJkwwbtMpFZ8TnTx1ARiHes91cGrt4Soc4ZrFl3AQPQg7X5ifNVVZMd93liTqLkl+aLvy9cUFxezGDN6A0gsipWrPk3zlkjKykqKpLu3burEy4T+VpensgXXxz494MPiqSnG7lFRHXjc6aPIVBLTT0QrLFirdGiQqPEbA5tf6gKW9IK0mRL5haxm+jQaBUq+XvVGhZxqJIqCQzw72jJvx89UTOwYs2/MVgjInIfQjXMpOzTR2ToUJHsbJH77zd6q4jIbPDcsCtVG3Q/eLDRW2OtOWtYwAALBZgFFiwY3XG0ujx/13yxo9jQWEnMTlRtof4IlYiYoxcerIXh/ozBGlETsWLNvzFYIyJy39tva+eXXSby/PPa5TfeEFm82NDNIiKTWbNO+/O0S+dKadHC6K2xjkhHpBoej3lXZjKhywR1/m/Sv2JHmG2XW5orqXmp4o8QKOaW5Kpg198xWCNqIlas+TcGa0RE7lm9WuS//0QcDpELLhCZNEnkjDMwx0rkuONENm40eguJyCxWr9X+PB0yiLPtGiMoMEjN/DLTAgagrwa6Pm29ZBRmiN1gkYaYkBhJyE4w3b73hbzSPBWuhbNijcEaUVNg/iYr1vxbt27aOYM1IqL6vfOOdn7yySKtW2uX331XZNQokcxMkWOOEUlMNHQTich0wZr9ht17W4tw8y1g0DqytfRv1V/N4FqYvFDsKDYsVnJKcmRv/l7xN9nF2Wq2WkBAgPg7BmtETYA/BEr2jzBo397orSEjK9Ywa1f/XiAiooP9+qt2fuGFBz4WFaV9vF8/keRkkRNP1FYMJSL/tnqt9gc6K9aa1g6KkKOyylz7bnyX8dWrg9oR9nmUI0pVrZkt2PQmfJ8hTGQbqIbBGlET6NVqrVqJhGrzVcnPoOoiPFyrXkxKMnpriIjM+0bUzp3a5cMOq/k5/A6dNUvUHCW0i37yiSGbSEQmUV4usm4DW0GbKjIkUq3CabaWRH3O2uLkxVJWoa38asdqwYyiDL+atZZfmi8FZQUM1vZjsEbUBJyvRqh47tJFu8x2UDK74OBgufrqq9UJl4l8ZeVK7bxHD5G4uIM/37mzyB13aJfvu48VwGQOfM70kbIy7d1qnIvI1m0BUlwcIJERldKzL/d7Y2HOFUKOojJzLWDQr1U/aRneUs3iWp66XOxctbYza6epVmb1prySPPVYEeYSgzWiZlWsMVjzb1zAgKwiNDRUXn31VXXCZSJfWbFCOx8+vO7rXHed9vsUc9awUiiR0fic6SMI1DBTY3+wtn6j9qfpgIGBEhjqMHjjrAdzrhBgmW1lUIROetXa3F1zxa5QtZZVnCV78veIP8gsypSggCCjN8M0GKwRNaNijQsX+DcGa0RE7gVrI0bUfR201T/wgHb5kUdEcnN9s21EZC4Ju7T5aj17Gr0l1hUTFmO6GWswqdskdT5v1zypwhwVG0KAiDl3/lC1Vl5ZLumF6ar9mDQM1oiagBVrBAzWyCrwInbfvn3qZNcXtGROy5c3XLEGF10k0revSHq6yJdf+mTTiOrE50xjJCQG1Fh5nRoPwU5wYLAKPsxkZIeRqlV1b8Fe2ZS+SexctZZZnCmp+an2n69WWqC+30jDYI2oCVixRsBgjayisLBQ2rRpo064TOQLqDzbutW9YA1jrE45pWYYR2QUPmcaI2GX9qdp9+5Gb4l1oYIIAZbZFjAIDQ6VMZ3G2L4dFFVr0SHRkpCVYOuqtdySXCmrLBNHEFu2dQzWiJqAFWvk/I6qvuIdEREdsGqVdo6FXrACaEOGDau54AER+WcrKCvWmi4kKESiQqNMt4ABTOw60fbBGsSFxalZa3auWsN8NUcgQzVnDNaImoAVawR9+mjnGLjNN7SJiJrWBuoarK1ZI1Juri4mIvIydNyyFdQzWoW3Ml3FGozvMl4Nu9+auVV25+7/Y8quK4SGRNm2aq2sokwyCjM4X80FgzWiRsKL/b17tcusWPNvrVuLtGypvRjcvNnorSEist7CBc4wsDw6WqS4WGSTfUfwEFEtMnKCpKAgoLrKlZoOFWtV+M9k8wFRyTW03VC/qlqz4wqheaV5UlBWIBGOCKM3xVQYrBE10p49WpASFCTSpo3RW0NGCggQOeQQ7fKGDUZvDRGROYM1dyvWAgNFhgzRLrMdlMimysq0mSo4d5KQElr9pnWodpGaCAPlw4LDpKTCfNVS/tIOaucVQvNK8qSiskItkkEHMFgjauJ8tfbttT8CyL/176+db9xo9JYQEZlHZuaBqjN3gzXgnDUim0OglppaS7AWos7ZBtp8aNFDNZGZ56yt3LNSsouzxc70FULt1va6r3CfmuVHNTEWIGokLlxAzlixRkR0sOuvF6msFBk4UKRdO/e/Tg/h9Go3IvIPCalamRqDNc9US8WHx0tRufmCtY4xHaVPfB+prKqUfxP/Fbsfh9jQWNmZvVMKy+wxjBnVd9lF2aoaj2pi/R5RIzFYI2cM1sgKgoOD5YILLqi+TORNX38t8umnWlX3O+807mv1ijWsKIqxC2i5J/I1Pmf6mMMhCTnh6iKDNc+IDYuViqoKMaOJ3SbKlswtMidhjhzf53ixMwRribmJkpybLH1a7l/1zOrz1coLpH1ke6M3xXT4m4KokVC9rreCEunB2rZtIqWlIiGsjCYTCg0NlQ8++MDozSA/+R151VXa5bvuEhk9uvHPqXgezckR2blTpEcPr2wmUaOeM8tc2hbJC8HaPm0QOoM1z8CqlKiYKq8sN90srMndJsvbK96WRcmL1OqlmAdnVwEBAdIirIUkZCdI+6j2Eh0aLVaWW5IrVZVVEhQYZPSmmA5bQYkaicEaOUPlYkyMSEWFyNatRm8NEZGxbrpJJCNDqzy7997Gf73DobWPAuesEfmPhATtnMGaZ6BVLzw4XAVXZtM7vrd0iOqgFldYnLxY7C4mNEYKSgskMSdRrAyrzKblp9k6CG0OBmtEjcRWUHLGlUHJKi+GCgoK1AmXibwBi7h8+aV2+b33ml7Bq7eDcs4aGYXPmb6FXcxgzbNCg0NVdZQZFzBAFRfaQQHtoP4AM+8QrFl5wQbM7MspyVGLY9DBGKwRNRIr1sgVgzUyu8LCQomKilInXCbyhsce0/5APvlkkaFDm347+gIGrFgjo/A507dQ5VpQoF3u0sXorbGPVuGtTFmxpreDwvzE+apd1R9ac0srSlVLqFXDerSBIlxDJSQdjMEaUSMxWCNX/ftr5wzWiMhfbd8u8tln2uV77mnebekVawzWiPzDzl2B1d0godrioOQBUaFRUoX/TBjkDG47WOLC4lQF1Ko9q8QftIpoJUk5SZJemC5WhGq7APzHVYVqxWCNqBHKy0XS0rTLDNZIx4o1IvJ3jz8uUlkpMnWqyIgRnnlO3bNHJD/fI5tHREbDAhCYp1LLQhAJu7Q/1Lt3N2C7bD5nDfOwMMvMbLCgwoQuE6qr1vyBPptsZ/ZOqayqFCvB9u7N3ysRDm2REToYgzWiRti7V2tzCQoSad3a6K0hs9D/CNyyRQtfiYj8yaJFIh9+qF1uyoIFrmJjRVq00C5jZVAisgEEamj7qCdY43w1z8IsLAQhhWXmbGce13mcOl+YtFD8ReuI1pKalyppBfsrNSwiryRP8kvzVVhLtWOwRtSENtC2bbVwjUifBxIRIVJaKrJjh9FbQ0TkXcXF2vMdfP+9yBFHaG8qTJsmMnasZ+5Dr1xhsEZkfwmJDNa8ITAgUAU5mItlRqM7jpaggCBVwbU7d7f4A0eQQ1XrYdZaRWWFWGm+GmbEYVEMqh2DNaJG4Hw1qk1gIOesEZF/WLdOJD5eJCxMpGNHkdNO04K2448/sCKoJzBYI/IfCftnrDFY87zYsFjTBjhYtXRI2yHq8sJk/6laaxneUrVV7ivcJ1aRWZQpjkCH0ZthagzWiBoBoyGAwRq50oO1TZuM3hIiIu95912RoiJtLAJ+J+L8qqu0yrWoKM/dD4M1Iv/BijXvhlchQSFSUm6+OWtwWOfD/K4dVK9a25m107Shp7OyijK14ALnq9UvuIHPE1EtFWtYtYjIWb9+2jmDNTKjoKAgOf3006svEzUFFif45hvt8gcfaPMlQ0JEBg8W8fQiYQzWyEh8zvQRh0Mq27aX7Tu0J5AePYzeIPvBTCzMWkM7qBnb+DBn7ZX/XpGlu5eq8M+M2+itFUIxa21vwV7pEN3B9G2gBWUF0jayrdGbYmoM1ogaga2gVBcGa2RmYWFh8vXXXxu9GWRxixeLJCeLREeLnHmm1g7qLXqwxrmVZIbnzLJaBu6TBzgcklTRQUpK1EU1s5Y8KygwSLUeojoqLixOzKZXfC9pE9lGDfNfkbpCxnb20KBOk0PFGkLE7ZnbVciGqkKzyinJkcrKSrXNVDe2ghI1AoM1cidYQ2sUEZHd6DnDiSd6N1RzrlxBxRqfU4nsa+tW7bxnT5Fg/t3uFS3CW0hFlTlbDgMCAuSwTlo76IKkBeJPEHhizlpSTpKYVVVVlaTlp0lYsJd/6dsAgzWiJsxYYysouerVS1vEICdHZO9eo7eGiMh7baDTp3v//rp21c4LCkTS071/f0TkBaj0w4vneir+9GCtd2/fbZa/iQqJUhVRmJVlRuO7jFfnc3fNVUGOP1UTxobGyo6sHZJfmi9mVFhWqCrW0E5M9WOwRtQIrFijuoSGHqiwYDsomU1BQYF6VxgnXCZqThvolCnevz9UxOlvYnHOGvkanzM9BIEaXjwzWDM8WAt3hKs5WWY0ptMYVRGVmp8qm9L960U02nPzSvNUq64ZQ0XMVysqK5Lw4HCjN8X0GKwRuami4kAlEoM1qg3nrBGRXfmyDVTHBQyI7G/LFu2cwZr3YDYW2g4RkJgRQjV9ddDZCbPF37SJaCOJOYmSUZQhZpNVlCUBgdqbDFQ/BmtEbtq3TwvX8LzSlouiUC0YrBGRXf31l3Z+6qm+u08Ga0T2p1es9elj9JbYf85aWaU5W0HhiG5HqPO/d/5tysotb0I1YWVVpVrIoKLSPLPwsC2YARfliDJ6UyyBwRpRI9tA27ThcFWqHYM1IrIjvKmk//E7bJjv7pfBGpG9lZcfWPmXFWveFR0SrSrXyivLxaxz1jAHDpVb27O2i79pHdFatcLiZKY20LySPIl0cL6aOxisEbmJ89WoIX37aucM1ojITpKSREpKREJCRLp08d39MlgjsreEBC1cQ3t5x45Gb43956xFOCKkoLTAtNs3uuPo6qo1f+MIcqg5ZqhaKykvEbMEa6hyxLZRwxisEbmJwRq5W7G2a5dIYaHRW0NE5Bl6tVrPniJBQb67XwZrRP7x3KKvrE7eg3CkZURLKSo355w1OLL7kep89k7/m7MG8eHxas5aQnaCmAHaQFFFSO7hUxiRm7BaOOirlBG5atVKpGXLmsN4iYisTn8+8/UMJD1Yw5sVaEclIhtwOLR3qR0OzlfzsRZhLaS0olTM6vCuh0tQQJBqBd2VvUv8TWBAoFpkYkfWDsksyjR0W4rLi9XCBagkJPcwWCNyEyvWqDFVa5s3G70lRAcEBQXJtGnT1AmXiawQrHXqpM00LSs78OYWkS/wOdPLwRrepXY4uCKoj0WHRktQYJBp56zFhMbIyA4j1eV/Ev4Rf4QgC+2XWzO2Gnqc0AZaWFao2ofJPQzWiNzEYI3cwQUMyIzCwsLk119/VSdcJrJCsIY8Q5/pxnZQ8iU+Z/qGXrHGYM13oQ0G0SMwMasjumurg85O8M92UGgb2VZS81Jld+5uw7YhpzhHrc6KKjpyD/cUkZsSE7VztoJSfRisEZHdGBWsAeesEVmMXmKK8wYwWPMtzMuKC4szdbA2setECZAA2bBvg+zJ3yP+CKu3IgTdmL5RtcRWVPp2FkJlVaXszd/LarVGYrBG5AashrZ2rXZ58GCjt4bMjMEaEdlJaam2cp9Rf/zqwdr27b6/byJqAgRqaPNoIFjDa2vMTwTOWPMdLGBg5jlr2L6h7Yaqy3MS5oi/ahHeQhyBDlmZulJW7VmlKsh8Jb80X3JLcyUyJNJn92kHDNaI3LBunfb6oEWLAy/yiWrTt++BGWtVVUZvDZGmoKBAIiMj1QmXidy1Y4dIZaVIVJRIu3bGvVmxcaPv75v8F58zffvc0rat0VvjP6JDoiUwMNDnVVCNMbnbZPH3dlBAdWG7qHaSnJssi3cvlm0Z26SkvMQn89VwP2HBbINvDAZrRG5Yvlw7HzFCJCDA6K0hM+vWTZsLVFR0YC4fkRkUFhaqE1FT20CN+P03aJB2rleNE/kKnzO9S1/kCZWwfG3t4zlrweaes6YHa6jUMnp1TKM5ghzSKaaThASGyJq0NbI4ebEK2ry5sEFGYYZqRyULBWvz5s2TE044QTp06CABAQHyww8/1Pg8Bubdd9990r59ewkPD5ejjjpKturN+PtlZmbKOeecIzExMRIXFyeXXHKJ5Ofn+/iRkN0tW6adH3qo0VtCVljsCuEabNtm9NYQEVl3vhoMHKid4+VfcbEx20BEnvfTT9r5qFFGb4l/CQ0OlbjwOCkoM28lZvvo9tK/VX8162vernlGb45pVkztHNNZisqK5L/d/8nS3UvVAgeerjxEG2haQZoKYMlCwRpKq4cMGSKvvvpqrZ9/6qmn5KWXXpI33nhDlixZosqxp0yZIsVOr6wQqq1fv17+/PNP+eWXX1RYd/nll/vwUZA/VawxWCN39OqlnTNYIyKrMzpYw0rc8fFayxjbQYnsAVX933yjXT7nHKO3xv+0jmgtZRUNLy5hinbQnf7dDuoMK3S2jmwtHaI7SFZRlgrXluxeolYP9cTxRJC5LXObCtfQMkwWCtamTp0qjzzyiJxyyikHfQ7Vai+88ILcc889ctJJJ8ngwYPlo48+kpSUlOrKto0bN8off/wh77zzjowePVrGjx8vL7/8snzxxRfqekSegBxXb0FBKyhRQxisEZHdgjWjVu1Di5hetYZ5p0Rk4ZJ+JOUOh/z8s0henkjXriLjxhm9Yf4nOjRaggKDvNpO2FxHdj9SnSM4yi7ONnpzTAVtmpi9hlN2UbYK2BYkLlAz2LDIAXKUpsAqrFiFtE1kG9VNSI1j2ubZnTt3yp49e1T7py42NlYFaIsWLZIZM2aoc7R/HupURoTrYyAjKtxqC+ygpKREnXS5ubnqvKysTJ2sTn8MdngsZrByZYCUlQVLy5ZV0qFDuTurh/sEj7N5de+O9yyCZMuWSikra3qJNo+x/fnqGDvfvl1+11mF1X+Ot27FS8UA6dEDv/+MWZFlwIBAmTcvSFatqpAZMyrFbKx+jKnh50z9j0weYzeUl2slpjgH/TKCtdat1Yc++gg/x4EyY0aFVFRUSoUJ5uj7089xWECYhAeGS35RvsSExYgZdY7uLL3je8vWzK0ye8dsObnvyc2+zcqKyhrnVhcogdI6vLVqB80ryZO1qWslJDhE4sPjpX1Ue3VsoxxRboVkxWXFsnnvZgnBfwEhTd9HFSIV5RWG/Rx5+ue4Mbdj2mANoRq0dVkmBv/WP4fzNm3a1Ph8cHCwxMfHV1+nNo8//rg8+OCDB3181qxZEhERIXaB9lhqvj/+wMCsIdKlS5r8/vtiMRseZ/PJysLz1hhZuTJXfvttbrNvj8fY/rx9jJ1HKMycOVPCwrjSk69Z8ee4qChIUlKOV5d37pwl+/YZ80K5qkr7PTxnTrr89pv5fg9b+RhT454zeYwbwbl7yOlybm6I/PHHFHW5U6e58ttveWIm/naM88W8s8lHh46WrbJVfl39q4wq8Nwwvj2r684JrB60lUu5pO3/r6lSpOmdfwESICu2rRC7/Bw3ZgEb0wZr3nTnnXfKTTfdVKNirXPnznLMMceoRRCsDskqvpmOPvpoceDdIWqWH38MUufHHNNKpk2bJmbB42xePXqIPPqoyL59sTJ16rQmr3bFY2x/vjrGRUVFcvjhh1ePYcCCQOQbVv45XrlSO2/dukrOOONow7YjLi5A3nhDJC2tjal+D9vhGJN7z5l4457HuBED1LDkZ9++2r/1y/t/77zxRqBUVATKsGFVcsUVE8Qs/O3nGHO5VqaulE6xncSsTss9TT755hNZW7BWwvqHqUqs5kAVFkK1dkPaSWCQoROxfKK4vFgKSgukpLxEtYc6gh0SFhymFkLADLWQoBA1V21H1g61KEKbqDbNXg10d+5uGdFhhGpTtcPPsd7ZaOlgrV077WDs3btXrQqqw7+HDh1afZ20tJppbHl5uVopVP/62oSGhqqTK+x8Oz2R2u3xGGXF/tB99OggcTi0kM1MeJzNB0O+Eabl5QVIdrZDXAprG43H2P68fYxx23PnNr96kvzr53jHDu28d+8AQ7d9/8s+SU4OkPx8h7RoIaZkxWNM7j1n6u1A/2/vLuCkKrs/gP9mZ7t32aS7G0kLJUQQRbB9zdfuALt91b/62mK/YmGBgdIgoQhId3c3S2zH/D/nPswuS27MzHPj9/VzP/eyLLtnvTt3Zs49zzk8x2Ug/6+CgmQZkfqz9/jI/7fvvlMfvu46vdeVk3HKOY6Pijd+zkIUIsRtzp+3RkINNE1qimV7lmHKpim4rOllPvm6klRzQmIt0h2JyLDIUok2SbLtzt6NbZnb4IHHSKxJkq16tI8SrG7AHSzvmUNs8Tguz9cw7W9UnTp1jOTYH3/8USpjKL3TOnfubPxZ9hkZGZjrHdkok0MmTUJRUZHRi43IFzfdli5Vx5wISmUlefuaNdUxBxgQ0bHM0E+oLBYtUnvv8ABd4uKAGjXUsfc5mYisZ+NGYMYMdfPxqqt0R+NskkyJCo1CZn4mzKxHPVUtPWGds5bo+oNUq8WFxyE1OhXVY6ujRmwN1IqrVelKQDJBYu3w4cNYsGCBsXkHFsjxpk2bjCZ7DzzwgDE19LfffsPixYtx/fXXo2rVqujXTzUvbNKkCXr16oVbb70Vs2bNwt9//4177rnHGGwgn0fkizcV0m9Veq1WN2+lNJkQJ4MS0dG2bJFWFFL9rJLv998P0zvy8qy4YkynFi3U3julm4isZ/hwtZdVtkctSCINZCpoUmSSsVTQzLrXUYMM522fhz1Ze3SHQ2TOxNqcOXPQpk0bYxPS90yOn3nmGePPjzzyCO69917cdtttaN++vZGIGzt2bKmmy0OHDkXjxo3RrVs3o+/GWWedhU8++UTbz0T2MmyY2kuRJKcOU3kwsUZmkpmZieTkZGOTYwq8u+5y4//+D5g1S1Wsff65WjFlZmZKrHmr5pYs0R0JOQGvmRUgFzQZUnCKC5v3dfXllwcuLDq5hIgEFHrMXUKdHpOOFiktjGWLE9dN1B0OkTl7rHXt2tVopHcyUrX2wgsvGNvJyATQb7/91k8RkpNJr8JPP1XHt9+uOxqyGibWyGz27OGdXl0OHw7GxInq7swHHwBPPQXs2wdIJ4tOnWBKO3cC27erm0reajGdWLFGgcZrZjlJQk0uGrVqlXxM+hNJaVpIiLEM9J9/1DVlwACdgZKXNLEPCw4z+m7J3qx61O2BxbsWG4m1q5pzDTGZk2l7rBHpJtUEklxr3Bjo1Ut3NGQ19eqpPRNrRDRnThoKClxo2hS48065sag+PmkSTGvhQrVv0ACIjjZXYu0U92SJyEwksSbteUJCSi0DPcWMOQqg6NBoRIWYv89atzrdjP2CnQuwK7P04EIis2BijegEZJnOO++o4wcfVAONiMqDFWtE5DVzpmom1L+/+vP555s/seZdBnqkW4d2cpMrKgrIyFCVfkRkLT/+qPZXXKE7EvIKcgUhOTIZWQVZMDNptt8qtZVx/Mf6ksGGRGbCdAHRCfz6K7BhA1CliowD1x0NWVHdumq/f79a8kVEzpSVBcybl2IcX3pp6cTa338DOTkwJTP1VxMy8KF3b3X8yy+6oyGi8pDX1NJfUpaBem8wkHn6rHmKPKdsz2SW5aCC00HJrJhYIzqB995T+7vuAiIidEdDViSVFd7hxKxaI3KuCRNcyMsLRq1anuLqL6m+krZDklSbOROmZLbE2tGJyZ9/1h0JEZXHyJFqz2Wg5hMTFoPwkHDkFJj0Ls9Ry0FdcGHRzkXYcXiH7nCIjsPEGtExpLror7/U8S236I6G7LAcdPVq3ZEQkS4jRqiXWpdcUlQ8XVr2Zl4OKlV2K1eaL7HWpw8QGgqsWAEsX647GiIqKxlaIM47T3ckdCzpsRYdEm36PmvJUclok6buTnE5KJkRE2tExxg/HigqApo3B2rW1B0NWVmzZmovyx+IdAoKCsIZZ5xhbHJMgRuSN3Kkyqb161d6mY2ZE2syIECeB1NTzVVdEhsLdO+ujrkclPyJ10z/JNY6dtQdCR3L5XIZPcyy87Nhdt3rqieA8WvH6w6F6Dh8piA6xpgxan/hhbojIavrpoYYYeJE3ZGQ00VERGD27NnGJscUGFL9nJHhQlxcLjp3PnFiTd5wHj4MUzHjMlAvLgelQOA1s5KTQGWtu+yPrATxVu63b683NDqx2LBYI8FW5CmC2ZeDysCFpbuXYvOBzbrDISqFiTWio8gd+rFj1TETa1RZsuRBlnwtWwZs3ao7GiIKNO/zSdu2O+F2l/672rWBOnWAggJg2jSYipkTaxdfrCZ1y2TQjRt1R0NEx5GEmjSZPZJYmzNHfbhePTUUjMyZWIsIiTB91VqVyCroWE2VPY5de+QJlsgkmFgjOsr8+cCuXUB0NHDmmbqjIatLTATatVPHf7AdBJEjWwuI1q13nfDvzzpL7WfPhqmYObGWklLy/00meBORuXnbYXAZqHlJUi02NBbZBeZOrIle9XsZ+zGrx5h+kik5CxNrRCdYBio9XKRBMlFl9VDTwbkclLTKyspC7dq1jU2Oyf927AAWLpSqVQ9at959ws/xTgmVmzpmIRV0ErdZE2uif3+153JQ8hdeM32fWOvQQXckdLpqMLNXrImutboizB2GTQc3YdmeZbrDIapcYi0zMxNPP/00unTpgvr166Nu3bqlNiKrYn818jVvo21JrPHGGukid3U3btxobLzDGxgTJqh9mzYexMXlWSaxtmQJkJ0NxMUBDRvClLx91qSH3c6duqMhO+I10zfkf513cAETa+ZfDgqX+t03s6jQKHSt3bW4ao3ILIIr8o9uueUWTJ06Fddddx3S09ONZodEVifNVWfOVMdMrJGvdOkChIcD27erXmveSaFEZG/jxql99+4nf5PirQjbsAHYvx9ISIB23jfB0mTcrMMQZWK3LLOXPmu//QbceqvuiIjoRDZtUi1WgoNLbiSQOUWHRiM8OBw5BTnG0lAzu7D+hRi3dhzGrxuPBzo9gOCgCqU0iHyqQr+FY8aMwahRo3Amm1CRjUhFkQwvkMRHjRq6oyG7kKTaOeeoXkvyO8bEGpH9yXOJt79az56ek079jI9XAwzWr1d9zWTgiW5WqS6R5aCSWPvlFybWiMy+DLRVK/V6iMwrMiQSUSFRyMrPMn1irVP1TogPj8e+7H2YtXUWutToojskoootBU1ISECidOUmshHvVLbzz9cdCdl5OSgR2Z/0KNu9Ww3C6dTp1MtqzLYc1CqNxr191uS6euCA7miI6ETYX806ZAVaclQysgvN32dNKtR61FVNjEevHq07HKKKJ9ZefPFFPPPMM2zmSbYyY0bJ0j0ifyTWZDLo2rW6oyGiQC0DlQq00w3CMVNi7eBBtWTdCom1xo3Vlp8PjBqlOxoih5IH4LZtan+KClizX0+opM9akZRcW0CfBn2M/eQNk5GZl6k7HKKKJdbeeOMNjBs3DqmpqWjRogXatm1baiOyGskRyzIc0bmz7mjIbqSP0llnqYbgV1wB5ObqjoiI/KlkGejpP9dMibU5c1Sz8Vq1gNRUmJ63ak2WgxKRBpJQkyaysg8JAdLT1f7IknhZru3t2UjW6LMW6g5FboH5X6g2S26GWnG1kFuYi0kbJukOh6hiPdb69evn+0iINL+ZKCgAqlZVTZGJfEnmu3z3nUqwzZsHPPww8P77uqMipy3xaNq0afEx+Y8k0P/+Wx33UCtVypRYW7FC/dsIja1trFZdIom1l18GRo/W//+O7IXXzAqQhJq8kD5CCtnkxrUMLjDrhGEqTXqsydTN7IJshAWHwczkcSlVax/M+QCjVo1C34Z9dYdEDlehxNqzzz7r+0iITLAMVKrV+PqJ/KF6deDrr4HevYHBg1Uly8UX646KnCIyMhJLly7VHYYjTJ8O5OUB1aqpN5Ny0+ZUpMAjJUVNzlu8WG8vIqsMLvCSRRLy/3nrVuDPP4ELLtAdEdn1mpl/kqWOdHJr1qi9DGiR5BqZnzvIjSoRVbAhY4MxHMDsejfobSTW5myfg+2HtiM9Jl13SORgFVoKunnzZmzZsqX4z7NmzcIDDzyATz75xJexEWlJrBH5y4UXAg88oI4/+kh3NETkD5MmlQzCKcuNGvkcMywHlSWgVqtYk/93cl0VUrVGROZLrNWvrzsSKo+EiAQUFJ3mjpBJpEWn4Yz0M4zjMWvG6A6HHK5CibVrrrkGkydPNo537NiB7t27G8m1J598Ei+88IKvYyTy+5sJqTAQTKyRv91yS8mb70z2WiWydWKtrLyJNVkqrovcL92xA3C7VSWYVXgTa2P4norIVFavVnsm1qwlJjTGMn3WvFVrYtTqUfDImzoiKyXWlixZgg5H1gn8+OOPxgCD6dOnY+jQofjiiy98HSORX61bB+zerSa3WenNBFmTtGypXVsNMJApoUSBIFO8mzVrZmyc6O3fqZqzZ5dMBC0rM1SseavVWraUZXCw1NRlWWYmb+I5dZl8hddM31WsNWigOxIqj5iwGGOIQVa+NX7vz69zPsLcYdh4YCOW7Tky1prIKok16TMQFqYaGk6cOBEXH2kU1LhxY2yXyTBEFlwGKkm18HDd0ZDdydKliy5SxyNH6o6GnELu4i5btszYeEfXf/76CygsBOrVU5M1y5tYkx5rp+vJ5i9WWwbqFRsLnHmmOmbVGvkKr5mVx6Wg1hTkCkJyZDKyCqyRWJMkYNfaXY1jGWJAZKnEmty9+eijj/DXX39hwoQJ6NWrl/Hxbdu2oUqVKr6Okciv2F+NAs2bWBs1Si1FJiJ78FahlmcZqJBEXEwMkJOjpoPqYNXEmuByUCJzkdc2TKxZV3xEPIo8RbAKmQ4qxq8bj/xCDhohCyXWXn31VXz88cfo2rUrrr76arRq1cr4+G+//Va8RJTIKthfjQLt3HOBqCg1in7BAt3REJHO/moiKAg48lJKy3JQqZKbO1cdW/FlnDexJu1/JTlJRHrJAiZZQSs9G8tTvUvm6bMmyytzCqxxQe1QrYMxzTQjJwPTtxx5Y0dkhcRax44djamge/bsweeff46NGzfi7bffRq1atYyEG5FVyAtwWXojOnXSHQ05hSw57tFDHXM5KJE97NkDLFxY/v5qZuiztnSpehMsyyobN4bltGgBVKsGZGcDU6fqjoaIvNVqklSTHsZkLbK8UpJrmXnWmLIVHBSMC+pdYByPXs0R0WShxNoll1yCr7/+GgkJCcjIyDCq1N544w088MADGD58uO+jJPKTZctUPxxZwVy9uu5oyEnYZ43IXkYfeS3frBmQmmqtxJp3GWj79qp6zoq9K490JeFyUCIT4OACa3O5XEiOsk6fNdGnoVoO+ufGP3Ew96DucMiBKvTyad68eTj77LONY0mkpaWlGVVrX331Fd59911fx0jkN97qApmCJi/MiQKlt5oOjlmzgE2bdEdDRJX10Udqf9VVFfv33sSaLA8PdO9FK/dX87pAFStw2jKRCbC/mvXFhccZe6sM72iY2BD1EuohvygfE9ZN0B0OOVCFEmsydjpGuuxKk8Dx49G/f38EBQWhU6dORoKNyCoWLVJ7b28bokBJTwe6qiFG+Ppr3dGQE+4+S7sG2eSYfEuqzGQQTkgIcMstFfsaTZuqf5+RAWzYgICyQ2LNu/x2yRJg507d0ZDV8ZpZOatXqz0Ta9YVGxaLiOAIZBdkwwrkcXpRQ7Uc5LeVv+kOhxyoQom1+vXr49dff8XmzZsxbtw49OzZ0/j4rl27ECsNOogslliTijWiQLvxRrX/4gtOByX/ioyMxIYNG4xNjsm3PvxQ7QcMANLSKvY1pA9R8+aVWw4qSbkRI8rXwP/gQdUWwaqDC7ySkkpukk2ZojsasjpeM8tI7gbInULZH4UVa9YnSbWYsBhk5VtoOWiDPnC73Fi6eynW7DvyS0hk5sTaM888g4EDB6J27drGIIPOR8YpSvVaG+9aBiKTk0TG0UtBiQLtssuA6Gj1AvTvv3VHQ0QVceAAMHSoOr7rrsp9rYr2WZMYXngBqFMH6NcP+Ne/yv5vZRqoPB/WrFnxpKBZeKexeqezEpGfSUKtatVSiTW5nrDHmk36rEUmW2YyqEiMSMQ5tc4xjkesHKE7HHKYCiXWLrvsMmzatAlz5szB2LFjiz/erVs3vPXWW76Mj8ivo8D37lWNmmUJDlGgRUUBl19eUrVGRNbz1VdqoqZUm511VuATa3l5gNzffPZZVbEmfvpJVa45ZRmoFxNrRPrt2gUcPqxeX9eurTsaquxyUI/8Z6FlFZc0uqR4OmheYZ7ucMhBKjz7SQYWSHWa9Fbzkumgja04p50cvQy0USMgIkJ3NOT05aA//ghkWmOqOVlQdnY22rdvb2xyTL4hvdBefVUd33ln5YfgVCSxJsPYly9X061/+AF45BH18bvvVss8nZRYO+ccwO1W1TIcCkOVwWtmxXmr1aQKNixMdzRUGbIU1Ep91kTn6p2REpWCA7kHMHXDVN3hkINYcKg6kW+wvxqZgVS41K0LHDoE/PKL7mjIroqKiowqc9nkmHyTVJOG+Vu3Ag0bAtdfX/mvKT3CJDm3bZuq+jgdKSJ4+211fP/9wBVXAM89p/oaSVyPP376f2+nxJq0+W3fXh1Pnqw7GrIyXjNPIz9fXahkfwwOLrAPK/ZZcwe50bdhX+P415W/6g6HHISJNXIsJtbIDKTo1/uGXKpNiMjcJAkuS7dlqq8k16SHkCw9lH6JlSVfw9uTqCxVazNnArNnq8EHt9+uPiYV2B9/rI4/+ED1XjvZKh4ZWiBtEaSqpG1b2AKXgxIFgCTU5OJxgsQaBxfYhxX7rImLG15s7GdtnYXth7brDoccgok1ciwOLiCzuOSSkjeC5ZnmR0SB9frrQGoqcNNNwMaNKgkmlVHVqvnue3grro5qYXtS77yj9tdeC6SklE4uPfWUOpbeazLM4ETXlpEjSz7fLoMPj06sWagtEJFtcHCBvVixz1q12GpoX7W9Efdvq37THQ45BBNr5Ei5ucCKFSVLb4h0kt9BmVYvDdD/+kt3NER0IrI089FHpfeS6s35n/8AM2b4Nqkmrr5a7b/5Rg0mOJnNm1V/Ne8y0GO9+CLwySdAcDDw7beqB9yxRo1S+4sugm106aIq+LZsKXmDT0SBw4o1e7Fin7Wjhxj8vup3FBYV6g6HHICJNXIkSaoVFADx8UD16rqjIaeTnkoXXqiOx4zRHQ0RnYgkoeSGvQwYkGEBTz6pBgb42gUXqET7nj0lFWXHkuWfffsChYVqSerJbhDdeivw25Gb9V9/rZJNXvv2AX//rY779IFtyFLYdu3U8dy5uqMhcha5RrLHmr1Ysc+a6Fq7K2JCY7Dj8A7M3jZbdzjkAEysEZy+DLSyU9yIfIGJNSJz8yaoZOm2P583pMLM23dxyJCSj8uUS6liu+46NWhAnsfk5tD//d/pry3nnquScO+/X/JxWWoqPdlbtABq1YKttG5d+rmeiAJDbgjINGK5RspgJrJPn7XsfGtVrIUHh6NX/V7G8a8rOMSA/I+JNXIkDi4gs+neHXC7VTXl+vW6oyE7SkpKMjYqP1n+OX586Z6I/iQ93MTo0cDKlapHmiS/JKkmyTWpCpG+anK9KMs0zwceUHtZGpqZqY691XB2Wgbq5a3gW7BAdyRkZbxmVnwZqKwGCQ/XHQ35ss+aJNis1Gft6OWgUzZOQUZOhu5wyOaYWCNHJ9bYX43MQipPpDeQYNUa+VpUVBR2795tbHJM5fPHH6oHYo0agXnekB5ucj2QijL5fkOHqgnCkkQbNAiYNk0l2GSQQlnIslGpHtm/H/jqK9UKwXudsdMy0GMr1phYo4riNbNiOLjAnmQpaHhIuOX6rDVOaoxGVRqhoKgAo1YfaSpK5CdMrJEjsWKNzIjLQYnMacQItb/44sC1D/BWrcmwndq1VTJt5kzgtdeAM88s39eSatj77lPHjz+uloZmZACJiUCnTrAdWd4qicgdO9RGRIHB/mr2FBkSidjQWGTmHSl5tpBLG19q7H9e/rPlKu7IWphYI8fZuVNt8uaoWTPd0RAdn1ibNEm9mSYi/aRq7PffA7cM1Ouaa4D+/YHbblOVV507V+7r3XyzqnA7cACYPr2kkk2SbnYTGQk0bKiO2WeNKHA4EdS+pM9aTmEOrObC+hcaicGNBzZizvY5usMhG2NijRxbrSZP+qzuJzORJV/JyWrJGZcwkS9lZ2eja9euxibHVHazZqmbMbGxqtIrkMmhn34CPv4YiIur/NeLiVHTTGVZ6+efA2+8Abz6KmyLy0GpMnjNrBgm1uwrNjwWLrhQ5CmClUSFRqF3/d7G8U8rftIdDtkYE2vkOOyvRmYlVZTt26vj2ZwMTj5UVFSEqVOnGpscU9l5hxb06gWEhsLSEhKA889Xy0wfeqjsPdqsyPscz4o1qgheMyuGPdbsKyY0BhEhEcjKz4LVXNb0MmM/deNU7M3bqzscsikm1shx2F+NzIyJNSJzvlFs00Z3JFQerFgj8qOQECA9Xe2P2LdPDUgRMiyF7EWSajId1IqJtfqJ9dEmrQ0KPYWYsG+C7nDIpphYI8fx3r1mYo3MiIk1InPZsEHtZYAAWS+xtnKlWl5PRD4kCbWqVUsl1ryDC6pVU0vZyX5SolKQW2DNJsADmgww9uP3jjemhBL5GhNr5Cj5+cCyZeqYS0HJzIm1FSuAQ4d0R0NETKxZU1qaWuoqq/iWLNEdDZH9sb+a/UnFmsvlQmFRIazm/DrnIzE8Efvy92HKxim6wyEbYmKNHEXuXEtyTZo416qlOxqi46WkADVrAjIRfN48l+5wiBwtLw/YulUdM7FmPVwOShQ4TKw5o8+aTNjMLrDeQI9Qdyj6NepnHP+47Efd4ZANMbFGjl0GKo3iicxctTZnDn9JiXTaskVVPIWH27vRv115++LNnKk7EiL74+AC+wsLDkNceJwl+6yJ/o37ww03FuxcgFV7V+kOh2yGiTVyFA4uICtgYo38ITIy0tio/MtApcKZN2Osp2tXtZ80SVUBE5UHr5nl4+2xxoo1e0uOTLZsnzXpEdcpvpNx/MPSH3SHQzbDxBo5MrHG/mpkhcTa3Ll8J0++ERUVhczMTGOTYyob9leztrPOAoKDgY0bgfXrdUdDVsJrZvlxKagzRIdGW7bPmuiT1MfYj10zFhk5GbrDIRthYo0chRVrZAVt26r9hg0uHDgQqjscIsdiYs3aJB/SqVNJ1RoRVYI0Kd62Te2PsXMnsHevquytV09LdBQgMWHW7bMmmkQ1QcPEhsgtzMWIlSN0h0M2wsQaOcauXer1gDzpN2+uOxqik4uPBxo2VMdr1sTrDofIsZhYs75u3dSeiTWiSpKE2vbtJ0yszZih9k2bAtHRgQ+NAic8OByx4bGW7bMm1XZXNL3COP55+c8o8hTpDolsgok1cozZs9W+USM1FZTICstBmVgjX8jJyUGfPn2MTY6pbJhYs77zz1d79lmj8uA1s3y8ibUuXXRHQgHrs1ZozT5romfdnsaE062HtmLGliO/vESVxMQaOcacOaUTFkRm5v09Xb06QXcoZAOFhYUYPXq0sckxlQ0Ta9bXsSMQEaGWqi1bpjsasgpeMyuWWOvcWXckFAiSlHLBZdlqL6m669uwr3E8fNlw3eGQTTCxRo6rWGNijazA++J05coEVlkQaZCXB2zdqo6ZWLOusDA1xEBwOSiR78nKUO/NaybWnDPAICIkAtn51uyzJgY0GWDsp22ahm2HtukOh2yAiTVyBElMeJ/0zzhDdzREp9e6NRAe7sGhQ2HFI+yJKHC2bAGKiuRxCKSm6o6GfLUclIh8a+FCIDsbSEgo6Q9L9iZJtdhQ6/ZZE7Xia6FDtQ7wwINfVvyiOxyyASbWyDFvkGQZiNutEhZEZhcaKtNBVanazJku3eEQOXYZaK1aaugNWT+xNmWKLPHTHQ2RvUyfXlKtFsR3lo6RFJmEnEJr9x+8rMllxv7XFb8it8C6PePIHHj5I0fwVqvJNFDptUJkBZ06qcTaP//wXT1RoLG/mn20bQvExQEZGSVtIYjIN9hfzZlkMqiV+6yJc2qdg9SoVOzP2Y8xa8boDocsjok1cgT2VyMr6tjRW7HGSzVRoDGxZh/BwUCPHup4DN87EfkUE2vOHWAgS0KtvBw0OCgYVze/2jj+ZvE3lk4Skn58t0aOwImgZOWKtSVLgIMHdUdD5CxMrNnLhReqPRNrRL6zfTuwcaNaAtqhg+5oKOB91sKs3WdN9GvcD1EhUdiQscEYZEBUUUyske1xcAFZVXo6kJycBY/HhVmzdEdDVhYVFQWPx2Nsckynx8SavfTqpfbyemD3bt3RkNnxmlm+arUWLYCYGN3RUKClRKUgpyDH8hNOvRNCv170te5wyMKYWCPbW7sW2L8fCAtTPdaIrKRx432lXrwSUWAwsWYvVauq4UVys23cON3RENkDl4E6mywHDXIFobDI2lNhrmp+lbEsdP6O+Viya4nucMiimFgj2/NWq7VqpSYtEllJo0ZMrBEFWn4+sHVryVRQsgcuByWqhJAQVUov+yPmz1d7rghxppiwGESGRCK7IBtWr7zrVU+VNX+16Cvd4ZBFMbFGtjdvntrzSZ+sqHHj/cWJtSL2VKUKysnJweWXX25sckyntmOHerxJ0/vUVN3RkK8Ta2PHAoXWLrAgP+M18wQkoSaln0cSa1L9uXBhyc1rcp7w4HDEhcchMy8TVvevlv8y9pPXT8bmA5t1h0MWxMQa2Z40fvf2fyCymtq1DyAiwoOMDGDlSt3RkFUVFhZi+PDhxibHdGrbtqm9FGdIU26yB1muFhcH7NtXMi2c6ER4zSzbDYg9e9Q1slkz3dGQLsmRycgtzIXV1U+sjzNrnAkPPBi6eKjucMiCTP9ysXbt2nC5XMdtd999t/H3Xbt2Pe7v7rjjDt1hk4ksXar27K9GVhQc7EH79mo66DQOKyIKCO8y0GrVdEdCviQViD16lFStEVHFeavVGjYEIiJ0R0M6l4MGBVm/z5q4ruV1xv73Vb9jf7ZaMUJkm8Ta7NmzsX379uJtwoQJxselNNvr1ltvLfU5r732msaIyUwOHQI2bVLHvJtGVnXWWSqx9uefuiMhcgYm1uyrWze1nz5ddyRE1rZokdpzGaizyQCDqOAoZOVnwerapbdD06SmRgXej8t+1B0OWYzpE2vJyclIS0sr3kaOHIl69erh3HPPLf6cyMjIUp8TGxurNWYyj2XLSpbzJCTojoaoYs4+m4k1okBiYs2+OnQoGWwkPaKIqGLYX41EWHAY4iPikZlv/T5rsvLNW7X249IfkZ1v7aEMFFjBsJC8vDx88803eOihh4xffK+hQ4caH5ekWt++ffH0008bybaTyc3NNTavgwcPGvv8/Hxjszrvz2CHn6WyFi2S35NgNG1ahPx865coH43n2f6857ZduzwEB7uxaZMLa9bkc0qhjQTqcXz017fLc50/bd7sNu49pqUVIj+/clNDeK02l8aNgbCwYOzf78KKFfmoX7/yX5Pn2H6OvWZ633fwHJdYsEDeRrrQtGkB8vOtn6Xm47jiEkITsDlvM4oKzT1lyxvfqeI8t+a5qB5THVsObcHwZcNxbfNrAxihDRQChQWF2h5Hvn4cl+frWCqx9uuvvyIjIwM33nhj8ceuueYa1KpVC1WrVsWiRYvw6KOPYuXKlfj5559P+nVeeeUVPP/888d9fPz48adMyFmNd9msk40cKes/6yMiYj1Gjz4yxcBmeJ7tb/r0Cahb92ysWpWI999fhPPO26I7JLLY4/joqXbjxo1DeHi4X7+f1S1e3EVq5rFr1wKMHu2bxxuv1eZRu/bZWLkyEZ9+uhDnnnukPNEHeI7t42TXTJ5jJT8/CCtW9DESa3v2/IHRo+0zOZXnuGKCEIRtODL5x+R2LNxxyr/vF98P7x96H1/O+xJdcrogLCgsYLFZnQsuzFszzzaP46yssi9xdnk81imEv+CCCxAaGorff//9pJ8zadIkdOvWDWvWrDGWjJa1Yq1GjRrYs2ePLZaRSmZVfpl69OiBkCMjsZ2qTx83JkwIwocfFuDf/7bMr3qZ8Dzb39Hn+Omnw/Dmm27cfHMRPvrIXtWXThaox3FmZiYSjqyH379/P6Kiovz2veygefNgrFrlwvjxBejatXLPHbxWm8+DDwZh8GA37ruvEP/9b+UrLHiO7efYa6a8/+A5LjF/PtCxYwgSEjzYsaMARy0ksiw+jisurzAPMzbPQJAryBhmYFZSqSZJtbRWaQhyn7wjVkFRAQYMH4Dth7fj4Y4P48pmVwY0TivbenAr2lVth7ToNFs8jiVPlJSUhAMHDpw2T2SZirWNGzdi4sSJp6xEEx07djT2p0qshYWFGdux5H++nS6kdvt5KtNjrWXLYNj1fwXPs/3J+e3a1Y0335TJoEEICTF9e0wy2eM4Li4Ohw8fNo6lMvvodgp0vG1HbrrXquW75w5eq81DXioOHix91twICZFlv77Bc2wfx14zCwoKnHuOZSnU7t3S+Fr+B5R6fd2qlQuhofb6/+HIc1xJ8v+rSnQVbDu0DXHuOJidJNVOlVgLdYfiptY34eVpL+OrxV+hf9P+Ri85KgM34A52a38M+epxXJ6vYZl3Z0OGDEFKSgr69JGy45NbsGCBsU+XbvXkaBkZJQ2oORGUrO6ss6SpKrBqFbDj1BXsRMeRRJpUqcnGpNqpSdvVI++nObzA5gMMpOqG7ZToRHjNPIo8SLZvL/Vg8U4EbdlSX1hkLlUiqxiVa3ZxUcOLkBqVit1ZuzFi5Qjd4ZAFWCKxVlRUZCTWbrjhBgQHlxTZrV27Fi+++CLmzp2LDRs24LfffsP111+Pc845By15pXc879206tXlzqPuaIgqR1aktGihjv/6S3c0RPblvSEjzxtcMWtPDRoAsqIjOxtYulR3NETWw4mgdKyY0BgEBwUbyyjtQKrWbmyt+rp/ufBLWyUNycGJNVkCumnTJtx8882lPi79DuTvevbsicaNG+Phhx/GgAEDTtmDjZzD+2KZ1WpkF+eco/aTJ+uOhKxG+orK4B/Zju4xSidfBlq1qu5IyF+CgoD27dXx7Nm6oyEz4jXz5KQ7tzexxjoG8pLealGhUcjMy4RdXNzwYqREpWBn5k78tvI33eGQyVkisSaJM5mx0LBhw1Ifl4EDU6dOxd69e43pPatXr8Zrr71miwEEVHlLjgwBZWKN7KJXL7UfPpzLl6h8pD/Ql19+aWzeXkF06oo1LgO1N29ibdYs3ZGQGfGaeeqbD3v3qgQ1X2OTl1SrVYmogqz8sk9RNDvpq3ZDqxuM4yELhrBqjayfWCOqCFaskd1ccAGQmqp6CI8ZozsaIntiYs0ZWLFGVDHSm1A0bgxEROiOhswkMSIR+UX2uvPbr1E/JEcms2qNTouJNbItJtbIbqTF5HXXqeMhQ3RHQ2RPTKw5a4CBVLdn2afAgihgibU2bXRHQmZcDiq9yfIL7ZNcY9UalRUTa2RL+/eXTE5s2lR3NES+c4N6bsfIkapyjYh8i4k1Z5Dzm5YGFBaWJAqI6PS8j5e2bXVHQmYTHRqNiJAIZObbp8+auLTxpcVVaz8v/1l3OGRSTKyRLW3cqPYpKUBMjO5oiHyneXPgjDOk/wvw7be6oyGy7/ACJtbszeUqqVrjclCismPFGp2qz1pSZJKt+qx5q9ZuaXuLcfzZ/M9wOO+w7pDIhJhYI1vavFnta9TQHQmR792opn/jiy90R0Jk34o1TgW1Pw4wICr/ipANG9Rx69a6oyGz9lkrKLLfwI9LGl2CmnE1kZGTgaGLh+oOh0yIiTWypU2b1L5mTd2REPneVVcBoaHAggXAjBm6oyGyD1kW6G0jwIo1++MAA6KKVavVrg0kJOiOhsy6HFT6rNmtF5lU493d/m7j+JtF32Bv1l7dIZHJMLFGtsTEGtlZlSrAtdeq4yeeADwe3RGR2UVGRmLXrl3GJsd0Yjt3quSa260m8JIzEmtr1gD79umOhsyE18wTY381Op2Y0BhEhkTabjmoOL/2+WiW3AzZBdnGklCiozGxRrbEpaBkd889B4SFAVOmAOPH646GzM7lciE5OdnY5JhOvQxUmtpLco3sLTERqFdPHc+ZozsaMhNeM48SEgKkpxt79lej03EHuW3ZZ03IteDeDvcaxzLEYP3+9bpDIhNhYo1siRVrZHfyu323qkjHY48BRUW6IyKyPg4ucB4OMCAqQ2JNmk4ysUZllBCRYMs+a+KMqmfg3FrnotBTiHf+eUd3OGQiTKyRrRNrrFgjO3v8cSA2VvVa++EH3dGQmeXm5uLuu+82NjmmU1esMbHmHBxgQCfCa+bxsrKAFSvUMRNrdLrloHbss+Z1X4f74Ha5MW3zNMzcMlN3OGQSTKyR7RQUlFQdsGKN7CwpCRg4UB2//bbuaMjMCgoK8MEHHxibHNOJcSKosxNr7FdJXrxmHm/RIlUdL/0nZWUo0akGGNi1z5qoFV8LVzS7wjh++5+3UVhUqDskMgEm1sh2tm9Xzaelcl365BDZ2W23AUFB6k3h2rW6oyGyNu9NGSbWnEMqb6SfnkyD9SZWieh4Ry8DdXrbOTp9n7XkqGRk5mXCrm5pcwtiw2KxZt8ajFg5Qnc4ZAJMrJFtl4HKUh5JOBDZmdw57tZNHX//ve5oiKx/Y0YwseYcUVFAs2bqmH3WiE6O/dWoPBIjEo0+ZHYVFx6HW9veahx/OOdDHM47rDsk0oxpB7LtRFAuAyWnuOoqtWdijcg3iTUuc3LmAIN//tEdCZF5LVyo9q1b646ErNJnLTw4HDkFObCry5tejtrxtbE/Zz8+m/eZ7nBIMybWyHY4EZScpn9/tfR5yRK1EVHlEmtsI+As55xTcnOC7bSIjictVhYvVsetWumOhqwgKjTK6LVm5+WgwUHBeLDTg8bx90u/x6YDR96EkiMxsUa2w4mg5DTx8cCFF6pjVq0RVUx+PrB7tzpmxZqzXHYZUKUKsHEj8NtvuqMhMp81a4DsbCAiAqhfX3c0ZAVBriCkRKUguyAbdnZmjTPRpUYXFBQV4M0Zb8LDKTiOxcQa2Q6XgpITXX212n/3HSfbEVXEzp1qHxysJu6Sc0iy4Pbb1fE77+iOhsi8y0BbtFDDPojKIj48Hh75z+YvTB/q9JBRvTZt8zRM2jBJdzikCRNrZDusWCMn6tsXiIwE1q1jA246XkREBNavX29sckwnXwYqA0E4+MZ57rpLJVX//BNYsEB3NKSb46+ZUsIrY5Jlf1RijctAqTxiwmIQERJh+6o16bN2Q6sbjOPXp7/OQQYOxZeOZDusWCOnTra7+GJ1zOWgdKygoCDUrl3b2OSYjsfBBc4mk8RlSahg1Ro5/popCTW5KDKxRpUQGRKJuNA4W/dZ87q59c2oEVsDe7L2YPDswbrDIQ0c+ExBdpaZCezdq46ZWCOnLgf94QfVaJiIyo6JNbr/frX/9ltg6FAuqyfyYmKNKiol2v591kRYcBgeP+tx43j4suFYvPPItA9yDCbWyJbVajExQFyc7miIAuuCC9QgA1m98ddfuqMhM8nLy8OgQYOMTY7peEysUadO6joqD5F//Qs4/3xg7VrdUZEOvGaW2LcP2LKlpMcaUXnEhsUagwwKi+x/x7dDtQ7o06CP0Vfuxb9eRH6hqvgkZ2BijWyFy0DJycLCgP791TGXg9LR8vPz8d///tfY5JiOx8QaiREjgJdeUgMNpkxRS+xZAew8vGaWWLRI7WvX5k1rKr+Y0BhEhUQ5ompNPNjpQSSEJ2Dd/nUYsmCI7nAogJhYI1sOLmBijZy+HHT48OLWKERUBkyskfcGxRNPAEuXqgrgZcuAYcN0R0WkD5eBUmWXSMZHxDumob9MQh3YZaBx/PmCz40EGzkDE2tkK5wISk7XtSuQkqJ6DU6YoDsaIutgYo2OVqcO8NBD6viFF1i1Rs7FxBpVVnJksqOWRfas2xNn1zwbBUUFeH7q88ae7I+JNbIVLgUlpwsOBq64Qh1L820iKhsm1uhY992nqtaWL2fVGjkXE2tUWTFhMXAHuR2TYHK5XHjszMcQHRqNpbuX4n/z/6c7JAoAJtbIVrgUlAi4/nq1lzeCW7fqjobI/IqKgJ071TETa+Ql/aRYtUZOVlCglkULJtaoMgMMokKjkJmXCadIjU7FE2c9YRxLYm3BjgW6QyI/Y2KNbIVLQYmA9u2Bs89WPdbefVd3NETmt2ePegPpcgGpqbqjIbNWrU2apDsaosBaucqF3FwgOlotjyaqiOCgYFSJqILMfOck1kTPej2NKaFFniI8Pflpx/SZcyom1sg2PB4uBSXyeuQRtf/oI+DgQd3REFljGWhSEhASojsaMlvVmnfa8vjxuqMhCqyFi9VbxZYtgSC+a6RKqBJZxTFLQY82qMsgVIuphu2Ht+OFP1+AR96wki3xEkm2qjjIyVHH1arpjoZIr969gaZNVVLtk090R0O6RUREYMmSJcYmx1Qa+6vRqXTvrvYTJ+qOhAKF10xl0ZKSxBpRZcSExiDUHYrcglw4ifRZe+n8l4yqvUnrJ+HbJd/CrjweDw7lHoJTMbFGtlsGmpYGhIXpjoZIL7mzPFBN+8bbbwN5ebojIp2CgoLQrFkzY5NjKo2JNTqVbt3UfsECYPdu3dFQIDj+mimlu+npWLjUbfyR/dXIFwMMJMmUlZ8Fp2me0hwPdVINO9/9513b9lv7cuGXeGDcA5i3fR6cyIHPFGRXXAZKVNo11wBVq6oBBiNG6I6GyLyYWKNTSUkpSSz88YfuaIgClFirWhULF6m3ikysUWUFuYKMhv6ZBc7qs+Z1edPLjZ5rhZ5CPDHpCezP3g87mb55OgbPHox92fuwZNcS3eFowcQa2QYHFxCVJpWbklwTv/+uOxrSKS8vD88995yxyTGVxsQanQ6XgzoLr5mqOlOujTLUpUUL3dGQHcSHxxvLBZ3YZ8zlcuGps59Crbha2JW5C89OedYYamAHmw9sxpOTnoQHHnSv2x3XtbwOTsTEGtkuscaKNaISF12k9mPGAIWFuqMhXfLz8/H8888bmxxTaUysUVkTaxMmqGFJZG+8ZgILF6p9vXpqKihRZcWGxSIiJMKRy0FFZEgkXu3+KsLcYZi+ZbqxdNLqZNLpwAkDcSjvEFqktMBtbW8zkohOxMQa2QaXghIdr0sXNdVOhnvMmqU7GiJzYmKNTufss4HQUHUTb80a3dEQBS6xxmWg5MvEUkJ4AjLznbkcVNRPrI9HznzEOP5wzofGEkqryi/MxyMTHsHa/WtRJaIKXuv+GkLczh2tzsQa2QaXghKduE1Kr17qeNQo3dEQmRMTa3Q6UVHqRoXgclByAibWyB9SolKQU5ADJ7u44cXo27CvsRT0kYmPWLInmcT+3NTnMGvbLCNh+vYFbyM5KhlOxsQa2QYr1ohOrE8ftR85UnckROYjy/qYWKPyLgclckpirWVL3ZGQ3ZaDBgcFo6CoAE4lSyWfOOsJdK7e2Ugy3j/2fmzI2ACrkB55b818C+PWjoPb5TYq1ZokN4HTMbFGtiDtL7ZtU8esWCMq7cILVfNheZHsTUATkXLgAJBz5OZ5WpruaMjMunVT+6lTgSJ79JwmOiGZ17B8uTpmxRr5OrEWFRpl9OZyMlkyKf3WmiU3w4HcA7hr9F3YcnALrOCTeZ/guyXfGcfPnvssOlXvpDskU2BijWxh61ZVdSD9T1JSdEdDZC5JSUDnzup49Gjd0RCZizfZnJgIREbqjobMrF079Tuyb19J0oHIjlasUDetpUdrrVq6oyE7kWo1WQ7q9MSakCWU7/R6B3Xi6xiTQu8YdQe2HzpSQm9SMnDh03mfGscDOw9E7wa9dYdkGkyska3eGEm1WhB/q4mOw+WgRKd//iA6Xc9K702KP//UHQ2R/5aALJxbULwM1KED/siPEiMSjR5dsqTQ6eLD4/Fhnw9RM64mdhzeYSTXth06sgzLRORcfTbvM7w36z3jz/e0vwdXNb9Kd1imwhQE2QIHFxCdWt++Jb2BZOkbOUt4eDhmzZplbHJMJZhYo/JOBxV//aU7EvInx14zJbG2fTsWLlAJDy4DJX+IC4szqrWyC7J1h2IKSZFJ+KjPR6geWx1bD23FTSNuwoo9K2AWhUWFeG36a/ho7kfGn29rextubH2j7rBMh4k1slVijYMLiE6seXOgcWMgNxf49Vfd0VCgud1utG/f3tjkmEowsUYVTayx2MK+nH7NnLdAvUVs00Z3JGRH0mMtLjyOy0GPIstjP7noEzRIbIC92Xtx6++3YtqmabrDQmZeJh774zEMWzYMLrgwqMsg3NbuNt1hmRITa2QLnAhKdGqylOPqq9Xxd6rfKBExsUbl1KkTEBwMbNkCbNyoOxoi35OE8byFQcV9BYn8IS06zZiISaWTa5/2/RQdqnUwqvkeHPcghiwYom3JrEwqvXHEjZi8YTJCgkLw8vkv48pmV2qJxQqYWCNb4FJQotPzJtYmTgR279YdDQVSXl4eXn/9dWOTYyrBxBqVhwwvOOMMdcw+a/bl5Gvmuq2hOHDAhbAwoGlT3dGQnZeDSrImvzBfdyimEh0ajXcueAf9GvWDBx4Mnj0Yj0x8BIdyDwU0jnFrx+GGX2/A+oz1SI5MNqrpetTrEdAYrIaJNbIFLgUlOr0GDdTd58JCYNgw3dFQIOXn5+ORRx4xNjmmEkysUXmxz5r9OfmaOXd5VPHgAhnYQeQPsWGxRhIpMz9TdyimE+IOwVPnPIUnznrCmKIqFWOXD78cUzZM8fv3lgTeU5OewpOTnjTOTevU1vj60q/RIrWF37+31TGxRrbAN0ZEZcPloEQlZHWFLOkTfP6gsmJijexs3opIY9+2re5IyM7cQW5j6ePhfPZZO5n+Tfrjs76fGRND92TtwcAJA43qtU0HjlSU+HhAwS8rfsFlwy7D2LVj4Xa5cWvbW/HRRR8ZwxXo9JhYI8vLyFCbqFVLdzRE5nbllarf2rRpJZWeRE61Zw+Qc6TFS7VquqMhqzjzTLVfuRLYtUt3NES+xcQaBUpiZKLRP6zIU6Q7FNNqntIc3/b/Fje0usFIdk1aPwmXD7scr0x7BdsObav01y8oKsCEtRNwzc/X4KW/XjIGJ0giTxJ6t7e73aiYo7JhYo0sb/16tU9OBqKjdUdDZG7VqwPnnKOO//Mf3dEQmaPaOTUVRj8horJITARaHFkVw6o1slsV79wjiTUOLqBA9FmLDIlEVn6W7lBMLTw4HPd2uBffXPoNzqxxJgo9hfhp+U+45PtL8ND4h4zpobkFueX6mlsObsGXC7/EgB8H4PFJj2Pt/rXG8tyHOz+MHwb8wKWfFcAUJNkmsVanju5IiKzhhReAc88FPv0U+Ne/ShJtRE7DidJUmeWgixerxNrFF+uOhsg3Nm12Yd+BYISEeNC8uUt3OGRzESERSIxIxM7DO41+a3RqDao0wDu93sH87fPx2fzP8M/Wf/Dnxj+NLcwdZkwTbZbcDPUT66NaTDUjaSlJOemVdiDnADYf3Iwlu5Zg/o75WL1vdakE5xXNrsBVza5CXHic1p/RyphYI8tjYo2ofCSRduutKrF2223AggVAeLjuqIgCj/05qTKJtQ8+YMUa2cvc+WoxU/OmHoSFMbFG/icTJzcfOPJkTGXSJr0NBqcPxoaMDRi2bJgx3GBX5i78tekvYysLWVbaLr0dutftjt4NehsJOKocJtbI8phYIyq/114Dfv9d9Qh66SXgxRd1R0QUeEysUWUHGMiNiYMHdUdD5BvzFqjEWtvW0vOKHYPI/2T5YUhQCPIL841pmFR2teNrY1CXQRjYeaBRgSYVbKv3rsaa/WuwO3M3sguykVOQY1SuSVVaclSyUdHWIqWFUd0WHx6v+0ewFSbWyPKYWCMqv/h44L33gMsvV4k16aXSr5/uqMhfwsPDMXny5OJjUphYo4qSYRd16wLr1gEzZrCyx+7XzKKiIkcl1tq1ccbPS+ZIrEWFRhnLFePdTPRUhMvlQsMqDY3tWDIcQv6e/I+3IsjymFgjqpgBA4Dbb1fNiq++Gpg+XXdE5C9utxtdu3Y1NjkmhYk18kXV2rRpfNNiN068ZhqDC7wVa2fwLSIFhjvIjZSoFCOxRr7HpFrg8KpJln8RsGGDOmZijah85Ln2/feBvn2BnBy1X13Sy5TI9phYI18k1v7+m29cyPq2bwd27XJB8ogt23JREwVOQkQCCosKjeoqIqtiYo0sbedOIDtbJQg41Y2o/IKDge+/Bzp2BPbtA669Figo0B0V+Vp+fj4GDx5sbHJMQGEhsHWrOmZijSqTWJs924W8PL6kthMnXjOXL1f7evWAiAjd0ZCTSP8vmRAq/cCIrIqvAsjSpLeJqF4dCA3VHQ2RNUVGAsOHq75rs2cDr7yiOyLytby8PNxzzz3GJsekbsxIElmqM9LTdUdDVtSgAZCaCuTmurB6NXsD2YkTr5krVqh948a6IyGnkeb60muNy0HJyphYI0tjfzUi35Dk9ODB6viFF4C5c3VHRBSYZaBVq6rkGlF5SbW8t2pt2bIqusMh8klirUkT3ZGQE/uApUalGlMsiayKiTWyRWJNJnMRUeXIAAOZEipVPNddJ1UYuiMi8h/2VyNf8CbWli9nYo0sSpa6btuGFcvVJFBWrJEOceFxRoKtoIj9SMiamFgjS2PFGpFvqy8+/FAtbZJeK1wSSnbGxBr5wnnnqf3ixUnYtUt3NEQVTKxt317cY42JNdIhPjwesaGxOJx3WHcoRBXCxBpZGhNrRL5VpQrw3nvq+OWXZXmT7oiI/IOJNfKF5s2B9u2LkJ/vxqef8mU1WdOhzCBs3aZ+fxs10h0NOVFwUDDSY9KZWCPL4isAsjQm1oh877LLgL591U3sW28FitTqECJb2bBB7WvV0h0JWb3S95571EXy44+D4JA+92QzKzeGG3upWE9I0B0NOVViRKKxLywq1B0KUbkxsUaWJX2gvBUHTKwR+faNogwyiI4Gpk8H3nlHd0REvrdypdo3bKg7ErK6AQM8SEzMxo4dLvz4o+5oiMpvxQaVWOMyUNK9HDQ6NJpVa2RJTKyRZUlSrbAQCAsD0tN1R0NkL7I87tVX1fGgQcCECbojosoICwvDyJEjjU2OnU6eO9asUcdMrFFlhYYCF16oSiDlRoTHozsiqiynXTOZWCMzCHWHIjU6FYfzmVgj62FijSy/DFSW8QTxN5nI5+68E7j+epWEuOIKYNUq3RFRRQUHB6NPnz7GJsdOt2kTjCV78n6ZPdbIF3r23IDwcA/mzFGVvmRtTrtmehNrTZrojoScLikyCUWeImMjshKmI8iy2F+NyP9LQj/+GOjcGcjIAK69VndERL5dBtqgAeB2646G7CAuLg9XXaVK1T77THc0ROXDijUy03LQqJAoZOZl6g6FqFyYWCPLWrdO7ZlYI/Kf8HBg+HBVFSqVGN6+hmQt+fn5+OKLL4xNjp3OW33JZaDkSzfeqCos5JqZyfeEluaka6b0LF61SS13ZWKNdAsPDkdyVDIO5R3SHQpRuTCxRpa1YoXacyw4kX9VrQp06KCOx4/XHQ1VRF5eHm666SZjk2OnY2KN/KFzZw/q1gUOHwZ++UV3NFQZTrpmrt/gQn5BECIiPFwaT6aQEpWCgqICeNiwkiyEiTWyrOXL1b5pU92RENnfBReo/bhxuiMhqjxOBCV/LZ+XvpTiq690R0NUNitWqbeDjRp42LOYTCEhPAFRoVHIzGfpL1mHqS+fzz33HFwuV6mt8VE1yjk5Obj77rtRpUoVREdHY8CAAdi5c6fWmCkw5Obh6tXqmI1WifyvZ0+1nzhRDTMgsjJWrJG/XHddybVy61bd0RCd3oqVLmPfuCGbxZM5RIREIDkyGYdyuRyUrMPUiTXRrFkzbN++vXibNm1a8d89+OCD+P333zFs2DBMnToV27ZtQ//+/bXGS4GxZo3qCREdDVSvrjsaIvuTpaBxccD+/arXGpFVZWerqaCCrQTI12Qp6NlnA7KC6ZtvdEdDVPaKtcaNmFgjcy0HzS/K53JQsgzTJ9ZkxHVaWlrxlpSUZHz8wIED+N///oc333wT559/Ptq1a4chQ4Zg+vTpmDlzpu6wyc+WLStZBipLL4jIv4KDgW7d1DH7rJHVb8yIhASgShXd0ZAdeZeDfv217kiITm/VGlfxUlAiM00HjQyNRFZ+lu5QiMokGCa3evVqVK1aFeHh4ejcuTNeeeUV1KxZE3PnzjWm9HTv3r34c2WZqPzdjBkz0KlTp5N+zdzcXGPzOnjwoLGXr2eHyT/en8EOP8vJLFkiOWE3GjcuQn6+M9elOeE8O53ZznH37i78/HMwxo4twmOPOfNxZ9VzfPTXt8tzXUUtXSpvIoPRoEERCgoKHfc4Jv+f44svBu68M9j4XVu6NJ9Lji3o2GumtKM59uN2sWq1ejtYt36RLX++suK12lxCXaFICE3ArsO7EOGO8MnXLCosKrUnPygECgsKtT2OfP04Ls/XMXVirWPHjsaY60aNGhnLQJ9//nmcffbZWLJkCXbs2IHQ0FDEx8eX+jepqanG352KJOfkax1r/PjxiIyMhF1MmDABdjVpUjsA1eFyLcfo0UfKDxzKzueZzHWO3cYLm56QouBhw8YjKqpAd0i24e9zLD1JvcaNG2fcrHKqkSMbSL0zIiO3YvToeY57HFNgznGzZp2xcGEKXnttFfr3d/brFCs62TXTbo/jzMxg7Nrdxzhet3kStu/h87rdzrEdbMM2n369HQtPnSuginPBhXlrAvfayt+P46ysLHsk1i688MLi45YtWxqJtlq1auHHH39ERETFM9ePP/44HnrooVIVazVq1EDPnj0RGxsLq5PMqvwy9ejRAyEhIbCjp59Wv7r9+jVC797OvBXshPPsdGY8x//9rwerVwchJOQC9O7NZSNWOccFBQX49ttvjeOLL77YaLPgVD/95Db2XbtWRe/eaY58HJP/z/GWLUG45x5gxYomjn2dYmXHXjOlz5PtHsfZ2Zj7y2bjMC3NgwEDjkwpciheq80nKy8LM7bMQERwhLEstLKkUk2Sammt0hDkNn1HLEvaenAr2lVth7Ro/7++CsTj2LuysSws9cpaqtMaNmyINWvWGP+z8vLykJGRUapqTaaCSi+2UwkLCzO2Y8n/fDtdSO3283jJRELvRLeWLYNhwx+xXOx6nsmc51hW38tE3tmzg3H55bqjsQ9/n2P52ldffbXfvr6VeCdKN23qRkiISrI57XFM/j/HMkvr3nuBWbOCsGtXEKpV0x0dVeaa6V0OZKvHcX4+1m1RhQoNG7rs83NVkq3OscXFhcQhJSYF2w5tQ3REtM++riTVmFjzEzfgDnZrfwz56nFcnq9hqd+ow4cPY+3atUhPTzeGFcgP+scffxT//cqVK7Fp0yajFxvZ1/r10icPkKLFWrV0R0PkLG3aqP2CBbojISq/oiKpIFLHDWRFKJGfpKcD3pejv/6qOxqiE1u1US1xZR9AMqu0mDRjOmiRh33RyNxMnVgbOHAgpk6dig0bNhjTPi+99FK43W7jDlJcXBz+/e9/G0s6J0+ebAwzuOmmm4yk2qkGF5B9JoI2biw9n3RHQ+QsrVuXJNY4Ad1ay5qGDRtmbHLsVIsWARkZQFSUmipN5E+XXqr2P/+sOxIqL6dcM1dtYmKNzC0xIhExoTHIzMvUHQqRdZeCbtmyxUii7d27F8nJyTjrrLMwc+ZM41i89dZbCAoKwoABA4wpnxdccAE++OAD3WFTgBJrfFNEFHjNmwNBQcDu3YDMiZGqDDI/eY684ooriqu/ndpjzVvkfs45QGio7mjICYm1QYOAqVOBvXuBKlV0R0QVvWbKwDQ7WrVJtcZhBS+ZVXhwOFKjU7E+Yz1iwmJ0h0N0UqZ+Zf3999+f8u9lQs/gwYONjZyDiTUifWQJdqNGwPLlqmqNiTWyYmJNegUS+Vu9etILVlVKjhoFXH+97oiISkjV+WpWrJEFpESlYN3+dSgsKoQ7iMuVyJxMvRSU6ETkDb1o0kR3JETOdPRyUCKryMsD/vxTHXfrpjsacoqLLlL78eN1R0JU2q5dwMFMN1wuj5EEJjL1ctCwGBzKO6Q7FKKTYmKNLNd42ptYY8UakR6tWqn9woW6IyEqu3/+ATIzgaQkoEUL3dGQU/ToofYTJ7IvJZnLqjXqbWDtWh6EqRWhRKYU4g5B1ZiqOJTLxBqZFxNrZCmrV6s3RrIcjXfXiPRgxRpZeRno+eerPoFEgSCTQSMjgZ07gSVLdEdDVGLVGpexb1ifGV8yv+TIZGMZaH5hvu5QiE6ILy3JUmbPVvs2bQCH9t4mMk1ibdUqlegmsgL2VyMdpBJIhmV4q9aIzGLVavU2sGGDIt2hEJ1WfHi8sR3IPaA7FKITYmKNLJlYa99edyREzpWaqjZZ1sQKDLKCw4eBmTPVMfurUaB5k7lMrJGZrF6rKtYa1GPFGpmfVKtVj62OzHze0SVzYs0PWQoTa0TmqVobN04tB+3YUXc0dDqhoaEYMmRI8bHT/PUXUFAA1K4N1K2rOxpyamJt6lQ1RMOBD0HLse01Mz8f2L0bSE7GqtVqumLD+qxYI2uoElkF4cHhyCnIMfZEZsLEGlnqtcD8+er4jDN0R0PkbDLAwJtYI/MLCQnBjTfeCKcvA2W1GukgwzKSk1U+QyonvUtDyTrXzHx5EWoH8nNs347CmHisWafeBjZswIo1soaY0BgkRSZhd+ZupEWn6Q6HqBQuBSXLWLoUyMkBYmOBBg10R0PkbN4+a/PmcdIdmZ93CR77q5EOMiyDy0HJTDZvcSE314XQUA9q1mWdBVmDy+UypoPmFubCwxefZDJMrJHlloFKtRonuhHp5a0anTUL6NULWLkS2LED+OcfNf2OzKWgoACjRo0yNjl2EqkSWriwZCIokQ7exNqECbojobKw+zVz+Yoj/dUauOAOD9EdDlGZVYmoYlSuHc47rDsUolJ4i4Isg/3ViMxDqkZffx146ilg/HigceOSv0tPB9avV9PwyBxyc3Nx0UUXGceHDx9GsIPGKk+eXLIcLyVFdzTkVN5lyPJa5tAhICZGd0RUnmumrfqsSWJtpbpD3aSJ7kiIyiciJMKoWluzbw1iwnghJfNg3Q9ZBhNrROYycKCaCioVa0IqSd1uo32L0aSbyAzYX43MoFYtoE4doLAQ+Ptv3dGQ0zGxRlYm/dWCXEHIK8zTHQpRMSbWyBKys4HFi9UxE2tE5lG/PjBmDLBnj3qc3nyz+viIEbojIyqdWGN/NdKta9fSVZREuixfqZaCMrFGVpQQkWBMCM3IydAdClExJtbIEmTyoNzllWU8NWrojoaIjlWlCiArZS6+WP35t9841ID027ABWLsWkJWvnMRIup13ntpPmaI7EnK6FatYsUbWJdVqNWJrIKcgh0MMyDSYWCNLmDOnpFrNpW6yEZEJyXK7yEhgyxaVECcyQ7Vahw7saUX6nXuu2s+dCxw8qDsacqrd+4Oxd6/LeD3dqJHuaIgqJikyCdGh0TiUd0h3KEQGJtbIEubNU/t27XRHQkSnEhEB9OypjrkclHRjfzUyk5o1gbp12WeN9Fq+PtzY166tnrOJrDrEoFpMNRzIOaA7FCIDE2tkCcuWlUx1IyJzu+SSkuWgRLrI6pBJk9QxE2tktj5rXA5KAZWfD2zbZuy9iTUuAyWrS4tJQ4g7xFgSSqRbsO4AiMry5sibWGvaVHc0RHQ6ffqoCaHz5wObN7MvohmEhobi/fffLz52ghUrgJ07VUVGp066oyEqSax9/jkTa2Znu2umJNZkZHetWli+QSXWGjfWHRRR5SSEJyAlKgW7MncZk0KJdGJijUxPejUdPqyaT8sEQiIyt+RkoEsXYNo0VbV29926I6KQkBDc7bATIb9/QpJqYWG6oyEqXbHm7bMWG6s7IirLNTNfElM2wYo1sguXy4XqsdWx9dBWFBYVwh3k1h0SORiXgpLpLV+u9pJUs8NNQyInLQf9+WfdkZBTeRNrZ52lOxKiElLBW68e+6yRPsvXq8ZqTKyRXYYYSOVaRk6G7lDI4ZhYI9PjMlAi6xkwQO1ludOuXbqjocLCQkyZMsXY5NgJ/vpL7ZlYI7NWrXmHa5D52PWaKStANu9Ud6mZWCM7kB5rNeNqIjM/Ex7pH0SkCRNrZHpMrBFZT506wBlnAEVFwC+/6I6GcnJycN555xmbHNvd1q3A+vWq1w9/1EcAAEaeSURBVB/7q5HZeIdpMLFmXna9Zq440l8tJcWDxETd0RD5hvRZiwqNwuG8w7pDIQdjYo1Mj4k1Imu67DK1HzZMdyTkNN4ldq1bs4cVmTextmABK3opsJavCTH2TZq4dIdC5DOSVKseUx0ZuVwOSvowsUamxomgRNZ1+eVqP3kysHu37mjISbgMlMwsJQVo1UodT5qkOxpykuUr1Vs/LgMlu6kaWxUhQSHIKbBPhSlZCxNrZGo7dwL796vlPA0b6o6GiMqjbl2gbVu1HPTXX3VHQ07CwQVkdt27q/3EibojIduSSabbtqn9EctWqEo1JtbIbuLC4pAenY592ft0h0IOxcQaWWIiqPRrilBDjIjIglVrXA5KgXLgALBokTpmYo3MqkcPtZ8wQVXnE/mcJNS2by+VWFuyTL31a9FCY1xEfuByuVA9rjo88CC/sOR3nihQmFgjU+MyUCJ79FmT5U5vvQUUFOiOiOxu5kxVJVmvHpCerjsaohOTpG9oKLBpE7Bmje5oyAkys4Owbr2qWGveXHc0RL5XJaIKkiOTWbVGWjCxRqbGxBqRtdWvr5JrhYXAQw+pSaGS+CDyFy4DJSuIigK6dFHHXA5KgbB8fTg8HpfR4y85WXc0RL7nDnKjZlxN5BXloaCId3IpsJhYI1NjYo3I+n74Afj4YyAhAVi4UL2ZvP12YB9vKAZMSEgIXnvtNWOTYzubP1/t27fXHQlR2ZaDMrFmPna8Zi5Zq3qqsFqN7Cw1OhVJEUmsWqOAY2KNTI2JNSLrk+Ejt90GrFgB3HCD6if0ySdqKt7evbqjc4bQ0FAMGjTI2OTYzrz91bxTF4nMPsDgjz+AvDzd0ZDdr5lL1oYbeybWyM6Cg4JRJ6GOMR2UVWsUSEyskWnJG+5du9Rx48a6oyGiypLlJ198AUydCtSoAWzZAvz4o+6oyE5kivTmzeqYzbnJ7Nq1A9LS1MAN6UNJ5E+sWCMnVa1Jr7X92ft1h0IOwsQamdbixSUTQaOjdUdDRL5yzjnAvfeqY04LDYzCwkLMnj3b2OTY7s8btWoBcXG6oyE6Nbcb6N9fHfNaaC6WvmbKFNBt20pNAxWL1zCxRs6pWqudUNuoWissstjjlyyLiTUyLenFJFq21B0JEfna5ZervVSv7dypOxr7y8nJQYcOHYxNju2+DJTPG2S1ycm//npcHoQ0svQ1U36Rtm8v9Qu171AItu1WS1qbNdMYG1GApEalIiEiARk5GbpDIYdgYo1Mi2+QiOyrdm3VXL6oCPj5Z93RkF3weYOsWMEry+RlmMvkybqjIbtauiqkuJo3NlZ3NET+F+IOMSaEHs4/rDsUcggm1si0+AaJyBlVa+yzRr7C5w2yGi4HpUBYskTtuQyUnCQlKgVRoVE4nMfkGvkfE2tkStLOwvsigG+QiOydWPvzTy4HpcqT6kdvjzU+b5AVl4P+8guXg5J/MLFGTiRJtarRVbkclAKCiTUypTVrpL8FEBEB1KunOxoi8gcuByVfWrcOyMoCwsOB+vV1R0NUdueeCyQlqWno0neSyNeYWCOnSo9JR5ArCHmFebpDIZtjYo1MvZynRQu1TIKI7F21JpUaRL543pDG3MHBuqMhKjv5ffUuB+VNBvI1j4eJNXKuxIhEJEUmYX/2ft2hkM0xsUamxD45RM7Qp0/JclCpNiKqKD5vkJVdfLHajxypEiFE5SJriLdtO+Fa4u07XMZwjKAgoHFjLdERaSPVajXiaiC3MBdFniLd4ZCN8Z4umRLfIBE5Q5MmQPXqwJYtwF9/ARdcoDsiewoJCcGzzz5bfGxHfN4gKzv/fNX+YvNmVV0kFfukj+WumZJQ274diI8/7q8WLnIZ+4YN1VJ5IqdJjkxGbFgsDuUe0h0K2RgTa2RKfINE5AwuF9CzJ/D558C4cUys+UtoaCiee+452BmfN8jKJKkmybVRo1TVGhNr5rpm5ltxqoQkBNPTMWuESgyecYbugIj0CAsOQ824mliyfQmCuGCP/IS/WWQ6Bw4AGzaoY76wJLI/bzJt/HjdkZBVHT4MrF2rjvm8QVZ10UVqL8k1Ip8k1qpWxex5qllxhw66AyLSJzU61UiwEfkLE2tkOt4Gq7I8LDFRdzRE5G/duqnKtaVL1ZJQ8r2ioiIsXbrU2OTYbpYtU/vUVCA5WXc0RBXTu7faz5gB7NmjOxpns8s1U/r1zZ6tjmUKN5FTyVJQSa4R+QsTa2Q6XM5D5CxVqpS84J8wQXc09pSdnY3mzZsbmxzbzfLlJT37iKyqZk312kfyOGPH6o7G2exyzdy0Cdi1S02ebd1adzREeqXHpBv7gqIC3aGQDTGxRqazcKHaM7FG5LzloNJnjai8mFgju+ByUPIlb7WavKbm4AJyusRwtRRqf/Z+3aGQDTGxRqYjkwEFm6wSOYcMMPBWrBUW6o6GrIaJNbKLPn3UXirWrNgvnwJMfkm2bTvpL8usWWrPZaBEgDtI9RvMLchFkce6S7zJnJhYI1PZubOkV8655+qOhogCpWNHIDYW2LcPmDdPdzRkNUyskV3ItTAtDcjIAL7/Xnc0ZHqSUNu+/aSJNW/FGgcXEJWID49HRk6G7jDIZphYI1OZMqWkZD0pSXc0RBTI4WVdu5a+DhCVRW5uyURQJtbI6txu4P771fH//Z/qt0ZUEVL9PXeuOmbFGlGJ6rHVcSjvEDwy3YPIR5hYI1OZPFntzztPdyREFGhMrFFFrF6tkg9S8Vi1qu5oiCrvzjvV77NU8I8cqTsasuSdqvR0rFwXgkOHgMhI3nQgOppMB40JjTGSa0S+wsQamQoTa0TO5U2sSZ/FAg5sogosA3W5dEdDVHlxccBdd6njV14BWFRB5U6sVa2K2QtCjD+2a6emghKREhESgRpxNbgclHyKl1kyDem9umqVemN0zjm6oyGiQJMl4PHxqrfQ/PlcuuJLISEhGDhwYPGxnbC/GtmRLAd96y1g5kzgzz/ZdzbQ7HDN5OACopOrGlMVGzI2IDMvE1GhUbrDIRtgYo1MV63Wti2QkKA7GiLS0VtIkuq//aauB3wz4DuhoaF4/fXXYUdMrJEdyQCDm28GPvwQeP55YNIk3RE5+5qZb6YRrRLL7t1AcvIpP42DC4hOLjYsFunR6UZyjYk18gUuBSXT4DJQImKfNSovJtbIrh57TBI86vURE2tU1kmg3qEuCxeqY96kIjr5EAO3y42cghzdoZANMLFGpsHEGhF5H//ss+ZbRUVF2LBhg7HJsZ2m3q1cqY6ZWCO7qVkTuO02dfzUU+y1FkhWv2YuWgTk5QFVqgB16uiOhsicEiMSjUEG+7L36Q6FbICJNTKFTZuAdevUUrCzz9YdDRHp7LMmS8EPHwbmzdMdjX1kZ2ejTp06xibHdrFxI5CTA4SF8c0j2dMTTwAREcCMGcCYMbqjcQ6rXzO9y0ClWo1DXYhOzOVyoWZcTRR5ipBfaKLl3mRJTKyRqarVzjgDiInRHQ0R6RIUVDK8hMtBqazLQBs2VDdmiOwmPR24556SqjULFk9RIMiABfllOTJogYMLiMomKTLJqFrbk7VHdyhkcUyskSlwGSgRHdtnzXtdIDoZ9lcjJ3j0UXXTUaYlf/ed7mjIlCShVrVqcWKNgwuIysYd5Ead+DooQhHyCvN0h0MWxsQaaSc9Q5hYIyKv7t3VXq4Lhw7pjobMbMkStWdijexM+mQ9/nhJki0zU3dEpIUMK9i27ZRDC4Q8b3pvOrBijej0kqOSUS2mGnZn7dYdClkYE2uk3fr1qsea3GQ780zd0RCRbs2aAQ0aqKlmo0bpjobMfFPGOymxc2fd0RD514MPArVrA1u3Av/9r+5oyKzTQMXcuer6KMMvUlMDFh2RZQW5glArvhaCEMQJoVRhTKyRdt43RlKuHhWlOxoi0k0aLQ8YoI5/+kl3NGRWq1cDmzcDoaEcekP2Fx4OvP66On71VfW7T3S6wQVEVDZVIqqgelx19lqjCmNijbTjMlAiOpY3sTZ6NJCVpTsaMqOJE9VeKp0jI3VHQxSY66IkkWVIZf/+wI4duiMiM+LgAqKKTQitHV8bYcFhOJx3WHc4ZEHBugMgZzu6v9r55+uOhojMol07oFYtYONGYNw44NJLdUdkbcHBwbjrrruKj+2UWPP25CNyQjXvBx8A554LzJmjKv1//x1o1Up3ZPZjmWvmMdNABQcXEFVMfHi8kVxbtnsZokKijGSbFWTnZyMiJEJ3GI5n4mcKcoJVq1S7iLAw9sghouOXg775ploOysRa5YSFhWHw4MGwi4KCkjYCTKyRkzRvDvzzD3DRRcDKlcBZZ6meWg0b6o7M3tfM/NP0NdM+DfSIXbvUDSl5DpUbVERUPjXjamLrwa3IyMlAQkQCzG5f9j5k5mciPC/cGMJA+nApKGnlrVaTpJr0DyEiOnY56G+/AWPHqgpXeSN5881qGdSBA7ojJF0kkSDnPz6ebx7JeerXB2bMALp0AQ4fBm67DSgq0h0V6ZwE6iUV3qJxYyA21r+hEdlRZEgk6iXWw8G8gygsKoSZ5RbkIis/Cw0SG6CgqIBLWDVjYo208lYcsL8aER2rUyegaVPg0CHgwguBRo3Un4cMAX75BXjoId0RWofH48Hu3buNTY7tsgxUWgi43bqjIQq8hARg6FDVX3DqVODzz3VHZC+muWaWcRKokDDfeEMdX3ON/0MjsqtqMdWQGpWK3Vm7YVZyXdqZudOosGuS3AQNkxoa1Wv5hSatrnUAJtZIG3mNMH68Ou7RQ3c0RGQ2QUEq+S4JNHnzKFMgpSqjWze1zEXeSI4apTtKa8jKykJKSoqxybHVsb8aEVC7NvDii+p40CAOM3D6NXPCBGDhQvV8eaQ9HBFVQIg7BA2qNDCSV1IRZkZ7s/ciNizWiDPIFYS6CXWNJNv2w9ttcQPViphYI22mT1dLeZKS2GCViE4sNVXdgd+wAfjiC7UEUJIqDz6o/v6WW4C9e3VHSYEkS9/k+UPwpgw53X33qeXQGRlqmbz0HyRnev11tb/1ViAxUXc0RNaWHJmMOgl1jKq1Ik+R6YYV5BbmonFSY0SHRhsfCw4KNv6cGJFoVLJR4DGxRtqMHKn2vXtzKQ8RnVpyMnDDDUDbturP//mP6iEjFRr33lv6c2XVjPSZ+eQT4MMPy9yahizi2WeBvDygXj21ETmZDKz87DM1BGrMGHWzgf3WbO4Ek0DnzVM3neT1tPfGExFVnEwElSqwKhFVsDfLPHdwpe/brqxdqJdQD1VjSgaXiKjQKGNZqMR+KPeQthidytSJtVdeeQXt27dHTEyMUYrdr18/rJTO1Ufp2rWr8ctz9HbHHXdoi5nKn1jr00d3JERkNRERwJdfqjcR330HDB+uPv7zz0CtWkCvXsDtt6vlMB99pDta8pUpU4C33lLH77yjlgQTOV3r1sCPP6rroVwXBw5U/bbIpryTQI8k1uRcv/SS+qsrr1TPgURUeREhEWhYpSHyi/KNKjEz2J65Hekx6cYSUMl7HCslKgWNqjTC/pz9yCvM0xKjU5k6sTZ16lTcfffdmDlzJiZMmGCMuu7ZsycyMzNLfd6tt96K7du3F2+vvfaatpipbNauBVasUHdae/bUHQ0RWZEsIX/sMXV8553A998DV1+tKtRkap682RTS4Jus7+BB4MYb1ZtIWerEmzJEJS6+uGSAgSSfX35Zd0QUKHLzSG4qSV/SRx7RHQ2RvaRFpxmVa1IlpntJaEZOBiKCI9AkqQlC3aEn/bza8bWNZazSb02mhVJgBMPExo4dW+rPX3zxhVG5NnfuXJxzzjnFH4+MjERaWpqGCKmivA3HzzoLiI/XHQ0RWdUzzwC//w4sWqSSaqJ/f+CHH4A9e4Bq1YB//gHWrQPq1tUdLVXU/v3AtdcCGzcCdeqUTL4johLXXw/s26eWAj71lOqzJTcdyL6mTVN99sQrrwCtWumOiMhepCqsXmI97M/ej12Zu4xEmw6SIDuYexBt0tsgPvzUb57dQW4j+ZZbkGsk12TKqQw4IAcn1o51QDrdQ14olO7IOXToUHzzzTdGcq1v3754+umnjWTbyeTm5hqb10G5DW5Mqcw3Nqvz/gxm/ll+/12aqgXhwgsLkZ/PZiB2Pc9UOTzHpydV8P/7H9ClSzDy813o2rUIX3xRaFQ1VakCnHeeG3/8EYShQwvx2GNFjj3HR399qz3XzZ7twrXXurFhgwuhoR58/nkhwsM9lumdx8ex/ZnpHN99N7BrVxBeecWNu+/2oEqVQlx6KdeFVvaa6V1yFfBzLNMopGmedyqF9zg/H7t2AZddFoyCAhcuu6wIDzwgr6kDG56dmOlxTOY6x264US++HuZtn4cDWQcQExaDQNtxcIfRUy0tIq1M8QchCI0TGiMnLwfbDmxDenT6CZeO+lwhUFhQqO1x5OvHcXm+jstjkXmsRUVFuPjii5GRkYFpcnvmiE8++QS1atVC1apVsWjRIjz66KPo0KEDfpaa6JN47rnn8Pzzzx/38W+//faUCTnyjezsYFx3XS8UFLgxePAfqFbtsO6QiMjiZs1KxbJlVXDFFasQGVlS9j5xYk28/34b1Kx5EO++OxlOJS8MPvjgA+P4rrvuQshRTa/NbMOGWAwceI7xfJGamolBg2ajfn11k42ITkxe2X/8cUuMHVsHCQk5+OijiQgLK9QdlqVY4Zr522918fnnLVC9+iH8979TER7Oc0xE5EtZWVm45pprjAKv2NhYeyTW7rzzTowZM8ZIqlWvXv2knzdp0iR069YNa9asQb2TjAs7UcVajRo1sGfPntP+D7PKiwHpSdejRw9TvhD46ScXrr46GPXqebBsWQGbT9v0PFPl8RxXXkYGUL16MPLyXJg7Nx8tWsBUeI5PTl6d9O6tKg7PP78IP/xQiLg4WA7Psf2Z8RzLy9zmzYOxcaMLL71UiEGDzFexayXaznF2NiCD2xo1UlN7jnLJJW6MGROEV18txIMP8vza8XFM5jrH0mNtxe4VWLt/rTFAIDjI/4v/8gvzsePwDjRPaW70TasIGWSwaMci5BTkIDU6Ff609eBWtKvaTtuSWV8/jiVPlJSUVKbEmiWWgt5zzz0YOXIk/vzzz1Mm1UTHjh2N/akSa2FhYcZ2LPmfb6cLqVl/nl9+Ufv+/WVZj/nisxqznmfyHZ7jiktOBi68EBgxQiaHhqBtW5gSz/HxpM3qH38AoaHAZ58FISnJ2v1BeI7tz0znWMJ44QXghhuA119348473UhI0B2V9QX8HMsyJJlKINO+jvq+kjidOlUd9+rlRkiItFghuz2OyXznuGlaU+QhD1sObjF6l0k/M3+RRN7OwztRp0od1EuqV+HvlRKSgtbu1liwfQF2Zfu5T5wbcAe7tT+GfPU4Ls/XMPWrVCmmk6TaL7/8YlSi1ZGOxaexYMECY5+enh6ACKm8srKAkSPV8RVX6I6GiJzAO9RABhpYo0bbP8+nMlFbNisUqhcWAoMGqeN77lEDC4iofGTgR/PmqnL31Vd1R2MtZr9mzpihXlOnpsJ0ldhEdhbiDkGzlGZG5dfWQ1v9OilUkmqJEYlolNSo0gm8pMgktEprhTB3mFEBR75n6sTa3XffbQwlkN5nMTEx2LFjh7FlS1k0gLVr1+LFF180poRu2LABv/32G66//npjYmjLli11h08nMHq0eiFQuzbQrp3uaIjICS66CAgPV5NBZXqoU3tEREdHG5scm92XXwJLlqip0U8+qTsaImtyu4GXX1bH77wDrFqlOyLrMPs1c/x4te/RQw3xIaLAiQyJRMvUlkiJSjGWPvojubY3a29xEk++ny8kRyWjdXprI7m27dA2vyYFncjUibUPP/zQWM/atWtXowLNu/0gZQeQ5SGhmDhxInr27InGjRvj4YcfxoABA/D777/rDp1OYtiwkmo1vhAgokCIigIuuKD0UnQyLykO8SYDnnpKJoHrjojI2jcWunUDcnLUa68j96bJKmQZkqzCOWY50oQJJYk1Igq86NBoowJMKsGkcq2gqGRwli+SaoWeQqOvmnx9X5Kv1ya9DWLDYo3lrHmFeT79+k5m6h5rpyu9loEDU70NBshSy0Avv1x3NETkJP37qz5rMjD6ued0R0OnMmuWVKQDMqT7jjt0R0NkbXIT8+uvgdatgYULgQcfBD76SHdUVGaSUKtatdSH9u4F5s5Vx0ysEelNrkmSasmuJUZyLS0qDWHBx/dxL489WXuMSjJJ2lWNKf3Y95UqkVXQvlp7rNyzEhsyNhhJtvjweL98LycxdcUa2QuXgRKRzqoNWRa1eLFK2pB5DR2q9v36qWpDIqocKXj65huVZPv4Y+C773RHRJUhQ12k9kD657GlNJFeUaFRaJ3WGnUT6mJn5k5k5GRU6OsUFhViy6EtCHIF+TWpduxyVoldquM2H9jM6rVKYmKNAmb4cLXnMlAiCjRZTti1qzrmclDzKihQQya8jdeJyDekskmWVos77wS2btUdEVW2v1rPnrojISIhVWotUlqgbXpbo9ps04FNyCnIKfO/P5x32EiqpUSmGJVk/k6qeclAhDoJddCpeifUiq9lDDUoT9xUGhNrFBByZ23KFHXct6/uaIjIqctBhSwHJfNWYuzaBSQlcYkTka898wzQoQNw4ABw++3OnZJsZXLO2F+NyHwkSSXJKUlSSbJKKtekCuxg7sET9l+Tj8nnbDywETmFOWhcpbGRmNOxJFOWgkr1Wv3E+tiVuYvJtQpiYo0CYsMGYOdO1SrijDN0R0NETnTJJWo/YwawfbvuaOhEvv22pLL5mF7dRFRJwcHAkCEy/AsYNQr46ivdEVF5yWTXTZvUOTznHN3RENGxYsJi0Cq1FbrU6IIGVRoYSzwlWSVJNhkWIHupaJNlo6JZcjOcWeNMNE1pWun+bJVNDDZJbmIk1yS23IJcbbFYlamHF5B9yBtZ0bYtEB6uOxoicqJq1YBOnYCZM4FXXgHefReO4Xa7cdlllxUfm5H04PRWE15zje5oiOypaVPg+eeBxx8H7r9fLSdkny7rXDO91WpnnaUGvBCR+bhcLiREJBibJKoy8zORmZdp9DIT0kdNBh/EhMYgxG2eu4jBQcFGck3iXLd/HWrE1jBipbJhYo0Cmljr3Fl3JETkZI88opaEvveeGqTy0ENwhPDwcAwbNgxmJlOjDx9W56VLF93RENnXwIHATz8Bc+YAjz7KyrWyXDPz8/NhBuyvRmQtUoUmW2JEIqxAkmuNqjTCgZwDRqVdWnSa7pAsgylICojp09WeiTUi0unSS4HXXlPHDz8MfPYZ+wyZbRqoVKtxwA2Rf5eEfvCBepx9/XXJazQyN8ntTZ6sjtlfjYj8JSIkAk2TmxqVd4dyD+kOxzKYWCO/y8wEFi5Ux0ysEZEZqjXuu08d33or0KaNmlrMBJs++/YBY8aoYy4DJfK/9u2Bm29Wx/fcAxSqFUpkYtLGQKp6ZbhL69a6oyEiO0uOSjYq12TAAocZlA0Ta+R3stRAXrBJf6MaNXRHQ0ROJ1Uab74JPP00EB2tEv+XXw7cdJN931xmZmYadx5lk2OzkcSmVGO0agU0a6Y7GiJnePllIC4OmD8f+PRT3dGYixmvmd7+at27A0F8B0dEflY7vjbqJtY1hhmcaLIplcbLMgWsvxp75hCRWUgv6hdeADZuVAk2+fOXXwL/+pdK8JCeaaCsViMKnJQUdR0UMsxgxw7dEdGpsL8aEQV6UmjjpMbGEINth7ahyFOkOyRTY2KN/I6DC4jIrBIT1RvLH38EQkKA779XyR0uCw2czZuBqVPV8dVX646GyFnuuktNbM/IUFNCyZz27wdmz1bH7K9GRIES6g5Fs5RmSI5MNpJrHr5APikm1siv5LHHwQVEZHYyKfSXX4DQULUs8YcfdEfkHJLMFOecw3YBRDoGGcgyUKnalRsMMp2XzGfIEKCoCGjeHKheXXc0ROQkkSGRaJnW0phsuvXQVibXToKJNfKrtWuBPXvUm1VpEE5EZFZ9+gBPPaWOH3kEyMrSHZGzloFee63uSIicSSrWHnywpILtEIfAmUp2NvD66+rYe56IiAIpNiwWrdJaIT48HlsPM7l2IkyskV95q9XatQPCwnRHQ0R0+omhNWuq5YneNzLkP+vXAwsWqEbcUjVIRHo8/zxQp4669slwFzKPzz9X/e/kuUn6gBIR6UqutU5rjfiweGw7zGWhx2Jijfzqzz/V/uyzdUdCRHR6ERElCbVXX1VvMsl/RowoWQaalKQ7GiLniowE/u//1PHbb6uea6RfXp56LhKPPaZWgBAR6RIXHmdUrsWFxTG5dgwm1siv/vqr5E0TEZEVXH65uhkgy2/uvdcegwzcbjd69+5tbHJstsRav366IyGiyy4DmjZVSbV334WjmeWa+dVX6gZPejpw003awiAiKibLQSW5Fhsai+2HtzO5dgQTa+Q3Ura+ahXgcgFnnqk7GiKispFr1gcfqCmhkvj5+WdYXnh4OEaNGmVscmwGe/eWVDVfconuaIhIlmQ/+6w6fustZ1etmeGaKcMKvBXU0vfTJJduIiIjudY6vTViQmOYXDuCiTXye7Vay5ZAfLzuaIiIyk4mrz36qDq+5x5nv8H0F5k+KG8cW7UCatfWHQ0RHVu19s47uqNxtkmT1A3qmBjgllt0R0NEdOLKNSbXFCbWyG+4DJSIrOzJJ4FGjVT1rTfJRr7DZaBE5q5ak2qpjRt1R+RcUjktbrgBiI7WHQ0R0fESIhLUstCwWGw9tBVFniI4FRNr5DccXEBEVibLbj75RB3/73/A1q2wrMzMTERFRRmbHOsm/evGjVPHTKwRma9qTV67yaXirrvs0WfSatfMLVuA335Tx3feGfBvT0RUruRa2/S2SIlKgQsuOBUTa+QX+/cDixapYybWiMiqpOJWrmGFhcDnn8PSsrKyjM0MfvlF4lFLQGUpKBGZq2pNbirIBMrRo4EffoAj6bxmfvqpet4591y1NJeIyMxiwmLQJr0N6iXUQ5g7DE7ExBr5xd9/qzucDRsCaWm6oyEiqrjbby/9RocqT/5fihtvVMMiiMhcGjdWy+HF/fcD//zjzMo1HfLzS6qlpWKQiMgKwoPD0TKtJapEVoETMbFGPifNqL//Xh2zWo2IrG7AACAhAdi8uWT5IlXc6tXAlCkqoXbzzbqjIaKTeewxVS21axfQqRPQrBnw3Xe6o7K/4cNVb0+5Mc2l8kRE1sDEmk0TW7ruKkrfnKuuAoYOVX/u319PHEREvuy1Js2jxccf647G+qRfnejVC6hRQ3c0RHQyshR01Cjg2muBiAhg+XLgmmuAb77RHZl9yev3V14p6a0m54CIiMyPiTUb+uknF+6993y8+moQNm3y//eTpVEyAfSll4COHYFhw4CQEGDIEKB3b/9/fyIif7vtNrUfOdLaQwzMsMTpiy/U8a236o6GiE5H+iBKIk0qqLxN9GUJtyTcyPfkOWbxYiAmBrj3Xt3REBFRWTGxZkM//BCELVti8PTTbtSqBVx4oVp64w85OUD37qrB91NPqRcDiYnAxInqhRcRkR00aaKWtktF8Lvv6o7Gun7/Hdi5E0hNBS66SHc0RFRWsbHA++8D//qXuqEqk0PnztUdlf2q1eQmtbe3mrQgICIia2BizYb+979C3H33fJx7bpHx57FjgZYtgVdf9W3jbfla8gJLeuVERQGXXw689x6wZIlKtBER2cmgQWov1zmp3rCSoKAgnHvuucYmx7reNL71ljq+6SZV2UxE1iGXDpmOLDds5cbqww/bd6CBjmvm5MlqSIS0H3jwwYB8SyIi8hEm1mwoLg7o0WMTJkwoNCrVevRQL4CkCa23b0NlyQupBx6QZaeq/4OUrv/4I3DPPUB6um++BxGRmUiFlSx3l16SvrqWBkpERASmTJlibHKsg7whnzYNiIwsWVJGRNYiCXHpNSmv/aZOBf74A7ak45r58stqf8stqqqXiIisg4k1m6tfX02xe/119ec33gAOHvTNxCJZEiC+/hro2rXyX5OIyMxkiuV//qOOP/pITQmlspEKv4ED1fELLwA1a+qOiIgqSoaO3HGHOpY2IHatWgskqVSTJGVwcEl1NBERWQcTaw55Mygl5Y0bAxkZwODBlft6mZnAQw+p4yefBK64widhEhGZXrdu6kZCXl5Jko1O7/771fNPu3bqmIis7fHH1aRQSQhxkIHvqtWuu443HoiIrIiJNYdwu4EnnlDHb76pkmMVJUugtmyBMRhBEmtERE66UfHii+r4s8+A2bNhCZmZmUhOTjY2OQ6kH35QrQLkeejTT1VFBhFZW1paydTKp5+2X9VaIK+ZMvjrt9/U88ujj/r1WxERkZ8wseYgV18N1K0L7NkDfPJJxb7GmjUly0olQaepVQ8RkTZnnQVcdZWaECpN+HNzYQl79uwxtkBatAi4+WZ1LG8Y27QJ6LcnIj965BEgLAxYsABYvhy2E6hrprdnpwwBa9TI79+OiIj8gIk1B5EqASndFzIhtLz9gaQ3m7xBkiVQ3bsDl17qlzCJiExPJoOmpABLlwLPP687GnPatw/o1w/IylJDdKS3GhHZR5UqJVPgx4/XHY01yQ1rqeoV3tfoRERkPUysOcz116u7YTt3Auedp5Jr69ernjfS10FK0fPzj/93W7eqF09//aUmur37ripZJyJyoqQk4MMPS25UzJmjOyJzOXxY3XyR55c6dYDvv1dLQYnIXi64QO1lUBaVn7RpkernPn2A1q11R0NERBXFTicOI+PR5a6iJNXWrlWNpKWqoLBQ/f033wDJyerJXZqnylLPTZuAmTOBXbtUhYY0qW3SRPdPQkSkV//+wJVXqmoD6TfJN5bKgQNA797A9OlATAzw669AYqLuqIjIX4k1mfg7dSqQkwOEh+uOyDr+/BMYNgwICipZDkpERNbExJoDScJs8mSVXFu3Tn2sZ0+gaVPgu+9UNduECcf/O5kqOnq0qj4gIiI1yW34cHXDYtYsoEMHwOlJNVn2KUMd4uNVsrFlS91REZG/NGsGVK0KbNumVjXI459OT25oP/CAOr7tNqBFC90RERFRZTCx5uDkmtwp+9//gAsvBNq3Vx+XwQQzZqhqto0b1d1H+dzatYGuXTmsgIjoaDIQ5l//Ar78EvjPf9RyeieT6YCSVJPeS3KDhsMKiOxN2oLIzdkvvlCJdCbWykaeM+bPB+Li2H+SiMgOmFhzsGrVgGeeOX7Awdlnq42IiMrWI+err4Dff1fT8czYJycoKAhnnHFG8bE/yFTADz5Qx7I8lkk1IucsB5XEmp0GGPjzmimrRQYNUsfyOlxasBARkbVxeAEREVElNGyoeq2Jp55SE5SFVPz+9JPaPB6tISIiIgKzZ882Njn2h4ceUsubLrkE6NbNL9+CiExIqtSkcm3xYrUk1A78dc2U54e+fVV/Y8nb3XOPz740ERFpxMQaERFRJcnwAiHDXdLS1BL79HTgssvUdvvtJ564bBdjxgBjxwIhIaqlABE5hyz9PlLchREjdEdjXnLj4dprgWXLVF86+X8lQ8WIiMj6mFgjIiKqpObNga+/VkNesrNVkikjQ715klVEn34K9OoF7N8P25FqvEcfVcf33Qc0aKA7IiIKtKuvVvvPPtMdiTktXAicey4wcqSanCrTkuX5gYiI7IGJNSIiIh+QIQZSiSDN+199VTXv37xZDTSIjgYmTVJLRnUsC83KykLt2rWNTY59SQbeyBIwWS3lrdwjIme57jpVfTVvntqszlfXTLneSx/Otm2Bv/8GoqKAb74pGRpGRET2wMQaERGRj0ifIVkS9cgjQPfuqlqtTx81hVmqFCTZ9u23gY/L4/Fg48aNxibHvuStULniCiAhwadfmogsIikJ6N9fHUuFrtX56pop18dXXgGKilRbgBUrgAEDfBoqERGZABNrREREfiYTMp9+Wh0/+KBqXG0H0ohbJoCKW2/VHQ0R6XTLLWovNw8yM3VHo59UMN9/vzr+v/8Dhg0DqlfXHRUREfkDE2tEREQBMHAg0LQpsHt3SU8yq5M30LJKqkkToEsX3dEQkU7nnQfUrasS7pJEcjLptXnVVWrfsycwaJDuiIiIyJ+YWCMiIgoA6T/08ccly4P++guW513yJdVqsgyWiJxLlr57q9aeeQZ49111I8GJ3nxT9Z5MSQG+/FL9vyEiIvviZZ6IiChAzjqrZMnk7bcDeXmwLG+TckkYSuNyIqKbbwbS09XgFlkGKZMvL7kE+OknIDcXjiAt2YYMUcevvQakpemOiIiI/I2JNSIiogCSiaFSxbB8OfDf/1r3afiDD9T+0ktV43IiotRUYNEi4L331CCXggI1GVka98twk27dgP/8B1i5Erb1zz/A2rVqAqj83EREZH/WfUVPRERkQfLm8u231fErrwRh27Yov39Pl8uFpk2bGpscV5Ys7/rmG3V8332Vj4+I7EMS7ffcA8yeDSxdCjz2mGraL/3GJk1Sg1waNwY6dpSbC+rzDh0Cvv9eTVFu2xbo1w946CF9CbjKXDO910a56SDJNSIisr9g3QEQERE5jTS1/uILYPx4F955p62xlDIkxH/fLzIyEkvlHa6PfPKJWtYlFSmdO/vsyxKRzcjAlldeAV5+WVXpTp0KjBwJjBsHzJqlthOZP1/t//c/4JdfgPPPD2jYx10z8/Pzy/Tv5NMkQSj+9S9/RUdERGbDijUiIqIAkwKIjz4C4uM9WLkyEXff7Tb68liB9IUbPFgdP/AAhxYQ0enJdUKSbHfeCYwaBWzdqoYb9O0r10H1ObVqqaEHsnRUrjEyaVgmjPbqBXz1FSxBEoZ796olsbLslYiInIGJNSIiIg3q1AG+/bYQQUFF+OqrIGOKnBUMHw5s364alF9+ue5oiMiKJPF0770qiSaJKBl2sG4d8PzzKtl2113AH38AV16pqsBuuEENfMnKgql5l4FefTUQzHVBRESOwcQaERGRJt27e3DzzUuM40GDVC8i6UN0tI0bgXfeURM4KyorKwvNmjUzNjmuKKmq8/aHkze+MhGUiKgygoJUDzbZHy08XG4+AE8+qSreZAm6LD+X4QD+VpFr5oEDwIgR6pjLQImInIX3UoiIiDTq02c9IiKa4b333MbE0J9/VkufhLT4kWbfQqofXnwReOSR49+Ano7H48GyZcuKjytKYpNG4/KGV6pHiIj8Sa51MkW0a1cYvSilT1unTsBFF6nqNhl04A8VuWYOHQrk5Kglr/6Ki4iIzIkVa0RERBpJJcYbbxQZlQ5VqwKrVwPvvac2b1JNJugVFACPPw707Ans2xf4OOUNo1TVCUnuJScHPgYicqbu3YFFi4Abb1TJNhmA0K6dmry5cKHu6FQ178cfq+PbbmPvSSIip2FijYiIyAQuvhiQAok33gCeekptcrxhg/r4Z5/JpDrVd0jeZAY6uSZLQNevV8k/SawREQWSJPOHDFFVa7LUUpJXv/4KtG4NnHce8PnnatiBDjLdVBJ/Us0rlXVEROQsTKwRERGZRFwc8NBDasmnbHIsk/LkDeS//w3MnKneXM6fr5Jr0vQ7ELZtA156SR3/3/8BUVGB+b5ERMdq2BD4+mu1VP6qq9T1ccoUdY2sVg144glgz57AxiT934QMdElMDOz3JiIi/ZhYIyIisogWLYDJk0uSazKZs0sX4Omn/VfB9uefQMeOwOHDQIcOwLXX+uf7EBGVR5MmwHffqarel19WS+blOvXKK2rqskwU/eADlYCrRGvJMg0t+P77kmWgRETkPEysERERWUizZiq51qgRkJ8PzJihmnvLcqi//vLN95AheBMnAvffr5ZYbdkCNGgAfPll+QcnEBH5U82aqv+kLJn3Lg2VBNuPPwJ33w00bw6kpAADBqibELKsfto0oLCw8t+7qAh44QV1zZShBWee6YufiIiIrIZTQYmIiCyYXJM+Q9LzTCrKZJnmmjVqcp4sIZU3mUc3z3a5XKgla0qPHJ/MqlVqqadMt8vLK/m4NAyXYQrR0X79sYiIKkwubZdcovpVSuJMlodOnQpMn66WhspUY9m8ZNnoNdeoCcf16h37tU5/zdy+Hbj+enUTQjz4IIcWEBE5FRNrREREFiRv4OrWVZtUYtx7r6ooe/JJVa0hyTbvm7zIyEhskPVSx5DlUStXqgq4ceOA339XFRiienVVrSY9g/r2DfAPR0RUQXLdO/tstUmFmtwkmDMH+PtvYO1aYONG4J9/gK1bgddfB959V103ZShLWNiJr5n5Uh58xLx5qupNbkDIsAQZKiM3Hm66ScdPS0REZsDEGhERkcXFxABffAG0aQM88IDqMSQJssceA+LjS3/uoUNqudSYMSqhtmNH6b+/6CL1JlP6qrH6goisLjRU9aKUzSs3Fxg9Gnj/fWDSJOCZZ4BvvwW++QZo1+7EX2fnzkj06+c2/p2XXHPl30l/NyIici4m1oiIiGxCeqJJD7T77gNefVVtMmlUVjTVrg2EhKg3k9nZJf9GKjTkDadUp8kyqpYtdf4ERET+J9e9Sy8F+vUDfvhB3ZBYsQLo3FndmJBlnd5+kjKc4L//DcJrr52PvLwg4zp62WVqCqlcN9l3koiImFgjIiKyEVkSKm8an31WVaPJm8JFi7KxaNE5Rz7jTzRsGIErrgC6dQM6dQLCwzUHTUSkgVTlXnUV0LMncOutqgfbwIGy1DMb+/adYyTNsrL+xMGDEcbnn3deET74IIgVakREVAoTa0RERDZz221qy8xU/YRWrixC//5zjL+bMqUI55zDZZ5ERF6JicDw4cAnn6hqtRUrpNmkumYCRWjSxIM+febgpZdaIzSUJWpERFQanxmIiIhsKioKaNpUVWN4nXEGk2pERMeS66JMCN20SQ2C8ZIhBfPnF+Css7bx2klERPZOrA0ePBi1a9dGeHg4OnbsiFmzZukOiYiIiIiILCQpSU1a9pLek+yjRkREp2KLp4kffvgBDz30EJ599lnMmzcPrVq1wgUXXIBdu3bpDo2IiIiIiIiIiGzKFom1N998E7feeituuukmNG3aFB999BEiIyPx+eef6w6NiIiIiIiIiIhsyvLDC/Ly8jB37lw8/vjjxR8LCgpC9+7dMWPGjBP+m9zcXGPzOnjwoLHPz883Nqvz/gx2+Fno5Hie7Y/n2P4CdY6P/vp2ea6zCj6O7Y/n2H6OvWa6jjRX4zm2Lz6O7Y/n2P7yfXyOy/N1XB6PxwML27ZtG6pVq4bp06ejc+fOxR9/5JFHMHXqVPzzzz/H/ZvnnnsOzz///HEf//bbb41KNyIiIjvJycnBbTImFDL17hOjHykREZ0Yr5lERJSVlYVrrrkGBw4cQGxsrL0r1ipCqtukJ9vRFWs1atRAz549T/s/zAokszphwgT06NEDISEhusMhP+F5tj+eY/sL5Dnu37+/X78+nRgfx/bHc2xPR18zeY7tj+fY/niO7S/fx+fYu7KxLCyfWEtKSoLb7cbOnTtLfVz+nJaWdsJ/ExYWZmzHkv/5dnqQ2e3noRPjebY/nmP74zm2P55j++M5tj+eY/vjObY/nmP7C/HROS7P17D88ILQ0FC0a9cOf/zxR/HHioqKjD8fvTSUiIiIiIiIiIjIlyyfWBOyrPPTTz/Fl19+ieXLl+POO+9EZmamMSWUiIjI6bKzs9G1a1djk2MiIjo5XjOJiKg8LL8UVFx55ZXYvXs3nnnmGezYsQOtW7fG2LFjkZqaqjs0IiIi7aSSWwb6eI+JiOjkeM0kIiLHJdbEPffcY2xERERERERERESBYIuloERERERERERERIHGxBoREREREREREVEFMLFGRERERERERERUAUysEREREREREREROXl4AREREZ1cZGSk7hCIiCyD10wiIiorJtaIiIhsLioqCpmZmbrDICKy5DUzPz9fazxERGRuXApKRERERERERERUAUysERERERERERERVQATa0RERDaXk5ODPn36GJscExHRyfGaSURE5cEea0RERDZXWFiI0aNHFx8TEdHJHXvNdLvdukMiIiITY8UaERERERERERFRBTCxRkREREREREREVAFMrBEREREREREREVUAE2tEREREREREREQVwMQaERERERERERFRBXAqKACPx2PsDx48CDvIz89HVlaW8fOEhIToDof8hOfZ/niO7S9Q5zgzM7P4WL4XJ4MGDh/H9sdzbD/HXjNDQ0N5jm2Oj2P74zm2v3wfn2NvfsibLzoVl6csn2VzW7ZsQY0aNXSHQUREREREREREJrF582ZUr179lJ/DxBqAoqIibNu2DTExMXC5XLA6yaxKolB+AWJjY3WHQ37C82x/PMf2x3NsfzzH9sdzbH88x/bHc2x/PMf2d9DH51hSZYcOHULVqlURFHTqLmpcCiqN5oKCTpuBtCL5ZeJFw/54nu2P59j+eI7tj+fY/niO7Y/n2P54ju2P59j+Yn14juPi4sr0eRxeQEREREREREREVAFMrBEREREREREREVUAE2s2FBYWhmeffdbYk33xPNsfz7H98RzbH8+x/fEc2x/Psf3xHNsfz7H9hWk8xxxeQEREREREREREVAGsWCMiIiIiIiIiIqoAJtaIiIiIiIiIiIgqgIk1IiIiIiIiIiKiCmBijYiIiIiIiIiIqAKYWDOpP//8E3379kXVqlXhcrnw66+/lvr7nTt34sYbbzT+PjIyEr169cLq1atLfc7atWtx6aWXIjk5GbGxsbjiiiuMf3esUaNGoWPHjoiIiEBCQgL69evn95+PgFdeeQXt27dHTEwMUlJSjP/vK1euLPU5OTk5uPvuu1GlShVER0djwIABx53DTZs2oU+fPsbvgXydQYMGoaCgoNTnTJkyBW3btjUmpNSvXx9ffPFFQH5GpwvkOfb6+++/ERwcjNatW/v1Z6PAn+OhQ4eiVatWxuekp6fj5ptvxt69ewPyczqZr87xfffdh3bt2hnX4RM9PuU6fckllxjnNioqyvgcOedkn3MsZGbYf//7XzRs2ND4vGrVquGll17y689HvjnHCxcuxNVXX40aNWoYr5mbNGmCd95557jvxddc9j/HXnzNZd9zzNdc1j7Pe/fuNfIjkiuRa7Gc73vuuQcHDx4s/pyff/4ZPXr0KM6VdO7cGePGjatw3EysmVRmZqbxYB48ePAJX5TJL9i6deswYsQIzJ8/H7Vq1UL37t2Nf+f99z179jSScpMmTTIu/Hl5eUayrqioqPhr/fTTT7juuutw0003GRca+bxrrrkmoD+rU02dOtW4IMycORMTJkxAfn6+cc6851A8+OCD+P333zFs2DDj87dt24b+/fsX/31hYaHxZlzO7fTp0/Hll18aL+CeeeaZ4s9Zv3698TnnnXceFixYgAceeAC33HJLpS4cZK5z7JWRkYHrr78e3bp1C9jP6HSBOsdybZZz++9//xtLly41vtasWbNw6623BvxndhpfnGMveWF+5ZVXnvD7yLlv2bKl8by8aNEi43lZzvnIkSP9+vNR4M6xuP/++/HZZ58ZybUVK1bgt99+Q4cOHfz2s5HvzvHcuXONN3nffPONcR1+8skn8fjjj+P9998v/hy+5rL/Ofbiay77nmO+5rL+eQ4KCjJuVspz7KpVq4zX1RMnTsQdd9xRqpBJEmujR482fi/kui25EsmtVIiHTE9O0y+//FL855UrVxofW7JkSfHHCgsLPcnJyZ5PP/3U+PO4ceM8QUFBngMHDhR/TkZGhsflcnkmTJhg/Dk/P99TrVo1z2effRbQn4dObNeuXcZ5nTp1avH5CgkJ8QwbNqz4c5YvX258zowZM4w/jx492jjPO3bsKP6cDz/80BMbG+vJzc01/vzII494mjVrVup7XXnllZ4LLrggQD8Z+fscH31en3rqKc+zzz7radWqVcB+LvL/OX799dc9devWLfW93n33XeMaTuY/x0crz+Ozd+/enptuusmH0ZPOc7xs2TJPcHCwZ8WKFX7+Ccjf59jrrrvu8px33nnFf+ZrLvufYy++5rLvOeZrLnue53feecdTvXr1U36vpk2bep5//vkKxcmKNQvKzc019uHh4aWyslLmOG3atOLPkWo1+ZiXfL58nvdz5s2bh61btxofa9OmjVHmeuGFF2LJkiUB/5kIOHDggLFPTEw09pI5lwy9VCJ6NW7cGDVr1sSMGTOMP8u+RYsWSE1NLf6cCy64wChzlTss3s85+mt4P8f7Ncj651gMGTLEqGJ99tlnA/gTUaDOsZSnb9682birJvdbpNx9+PDh6N27d4B/QqrIOa7M9/J+H7L+OZa763Xr1jWqEOvUqYPatWsb1Uz79u3zw09BgTjHxz5G+ZrL/udY8DWXvc8xX3PZ7zxv27bNWPp57rnnnvT7yKq+Q4cOVfh1FxNrFuT9xZGy1f379xvLh1599VVs2bIF27dvNz6nU6dORo+WRx99FFlZWUbp5MCBA40lR97PkScE8dxzz+Gpp54yXuhJj7WuXbvyRV6AyQNZlguceeaZaN68ufGxHTt2IDQ0FPHx8aU+V958y995P+foN+Pev/f+3ak+R960Z2dn+/XnosCcY+mv+Nhjjxll7dLrg+x3juVrSr8PWWImXy8tLQ1xcXEnbBdA5jvHFfHjjz9i9uzZxpJQssc5ltddGzduNJaufPXVV8bSFHmDcNlll/n85yD/n2NZvv3DDz/gtttuK/4YX3PZ/xzzNZf9zzFfc9nnPF999dVGnzzpZyp91KQVw8lIi4bDhw8bfekrgok1CwoJCTEyrrJeWDKq8ssyefJko9pMqs+ENOGTF25yd1Qa+snFQHoBSDNV7+d4e63J2nJp+CcNd+UOjFS6yb+lwJF15FIp+P333+sOhSx2jiVZLn0Rn3/+eaMZNtnzcbxs2TKjN5P0XZM34mPHjsWGDRtK9Yog+1yr5TldEmqffvopmjVr5tfvRYE7x/K6S1YUSFLt7LPPNm5k/u9//zPO97GNmcnc51j+vfTvkYol6f1DzjjHfM3ljMcxX3PZ5zy/9dZbxio96Usvgx0feuihE37et99+azyu5aam9OCrCKbZLUqSYNIUVUojpWJNEmky2fOMM84o/hy5QMgv0J49e4w7KpLVlYy7LEMQsvRTNG3atPjfyNJR+XuZUEeBIRNKpFpQGihWr169+ONyruTcSkL06Iy8lCPL33k/R5ppHs07EeXozzl2cpn8WbL2Mg2HrH2OpWR5zpw5RqNN+T7eN29Sui6P+/Hjx+P8888P0E/qXP5+HMuEJLlbJ9NChTS5l6pkeXP+n//8p/h6TuY8x+UhTXilea68GJTmyWSfcyyPU7kuH/2GXCbSCXnd1ahRI5/9LOS/cyxvuqVhvVS4yIqPo/E1l73PMV9zOeNxzNdc9jnPaWlpxiYr/qQgSc7h008/XeocStJO2jJIYdGxS/nLgxVrFieVaJJUk7JkudBL1v1YSUlJxi+dTAfdtWsXLr74YuPj3pHwR98llfXKkpGXKaPkX/IkLBeMX375xTg30m/laHJ+pDrxjz/+KP6YnCt58S1r/4XsFy9ebJxXL5meIi/gvAlT+Zyjv4b3c7xfg6x9jmUvfy+Jdu8md9TkDZocS8KdrP84liX93mpjL7fbXRwDmfscl9WUKVOMiYLS3uHoZSlkj3Msb9QKCgqMm55esvpA8HWXNc6x9L2UyXE33HADXnrppeO+D19z2fsc8zWXMx7HfM1lz+fkoiOr9bz96sV3331nrBCQvbz+qmzgZEKHDh3yzJ8/39jkNL355pvG8caNG42///HHHz2TJ0/2rF271vPrr796atWq5enfv3+pr/H5558bkzHWrFnj+frrrz2JiYmehx56qNTn3H///caEE5kiKlOq/v3vf3tSUlI8+/btC+jP60R33nmnJy4uzjNlyhTP9u3bi7esrKziz7njjjs8NWvW9EyaNMkzZ84cT+fOnY3Nq6CgwNO8eXNPz549PQsWLPCMHTvWmA77+OOPF3/OunXrPJGRkZ5BgwYZE1MGDx7scbvdxueSPc7xsTihyn7neMiQIcY0wQ8++MC47k+bNs1zxhlneDp06BDwn9lpfHGOxerVq43n8dtvv93TsGHD4ud47+RX+bdyrZbzfvT32bt3b8B/ZqcJ1DmWCe5t27b1nHPOOZ558+YZX6djx46eHj16BPxndhpfnOPFixcb1+Z//etfpb6GTKzz4msu+5/jY/E1l/3OMV9zWf88jxo1ysiFyPlev369Z+TIkZ4mTZp4zjzzzOLPGTp0qHGe5Tp99PeRqaMVwcSaSUnSTBJqx2433HBDqXGxMmpWfqlk3LP3hZvXo48+6klNTTU+p0GDBp433njDU1RUVOpz8vLyPA8//LCRTIuJifF0797ds2TJkoD+rE51ovMrm1zMvbKzs40R0AkJCcYLtUsvvdR4wB9tw4YNngsvvNATERHhSUpKMs5nfn7+cb9PrVu39oSGhhrjo4/+HmSPc3w0vsiz5zmWUe8yBlw+Jz093XPttdd6tmzZErCf1al8dY7PPffcE34decEn5Pn9RH8v/47scY7F1q1bjRuh0dHRxmu0G2+8kclTi5xjeW490deQm9tH42su+5/jo/E1lz3PMV9zWfs8T5o0yUi0SYIuPDzcyIVIbmT//v2nfc725lvKy3UkeCIiIiIiIiIiIioH9lgjIiIiIiIiIiKqACbWiIiIiIiIiIiIKoCJNSIiIiIiIiIiogpgYo2IiIiIiIiIiKgCmFgjIiIiIiIiIiKqACbWiIiIiIiIiIiIKoCJNSIiIiIiIiIiogpgYo2IiIiIiIiIiKgCmFgjIiIiIiIiIiKqACbWiIiIiGzmxhtvhMvlMraQkBCkpqaiR48e+Pzzz1FUVFTmr/PFF18gPj7er7ESERERWRkTa0REREQ21KtXL2zfvh0bNmzAmDFjcN555+H+++/HRRddhIKCAt3hEREREdkCE2tERERENhQWFoa0tDRUq1YNbdu2xRNPPIERI0YYSTapRBNvvvkmWrRogaioKNSoUQN33XUXDh8+bPzdlClTcNNNN+HAgQPF1W/PPfec8Xe5ubkYOHCg8bXl33bs2NH4fCIiIiKnYWKNiIiIyCHOP/98tGrVCj///LPx56CgILz77rtYunQpvvzyS0yaNAmPPPKI8XddunTB22+/jdjYWKPyTTZJpol77rkHM2bMwPfff49Fixbh8ssvNyrkVq9erfXnIyIiIgo0l8fj8QT8uxIRERGRX3usZWRk4Ndffz3u76666iojGbZs2bLj/m748OG44447sGfPHuPPUtn2wAMPGF/La9OmTahbt66xr1q1avHHu3fvjg4dOuDll1/2289FREREZDbBugMgIiIiosCRe6qyrFNMnDgRr7zyClasWIGDBw8avddycnKQlZWFyMjIE/77xYsXo7CwEA0bNiz1cVkeWqVKlYD8DERERERmwcQaERERkYMsX74cderUMYYayCCDO++8Ey+99BISExMxbdo0/Pvf/0ZeXt5JE2vSg83tdmPu3LnG/mjR0dEB+imIiIiIzIGJNSIiIiKHkB5qUnH24IMPGomxoqIivPHGG0avNfHjjz+W+vzQ0FCjOu1obdq0MT62a9cunH322QGNn4iIiMhsmFgjIiIisiFZmrljxw4jCbZz506MHTvWWPYpVWrXX389lixZgvz8fLz33nvo27cv/v77b3z00Uelvkbt2rWNCrU//vjDGHogVWyyBPTaa681voYk5STRtnv3buNzWrZsiT59+mj7mYmIiIgCjVNBiYiIiGxIEmnp6elGckwmdk6ePNmYADpixAhjCackyt588028+uqraN68OYYOHWok3o4mk0FlmMGVV16J5ORkvPbaa8bHhwwZYiTWHn74YTRq1Aj9+vXD7NmzUbNmTU0/LREREZEenApKRERERERERERUAaxYIyIiIiIiIiIiqgAm1oiIiIiIiIiIiCqAiTUiIiIiIiIiIqIKYGKNiIiIiIiIiIioAphYIyIiIiIiIiIiqgAm1oiIiIiIiIiIiCqAiTUiIiIiIiIiIqIKYGKNiIiIiIiIiIioAphYIyIiIiIiIiIiqgAm1oiIiIiIiIiIiCqAiTUiIiIiIiIiIiKU3/8DrGOj68uaGUoAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 1500x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABOwAAAK9CAYAAACXR/PtAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQABAABJREFUeJzs3Qd4U+XbBvCnew9oS1llb2QvBVQQZAgIDlRciFvce4t74f6Lfqi4xQkuhogMERBZsmRDaWlLoZTuvb7rfg+npCFtkzbNybh/XjGhSc55k9Om6ZNneFVUVFQIEREREREREREROQVvoxdAREREREREREREpzBgR0RERERERERE5EQYsCMiIiIiIiIiInIiDNgRERERERERERE5EQbsiIiIiIiIiIiInAgDdkRERERERERERE6EATsiIiIiIiIiIiInwoAdERERERERERGRE2HAjoiIiIiIiIiIyIkwYEdERERu49ChQ+Ll5SWffvqp0UvxeLYcC/22r732mkPW5q6uu+46adOmjdHLICIiIjtgwI6IiIicytq1a+Xpp5+WzMzMBtvHypUrVYDI0umKK64Qd7do0SL1HLvLfhEUxLHbuHGjxevHjx/v9IGsnTt3qucGwUtP+p4gIiIiy3yr+ToRERGRYQG7Z555RmULRUZG2nTf1q1bS0FBgfj5+Vl1+7vuuksGDBhQ5WvOHtixV3Bm1qxZDRqgsXQsHLFfV4WAHb7vhw0bVufvwQ8//FDKy8vrdF8eGyIiIufCgB0RERG5DWRZBQYGWn37s88+Wy699FK7ryMvL09CQkLEk9l6LDxVYWGh+Pv722Vb1gaqiYiIyPmxJJaIiIicBrJ7HnzwQXW5bdu2lWWqepng0qVLZejQoSrzLjQ0VDp37iyPPfZYg/Ww+/fff2Xs2LESHh6u9jdixAhZt26dxXLMP//8U6ZPny5NmjSRli1bVl6/ePFiFRhEAC8sLEzGjRsn//3332n72r17t1x22WUSExMjQUFB6rE9/vjjldcnJCSo7ePruD4qKkomT558WgllSUmJytTq2LGjCpjhdnjO8NwBMheRSQWmpcDVue+++9Q2KioqKr925513qvu88847lV87evSo+tr7779v8VhYu98PPvhA2rdvLwEBASr7ccOGDWJvpj3zrNlfbccGkpOT5frrr5fY2Fi1re7du8vHH39ssRT7m2++kSeeeEJatGghwcHB6nnEsYThw4dXPje4Pfz888/q+6Z58+Zq21jvc889J2VlZTX2sLP2cVZ3bHDMsb2JEydaDDRGRETILbfcUsejQERERDVhhh0RERE5jYsvvlj27t0rX3/9tbz55psSHR2tvo5ACYJc6EXWs2dPefbZZ1XgYf/+/bJmzZo67y8nJ0eOHz9e5WuNGzcWb29vtT8E2hCse+ihh1T20uzZs1XJIoJzgwYNqnI/BNOwzqeeekpl2MEXX3whU6dOldGjR8srr7wi+fn5KqCFABqCgXpwZdu2bWpf2MfNN9+svn7gwAH59ddf5YUXXlC3QYAF5cLosYeAIIIx2BbWg3JKBH70oOdLL70kN954owwcOFCys7NVb7fNmzfL+eefrwIsKSkpKoCH9dUG68KxwPNxxhlnqK/99ddf6jnCOcqK9a/BOeecY3E71ux37ty56pjgtggYvfrqq+p74uDBgw2SPWbN/qw5NghWnnnmmWobd9xxh/o+QKD2hhtuUM//PffcU2W/CLYhq+6BBx6QoqIiGTVqlHoeEbhDALpr167qdvo5gp4IGCN4ivPly5er7zNse+bMmfV+nNUdG9z26quvVrc/ceKE+tnQ4fFj/7ieiIiIGkAFERERkROZOXMmUrkq4uPjq3z9zTffVF9PS0ur9r64D27zySef1LiPFStWqNtZOun7nTRpUoW/v3/FgQMHKu+XkpJSERYWVnHOOedUfg37wv2GDh1aUVpaWvn1nJycisjIyIqbbrqpyr5TU1MrIiIiqnwd28N2ExISqty2vLy88nJ+fv5pj+Pvv/9W+/78888rv9arV6+KcePG1fj4b7/9dnU/axw7dkzd9r333lP/zszMrPD29q6YPHlyRWxsbOXt7rrrrorGjRtXrtnSsahuv/pto6KiKk6cOFH59Z9//ll9/ddff61xjfox2LBhg8Xr8Xy0bt26Tvuz5tjccMMNFc2aNas4fvx4ldtcccUV6ljrx07/vmvXrt1px/P7779X1+E25iwd+1tuuaUiODi4orCwsPJrU6dOrfPjrO7Y7NmzR339/fffr/L1Cy+8sKJNmzZVngciIiKyH5bEEhERkUvQB1CgPLCujfXNIUsJWUWmp6ZNm6pSw99//10mTZok7dq1q7x9s2bN5Morr5TVq1er7CJTN910k/j4+FT+G9vCpNspU6aoLD79hNsgO2/FihXqdmlpabJq1SpVTtmqVasq2zQtGUUppmnZa3p6unTo0EE9L8ieM32ekA23b98+uzxHyBbr0qWLWiMgoxGPAaXLyCzT94MMO2QO1lReW5vLL79cGjVqVPlvZLYBMsEaQm37s+bYoGx03rx5MmHCBHXZ9FgjszIrK6vK8QFkXZoez9qY3lbPCsVakbGJct36Ps6adOrUSX2/fvXVV5VfQ7YdMgivuuqqeh1vIiIiqh4DdkREROQSEHQYMmSIKvVEnzCUhn733Xf1Ct716NFDRo4cWeWEvm8I1CAYgl5l5lCmiH0ePny4ytfRc8+UHsg677zzVNDL9IRg4LFjx6oETfRy0+pg4ioCjHFxcaocGOXC2BaCgggK6VAujK8h0ILHh8AayjrrAwEeveQV5/3791cnlEji3whebt26tTIQVFfmQTE9yJSRkSH1ZSmwVNv+rDk2+F7B840ecebHedq0aeo2+rGu7nulNgjAXnTRRapnHEq0sW29FNX02DfU83rttdeqQC36KML333+vgsbXXHONTY+DiIiIrMcedkREROQSkGWEbCdkpi1cuFB+++03+fbbb1VADAEw0+w2o9ZnSg8koicYsvbM+fra9jYMgx4++eQT1Q/trLPOUsEbBKEQuDQNWqKHHHqsIRMRz8tHH32ketD93//9nwp21gUy5z788EMVwEKADoE57Btfx78xDAFrqG/ArrpjaDrwwhJ9Gi2CmpYg+GppYm1d92dKf+4RQEPmnCXou2jKluw6BAPPPfdcFahDMBaDI/BYkLX38MMPWxWwru/jxPfYvffeq7Ls0GPvyy+/VAFbSwFtIiIisg8G7IiIiMip1FRih0EHmNSK0xtvvCEvvviimtaJIB6y4+wFGUwY4rBnz57TrkMJItaBTLeaILACmBpb09r0ktsdO3bUuL0ffvhBBYRef/31KpM6EdAxh8w3ZHfhlJubq4J4GEahB+xsLWPUA3Eo88Xwi0ceeUT9G9vF4AsE7DAFt1+/fjVup6HKJ1u3bq3OcbwsBQ0xyKS2DMa6Hht8r2D6L8qo6/M9WN1zg0mxKH+eP39+lYEe8fHxdd6XLfvXv58wpRYBO5TBItvurbfesuv+iYiIqCqWxBIREZFTQeAHzANR6Jtlrnfv3uockzbtCRlJmNyJLDVMY9WhZxsmbiKzDBlPNUH/MtwGQUWUD1oqpdQDPgjEfPzxx5KYmFhtBhTWZJ4R9b///U8FikwhuGMKU0XR6870OaruOa4OSjhbtGihMvXwWFCaDAiOIZsPwURMSa0ta9DW/VoLgUIERpFNaP698NNPP0lycrKMHTvW5u1ac2xwXC655BLVx85SYE8/zrWp7rnRs+NMj31xcbG89957Nj+euuxfh/JXTCNGiTXWhKw7IiIiajjMsCMiIiKnomdpIXMOQQE/Pz/V0B/lgCiJRaYPMqrQFwxBi5YtW6oAmr09//zzKqMM254+fboKRs2ePVsFhF599dVa749gHbLPEOjo27eveiwIACHwg5JeBL3effddddt33nlH7Qe3u/nmm1WADIFC3G7Lli3qNuPHj1fltSiF7datm/z999/yxx9/SFRUVJX94rphw4ap5xGZURs3blQBtTvuuOO05/iuu+5SgUVrAjAIzn3zzTeqL57eAw3rRaAHGWwYxlGbuuzXGv7+/vLaa6+pDMQBAwaofod4Xv79918VbENJKp7XurDm2Lz88ssqyxPDGTB8BMcAAWaUreIYWQo2Wwo+4/l45ZVXVF869ClEuffgwYPV843HhucNmXD4PrClbNcatR0b/NzhOUX/OgQ/ESAlIiKiBmTHibNEREREdvHcc89VtGjRosLb2xtRiYr4+PiKZcuWVUycOLGiefPmFf7+/up8ypQpFXv37q28H26H23/yySc1bn/FihXqdt9//32Nt9u8eXPF6NGjK0JDQyuCg4Mrhg8fXrF27doqt8G+sK0NGzZUuy9sIyIioiIwMLCiffv2Fdddd13Fxo0bq9xux44dFRdddFFFZGSkul3nzp0rnnzyycrrMzIyKqZNm1YRHR2t1oNt7t69u6J169YVU6dOrbzd888/XzFw4EC1naCgoIouXbpUvPDCCxXFxcWVtyktLa248847K2JiYiq8vLzU+msza9YsdbvbbrutytdHjhypvo7jY8rSsahuv/ptZ86cedp+8fUZM2ZUWGPx4sXqGIWHh1f4+flVtG3btuK+++5Tz52ltVm7v9qODRw9erTi9ttvr4iLi1P7btq0acWIESMqPvjgA6u/7z788MOKdu3aVfj4+Kjb4fawZs2aijPPPFMdT3zfP/TQQxVLliypchvA9wG+H+ryOK35npg+fbr6+ty5cy2un4iIiOzHC/9ryIAgERERERG5PgyemDNnjqSmpqoej0RERNRw2MOOiIiIiIhqhAEnmA6Lfn0M1hERETU89rAjIiIiIiKL0CsSffjQBxEDTe6++26jl0REROQRGLAjIiIiIiKLMBn2qquuUkMmMIBDn8xMREREDYs97IiIiIiIiIiIiJyIoT3sVq1aJRMmTJDmzZurEfU//fRTleuffvpp6dKli4SEhKhx9iNHjpR//vnntO0sXLhQBg0aJEFBQep2kyZNsrg/pPG3bNlS7SszM7PadR06dEhuuOEGadu2rdpm+/btZcaMGVJcXGyHR01EREREREREROSkAbu8vDzp1auXzJo1y+L1nTp1knfffVe2b98uq1evljZt2sioUaMkLS2t8jbz5s2Ta665RqZNmyZbt26VNWvWyJVXXmlxewjC9ezZs9Z17d69W8rLy2X27Nny33//yZtvvin/93//J4899lg9Hi0REREREREREZELlcQi6+3HH3+sNjsOsrOzJSIiQjW+HTFihJSWlqog3jPPPKOCcTV5//335dtvv5WnnnpK3TcjI0MiIyOtXt/MmTPVNg4ePGj1fRD0S0lJkbCwMPX4iIiIiIiIiIjIM1VUVEhOTo6qNPX29naPoRMoR/3ggw9UwA5ZebB582ZJTk5WD7JPnz6SmpqqGuEiuHbGGWdUaZb77LPPqnJaWwJuprKysqRx48Y13qaoqEiddFhbt27d6rQ/IiIiIiIiIiJyP4cPH1Yt21w6YLdgwQK54oorJD8/X5o1ayZLly6V6OhodZ0efEOvuzfeeENl273++usybNgw2bt3rwqwIYA2ZcoUFcRr1apVnQJ2+/fvl//973/y2muv1Xi7l156SWX7mfvoo48kODjY5v0SERE5u8LCQrn++uvV5Y8//lgCAwONXhIRkVPi6yUREeXn58uNN96oKjFdviQWfe6OHDkix48flw8//FCWL1+uMuUwWn7u3LlqzDx6zd18883q9gjQIUr5/PPPyy233CL33XefKkv95ptv1PUrV66U4cOHW10Siyy5c889VwUBEXizJcMOJbxxcXFq7eHh4eIOSkpKVND0/PPPFz8/P6OXQw2Ax9j98Ri7P0ceY/yexsAnwO9WDIqihsefY/fHY+x+zF8v/f39eYzdHH+O3R+PsfsrsfMxRpwISWio4qwtTuT0GXZ449+hQwd1OvPMM6Vjx44yZ84cefTRR1XGHZiWnQYEBEi7du0kMTFR/RsBPgyt+OGHH9S/9fgknqDHH3/cYkacDoE+BPcGDx6synFrg33jZA4H1d1+eN3xMVFVPMbuj8fY/TniGJtun99Tjsfn3P3xGLuP6l4veYzdH4+x++Mxdn9+djrGtmzD6QN2lgY56Fls/fr1UwGyPXv2yNChQyujn4cOHZLWrVtXTpEtKCiovP+GDRtUKvpff/0l7du3rzGzDsE67OOTTz6ptRkgERERERERERGRPRgasMvNzVX94XTx8fGyZcsW1XsuKipKXnjhBbnwwgtVJh3KSmfNmqUCaZMnT1a3R/rgrbfeKjNmzFClpwjSoVcd6LcxD8phO9C1a9fKktj169fLtddeK8uWLZMWLVqofaAEFttD37q0tLTK+zdt2tQBzwwREREREREREXkqQwN2GzduVFlsOvSbg6lTp8r//d//ye7du+Wzzz5TQTYE8AYMGKAy47p37155HwTofH195ZprrlGZdIMGDVJlsHp/CGub/iFLD9l5gPpkBBJxMp/a4SQt/4iIiJwWfleWlpZKWVmZ0UtxW3jPgvc/aGLP59k9ecIx9vHxUY8RvayJiIjIiQJ2yGKrKQA2f/58q+p/kQVX2wTXmvZp/rXrrrtOnYiIiMg2xcXFalgUPgyjhoP3Lcj6P3z4MIMdbspTjnFwcLCqpsEABiIiInLhHnZERETkXBkyF1xwgbqMoALaW+BrzZs3V3+Au3OgweievmgtEhoayj67bsrdjzECkgjwo/UMXjcwWM4dH2d1r5e4TEREVBMG7IiIiKjOAgMDZeHCheoySvcQZEBfWWTNUMPB84xgB55/dw9yeCpPOMZBQUGqWiYhIaHysXrK6yXo7XiIiIgscc/f/kRERGQYdw0uEJH98fWCiIjIMv6GJCIiIiIiIiIiciIM2BEREVGd5eXlSUhIiDpx0AQRkXWvl7hMRERUEwbsiIiIqF4QqPOUYN2nn34qkZGRhuwbE+wnTZpkt+09/fTT0rt3b3HmNRK5G096vSQiovphwI6IiIg8XnWBppUrV6pJt5mZmerfl19+uezdu9eQ4N7bb7+ttuko5o/dHmvUt4kTepdFRERInz595KGHHpIjR47YvEZs56effrL5fkRERETOjgE7IiIiIhumWjZp0sSh+ywrK1MTQxHcMiq7z1rWrnHPnj2SkpIiGzZskIcfflj++OMPOeOMM2T79u0OWScRERGRs2PAjoiIiBpMRQX6Nhlzwr7tzTxrbuvWrTJ8+HAJCwuT8PBw6devn2zcuFFlkk2bNk2ysrIqM8pQggoZGRly7bXXSqNGjSQ4OFjGjh0r+/btO20fv/zyi3Tr1k0CAgIkMTHxtCxABPFmzpwpHTp0ULdp1aqVvPDCC5XXIxDWqVMntY927drJk08+KSUlJVY9zkOHDqnHBVgn1o/9ww8//CA9evRQwcuoqCgZOXJkZT8ua0tiEfRs2rSpWt8VV1wha9askZiYGLntttsqb4Ng3vnnny/R0dEqEHjuuefK5s2bK69v06aNOr/ooovU+vR/HzhwQCZOnCixsbESGhoqAwYMUAFBIiIiIlfia/QCiIiIyH2hVVNoqDH7zs0VCQlp2H1cddVVqqTz/fffFx8fH9myZYv4+fnJ4MGD5a233pKnnnpKZZMBgkd6UAsBOgTkEORDYO2CCy6QnTt3qvsCely98sor8tFHH6mgmKWsvmeeeUa++OILefPNN2Xo0KGqpHT37t2V1yOIiOBf8+bNVebaTTfdpL6G8tPaxMXFybx58+SSSy5R68c6EaDDPqZMmSKvvvqqCpTl5OTIX3/9JRX1jI5i27feeqvce++9cuzYMfV4se2pU6fK//73P7X9119/XT1PeO7wOBDQw+0++eQTGTNmjHr+ITc3V90OwUsEMj///HOZMGGCehwIahIRERG5AgbsiIiIiERkwYIFlUE103LUmiDz7cEHH5QuXbqof3fs2LHyOmSFIfMLmWQ6PVCHjDIE9eCrr75SATL0Yps8ebL6GjLh3nvvPenVq5fF/SKYNXv2bHnnnXdUUAvat2+vAne6J554ovIyss8eeOAB+eabb6wK2CH41bhxY3UZQTE9qxDZa6WlpXLxxRdL69at1deQbWcP+nOI7D7s87zzzqty/QcffKDW8eeff8r48eNVRh7ga6bPMZ4z0+ftueeekx9//FE973fccYdd1kpERETU0BiwIyIiojrD4ACUKuqXzQUHa5luRsC+bYESUGTKmfrnn3/k6quvrvY+9913n9x4440q0w2loQi4IXBWnV27domvr68MGjSo8mvIoOvcubO6Tufv7y89e/ascTtFRUUyYsSIam/z7bffqoAegmzIOkOgDZly9YFAGPaJIN3o0aNl1KhRcumll6qy2frSs/QQ5ISjR4+qoCPKi5F1h+ApMg8RJK0JHivKjxcuXKgyAvG4CwoKar0fkdGvl0RERKYYsCMiIqJ6lTIioAKFhYWnXY/YS0OXpdpLSEiI6gdnKikpqcb7IDB05ZVXquDQ4sWLZcaMGSqLDeWi9X1e9cBVddfX5O+//1bluiibRWAN2X5YF8pK6wOZd0uXLpW1a9fK77//rspVH3/8cRXYbNu2bb22rQcs9V50yBxMT09Xk2eRzYfy1rPOOkuKi4tr3A4yCbHG1157TR1PPFcIKtZ2PyJHvl6CtT0liYjIM/GjHSIiIqJ6wOAE9F5DAAulouippmfJmZfUdu3aVWV8IcClQ1AK/dUwYMJaKL3FH//Lli2zeD0CaghyIZjWv39/dfuEhASbHhfWD+aPAYHEIUOGqGDgv//+q26HktP6QAYcSl7POeecylJXlA3fddddqh9d9+7dVcDu+PHjVe6Hnn/m68P90CcQQVNkAqJcFmW2RERERK6EATsiIiKiOgaZ0BMNGTMIhiFQhEEICMrpmWIoz0RQDYEmlHMicIYJphgAsXr1ajVlFiW3LVq0UF+3VmBgoNx9993yyCOPqKEKKHtdt26dzJkzR12P/aAEFFl1uA6lsbYG1RDwQ3AOvf3S0tLUY0Gg8cUXX1STcLH9+fPnq+v0x2wtlLimpqaqnn5YIwKAeI5MS5LxGFBqjMw77BcZg+aZhXiO8fxiW5i+q98P68IAEDy/yIDERF0iIiIiV8KAHREREdVZXl6eyojCCQEpT4LyUGTHXXvttSrL7rLLLpOxY8eqzDPAUAlMPr388svV84PJqoAMvH79+qnBCSjxRO+2RYsWVU6ItRaGXaCHHibRImCG/SAQBhdeeKHK+kNAsXfv3irj7sknn7Rp+wgi4rEgKBgbG6u2hR54q1atUllveMzoMYcyWzxuW6BnH6bX4nl4+eWXVf+/HTt2VMkyRPARQbi+ffvKNddco7LtzKflYt8of8XQDkzrhTfeeEP11MPzj+mwKAnGNoic6fUSl4mIiGriVaF3+CW7y87OVj1jsrKy6t3k2Vmg1wb+qMAbdVv/sCDXwGPs/niM3Z8jjzH+6NQnqyJ4hUEB6GWGDDBqOMgYw/sMvL9g83r35CnHGL0v4+PjPeJ1w/T1EhmrKCfn72P3xvdc7o/H2P2V2PkY2xInct/f/kRERERERERERC6IATsiIiIiIiIiIiIn4mv0AoiIiIiIiIg8DYZ3t2yJnqjW3yezMFOKy4qlvKJcfLx8pHFQY/HxtmEDROQyGLAjIiIiIiIicpCkJJG77xaZP1/k9ttF3n3Xwo1KSkTS0kRiYkT8/CS7KFsSMhPkcPZhFbCTClH9LWOCY6R1ZGuJDYll4I7IzbAkloiIiIiIiMgBPv1UpGtXLVgHOLc4BhIBuyNH1Dmy6tYnrZcDGQckzD9M4sLjJC4iTgXpMgoyZEPyBvkv7T8pLS919MMhogbEDDsiIiKqM3y6379//8rLRERkGV8vaft2kRtuwBRokTPPFPn3Xy0mt2ePSJcu1d8PGXW5JbkqUGfK19tXYkNjpai0SPaf2C/e4i1dY7oy047ITTBgR0RERHUWFBQkGzZsUJcLCwuNXg4RkUu8XkIJMqjIYyCL7p57tGDdpEki8+aJnH++yPLlIsuWmQTs9FLYkBCrtx3gG6Cy7fad2CfeXlrQzsvLq8EeCxE5Bj/aISIiIiIiImpAP/2kBecCAkTefBNZliIjRmjX4euWSmFtEegbKNHB0apsNjU31b6LJyJDMGBHRERERERE1ECQgH7//drlBx8UadNGu3zeedr5ihVa5l19BfsFqzLZvel7pbCUWe9Ero4BOyIiIqqz/Px8adOmjToVFBSIJxs2bJjcg3qnk/CcvPXWWzXeByVLPyHtop7stR17s+Y5cJSnn35aevfuXfnv6667TiahLq0e7LEN8szXS1wmz1BY6COXXuoj8fEiLVqIPPLIqevQ0jAsTCQjQ2TLFvvsD1l2JwpOyMETB+2zQSIyDAN2REREVGcVFRWSkJCgTrjsiiZMmCBjxoyxeN1ff/2lgmHbtm2zebvoVXXzzTdLQwaddEeOHJGxY8fadV/W7rs+zwG2iecXJ19fXxXIuPfeeyU3N1ca2ttvvy2fYlyjFQ4dOqTWuMXsL2pbtkHkDq+XZJvMTJFnnjlLfv/dW4KDRT7/vGprOl9fkXPOsVAWWw/oYYegXXxmvKTlpdlno0RkCAbsiIiIyKPdcMMNsnTpUklKSjrtuk8++URNdezZs6fN242JiZFg/IXmAE2bNpUANEZyMtY8B927d1cBRwTFXnnlFfnggw/kfr12zExxcbHd1hYRESGRkZGGb4OI3NfkyT6ya1eUREZWyNKlp0pgTelfs1fATi+NRVD4YMZBKa+wQ60tERmCATsiIiJqOMgiQZDFiJOVGSzjx49XgSXzTClkeX3//fcqoJeeni5TpkyRFi1aqABUjx495Ouvv7apHHTfvn1yzjnnSGBgoHTr1k0FCc09/PDD0qlTJ7WPdu3ayZNPPlk5SRLre+aZZ2Tr1q3i4+MjjRo1qlyzeUns9u3b5bzzzlNTKaOiolSWm2nWml7K+dprr0mzZs3UbW6//fZqp1aa7lvPiMPX8AchsuRatWqlAobNmzeXu+66q9rnwBJk1iHg2LJlS7n88svlqquukl9++aVKVt9HH30kbdu2Vc8dZGZmyo033qiOW3h4uHqsWJupl19+WWJjYyUsLEwdQ/MpxublrOXl5fLqq69Khw4d1GPBY3rhhRfUddg39OnTRz12lD9b2kZRUZF6/E2aNFFrHTp0aJWpoCtXrlT3X7ZsmQoE4zgPHjxY9uzZU3kbPI7hw4erYCDWMGDAANm4cWONzyEROZ+dO0X+/NNbfH3LZenSUhk82PLt9METq1aJ7N1rv/0jyw7DJ5hlR+S6fI1eABEREbkxBIBefNGYfT/2mIi/f603Q8Do2muvVQGoxx9/XAVUAMG6srIyFahDsKtfv34qoIYA0cKFC+Waa66R9u3by8CBA2vdB4JBF198sQog/fPPP5KVlVWl350OwSWsA4EvBN1uuukm9bWHHnpIBbN27Nghv/32m/z++++Sk5Ojglzm8vLyZPTo0XLWWWepYNGxY8dUcOuOO+6oEpRcsWKFCtbhfP/+/Wr7CI5hn+ZM9/3HH3+oryGgNG/ePHnzzTflm2++UZlyqamppwXObIUgo2kmHdaG/cyfP18FKmHy5MnqdosXL1brmD17towYMUL27t0rjRs3lu+++04F+2bNmqWCZl988YW88847KghanUcffVQ+/PBD9XhwH2T97d69W123fv16dZzx2PE4/av5vsJxwlo/++wzad26tQoA4ljgMWBdOnyfvf766yrgeOutt8r1118va9asUdchYInAINaOvpC4r5+fX72eUyJyvO++08579z4mvXpFVXu7Hj1EmjSpkGPHvKRzZ5FzhgbIjec3lkuuE6lPjrafj5/4ePnIocxDEhMSo0plici1MGBHREREHg8Bk5kzZ8qff/5ZmT2FcthLLrlEBYRweuCBBypvf+edd8qSJUtUYMiagB0CPQj+4D4IxsGLL754Wt+5J554okp2GvaJYBgCQQhQhYaGVmakITsLXzM3d+5clU32+eefS8jJZknvvvuu6tWHklMEDQEZevg6gmBdunSRcePGqcwvSwE7833rEhMT1b9HjhypgkrICLPm+ajOpk2b1PqRMadD8A6PBcEtWL16tQqgIRCplwEjUxAZhj/88IPKJkRWH7LqcILnn39eHQPzLDsdgp/oR4fnY+rUqeprCMYicAf6vpGJaPr4zQOl77//vgqK6scVAUBkUs6ZM0cexGjIk5C5d+6556rLjzzyiHrusTZk5eE5xW1xTLKzs1Xwztubf2gTuRIkeOsBuyFDkvHqUe1t8eP949dF8tLThbJoTYSsWu0jq1a3lTteK5erRpfLPU94SWSH+mXZHcs7Jk1DLb92EZHzYsCOiIiIGg4yg5DpZtS+rYTgCEoTP/74YxWwQ1YTBk48++yz6npk2iHAhgBdcnKyCiKh/NHaHnW7du2SuLi4ymAdIAPO3LfffqsywQ4cOKCy+kpLS1VGny2wr169elUG62DIkCEqyw+ll3rADpliesYaINsOWX22QKYbgmPIXMPgjgsuuEAFBhHYsxb2iWAgnmM8rwheIXCmQ6aaHjADZPDhuUHwzBSy0fC86c8BMtdM4flGNqEluD2OJ7L06gr7RkkxnmsdgpgIYGL7pkx7IuJ5BwQgEfC87777VEYksgKxrauvvlo6duxY53URkePt2IHXFSR5V8jAgan4qa/x9oPPLJdf3zwgyRHd5NMvfWTORxUSnxwg7//QRCZeXSh9OtQ9y87X21fLsguOER/vU6/5ROT8+HEdERER1RnKR9GPDSe9lNTsBlpZqhEnS+upAbKxUM6IbCtk1yHDSs+CQvYdMrBQEougD6aFotTRnkMQ/v77b1UOiaDXggUL5N9//1Wlk/bchynzMkscPwT1bIEgJIKA7733nsrCmz59uurTV10vPEs6d+6snk8EtRB0Q/86PagIpoFHQLAOQS7cx/SEdZhmsdnCUqZiQzJ97vWfG/25Rynvf//9p74PEDQ+44wz5Mcff3To+sig10tyaTk52lRY0LPrRo2qkJCQUqu30aJ5hTz+UKns/3GH/DEvS2679JiMPK9+QyOigqJUhl1GYUa9tkNEjseAHREREdUZMswQXMDJ0UEPe7vssstU6SFKMlGCiTJZ/Y9q9BebOHGiynZC9hoyytAvzVpdu3aVw4cPq75ounXr1lW5zdq1a1U2GYJ0GEiArKqEhIQqt0HvNGSi1bYvZKGhRFOH9eOxIThWV9XtG8cdWXXIDMRQBQQebcnUw3Yx6AElwNX1hjPVt29f1SsPWXy4n+kpOjq68jlAr0BT5s+3KTzXeBwoCa5ujVDTc48AL26n96IDBC7RRxABGltg8Ah6HKJv30UXXaQCyORer5eOmiBNjoGX6q5dkTEr8t57pwJ2kyfXLdiGMtkR55TIe48cFpNE6Dpn2WFA0NHco/XbEBE5HAN2RERERCKqLBPDFTB8AIE1TAA1DeigFxmCasgEu+WWW+ToUev/+EGPNwRh0B8NwTRkTiEwZwr7QP8y9KxDeSUCYOaZVQhqxcfHq4wyTK5FGac5ZOmhFxr2hUERyAhEzz0MyTDNXLOV6b6PHz+u9o1+bejPhv0cPHhQvvzySxX4QuCxoeC5RHkrprNi+MahQ4fUccHzqU9Tvfvuu1V5MwJdCKzOmDFDBUmqg+cL2ZPoFYhgLZ5/BPjw2ABTX/G4MHQDxx1DQ8whE/C2225TWX643c6dO1U/wPz8/MpeerVBhiGGgyDwiWAt1oDHhAAkERlrwQKRAQMwhKbq1/FyMH68SHKyCNpk3n67Nu0VLTbHj7duWnlDCw8IlyM5R6Sw1HIfTyJyTgzYEREREZ2EwEpGRoYqdzXtN4dhEMjswtfR4w6DBxAwshay2xB8Q0AGPc3QowyDB0xdeOGFcu+996qADaa1Igj15JNPVrkNhmCgVxx6rSGj7Ouvvz5tX8jcwXCLEydOyIABA+TSSy9VtzftC1cX+r6HDx+uesph35GRkWqwAnqtoS8bBjv8+uuvp/WXsydkPS5atEiV3k6bNk0FQq+44goV4NIDkgi84rlDAA7TfXEdgmk1we3vv/9+eeqpp1SADNtAXzlANh8CqJhGi+8LZFta8vLLL6vnCcFRfL+gFyKOBQZ8WAM9BRGIxdRi9FVEliee82eeecbm54mI7Cc7G78fRPCZwFVXIbiufb20FK83Ws86ZNc995wWqIMLLsDk7/rvG9lxb/z9hqTlpdV5G2H+YZJbkivp+en1XxAROYxXBV4BqEFgshemyuFTWFsbRjsrlHbgTTL6qpj3viH3wGPs/niM3Z8jjzGyhxAU0qd3olSxbdu2KmOJGg76neF9Bt5fcIKoe/KUY4zpuMjc9ITXDdPXS5RK4/WZv49dw0MPoZfpqX8/8ogI4ugYKv3NN/igRGTVKpF+/TBIR+Srr0TuuEMkNtbK38f5+dqUCj2bFpeRqZyQIHMrtslVC6+XIN8guefMe+TiLhfXqQcipsXGhMTIgOYD2EPRjvi+2v3Z+xjbEidy39/+RERE1ODwuR9K/3DiZ4BERNXj66Vr2rdP5K23tMvTp2vnCN5hqDSCdRiKPXeuFqyDHj2QbSvSsqUVG8eAnpQU7bwafWN7S//m/aWgtEBeWv2S3L7odskpyrH5cUQGRsrx/OOSXZRt832JyBgM2BERERERERFZ8MADWjxtzBgRdBaYPBkDaJBVjqE7Ir/+KlJNlXztsGEMI6ohYNclqrP8csUvMq33NAnwCZD1KevlvY3v2byrQN9A1cMOQTsicg0M2BERERERERGZwfCIX37RsujeeAM9NEX+9z+RFi1E0Jpy6VItkNfQfLx95MLOF8qbo99U/56/a74cyjxUp152SdlJUlpe2gCrJCJ7Y8COiIiIiIiIyAxayUHv3qfay2G2Db6OqbBDhjh2PQNbDJSzW50tZRVl8r/1/6vTtNjMwkw5UXCiQdZHRPbFgB0RERERERGRmYMHtfN27ap+HdNfUQ5rhLsG3iU+Xj7yZ8KfsunIJpvu6+vtK+IlcjT3aIOtj4jshwE7IiIiIiIiIjMHDmjn7duL02jbqK1c1OUidXnWhlk23z/CP0JNjC0oKWiA1RGRPTFgR0RERHXm5eUlrVu3VidcJiIiy/h66boBO/MMu1onvlox/bU+bux7o8qy23Z0m+w/sd+m+4b6h0puca6kF6Q3yNqIyH4YsCMiIqI6Cw4OlkOHDqlTkFH1QURELvZ6icvkOiWxVmXYmU581S+XWhjuYIdgXnRwtJzT+hx1+de9v9p0XwSL/X38JSUnRSoqKuq8BiJqeAzYEZHHKSwUefNNkR07jF4JkQcpLhbJz3fcCfsjIiKqo7Iykfh4GzLsLNGDcqbBOdPAXj1c2OlCdb5o3yIpKbNtW5GBkZKeny45xTn1WgMRNSzfBt4+EZHTuftukQ8+EOnWTQvasSqFqIEheLZ+vUhuruP2GRoqMnCgiL+/4/bpop5++ml5//335dixY/Ljjz/KTz/9JJmZmeq8OsOGDZPevXvLW2+95dC1eqLzzjuPzzWRATAFFjE1Pz+Rli3ruBE9KIdMO1xOSxMJCbHL+s6KO0uigqJUaevqxNUyvO1wq+8b6BsoR/OOSkZBhpocS0TOiRl2RORR5s/XgnWwc6fIsmVGr4jItRUUFMiAAQPUqRDpq5bgDxUE6xA8w2i9hj5hP9ifpVKkauTk5Mg999yjekuhtHfw4MGyYcOGKrdB6dBTTz0lzZo1U7cZOXKk7Nu3r/L6oqIiueaaayQ8PFw6deokf/zxR5X7z5w5U+68806r1pOdnS2PP/64dOnSRQIDA6Vp06Zqf/Pnz7drCdOuXbvkmWeekdmzZ8uRI0dk7Nix8vbbb8unn34q7gClXzUFHs3hcUdGRjbomshzmb5e4jK5Rv+6tm1FfHyquZEt5a12yqwznfg6vtN4dfmXvb/YfP9g32CWxRI5OWbYEZHHSEoSufFG7XJsrMjRoyLvvCMycqTRKyNyXeXl5bJx48bKyzUKCBAJDHTMwmwsib3xxhtlx44d8sUXX0jz5s3lyy+/VAGynTt3SosWLdRtXn31VXnnnXfks88+k7Zt28qTTz4po0ePVrdBUO2DDz6QTZs2yd9//y2LFy+WK6+8Uo4ePaqCRvHx8fLhhx9WPlc1QXbb0KFDJSsrS55//nn1x72vr6/8+eef8tBDD6mMKwQF7eHAyb9IJ06cWNkEPwDHieqlrKxMPZ/e3vxsnOr4ekmuMXBCD8IZFOif0GmCfLb1M1lzeI0czz+uettZKywgTDIKMyS7KFsiAiMadJ1EVDd8F0FEHgEfZF9xhUhGhkj//qcy6xYsOPWGjIg8EzJd5s2bpwJy55xzjnTo0EGVieIcpaKADASUJD7xxBMquNWzZ0/5/PPPJSUlpTKDC9lqF154oXTv3l1uv/12SUtLk+PHj6vrbrvtNnnllVesCrQ99thjqin9P//8I1OnTpVu3bqpjL2bbrpJtmzZIqEo9z0Z2MP1jRo1Ug3skR1nmvGnZ4stWbJEunbtqu43ZswYlUkHeIwTJkxQlxFY0gN21113nUyaNKlyO3l5eXLttdeq+yO78PXXXz9tzcgufOCBB1RwMyQkRAYNGiQrV660ei26jz/+WD1/CBpiX3fccUfldXi8CKzGxMSo5xGBy61bt1p5lEU9p3iMyFIcPny4es569eqlAqyA9U6bNk0FSnE7nPAc2fL4fvnlF3W8sP6PPvpIBXKxblN33323Wjukp6fLlClT1Haxnh49esjXX39t9WMiIicZOGGQNpFtpGdsTymvKJclB5bYdF+UxRaWFsqJghMNtj4iqh8G7IjII5oGX3WVyJo1IhERInPninTvLjJmDP4IF5k1y+gVEpGRSktLVUYUgiumUPa6evVqdRkZcqmpqSrrThcREaECN3rAB8Ef3B4BQASmEHCKjo6Wr776Sm37oosuqnUtyLr55ptv5KqrrlKZfuYQ6EK2HUyfPl1l9CFIhDUgqHjBBRdIiUm5VX5+vrz22msqc3DVqlWSmJioAk+A808++URdRuDMPHime/DBB1V2388//yy///67ClRt3ry5ym0QWMMasPZt27bJ5MmTVUDONIBY01oAwVEEOm+++WbZvn27elwImuqwTfTZQ/YiHnffvn1lxIgRcuKEbX9sotQY+0XwE4FQBMzwPYAyaARlEQzUnw99fdY+PgRlEaj777//1DFEEA/BYB2+z7799lt1HaCMvF+/frJw4UKV4YnHjrLq9ej5SETOn2HnBEa21X4vrUlcY/N9Q/xC5EjuERXwIyLnw4AdEbk1BOTuukvkxx+1tlY//yzSsaN2Hb4Oc+Y4thc+ETmXsLAwOeuss+S5555TGXMIqqAkFgEaPYiFYB3Eop7eBP6tX3f99deroB0yrF544QX57rvvJCMjQ/W9+9///qey8xCAQhltMrqZW4CMPNwHvetqgkARAlcowz377LPVfhEYxHZNe7YhePd///d/0r9/fxXgQuBp2ckUYwT/9H5t6JGHk7nc3FyZM2eOCrQhOIYMMJQEI8ClQ+ANgb/vv/9eraV9+/Yq0IWyXj0gWNtaAOW/999/v8pAQyANpcDoKwgIhCKIhX3g/h07dlRrwvp/+OEHsQXWNm7cOLUP9O9LSEiQ/fv3i7+/vwrCIrNOfz7wHNny+N577z0V+OvcubPKxLviiitkLj4lOgmPFxl3l1xyifo3MuuwLQyVaNeunepxiEAgvneIyFiukGEHQ+KGqPPNqZslrzjPpvuG+YepwRMoiyUi58MedkTk1hYuFHnvPW0S7FdfiZx77qnrRo8WQfLG/v0iv/0mcumlRq6UiIyErC8E3BBA8fHxUQElZF4hk8tafn5+MsssZRcllnfddZf8+++/KpCGEk6U3uJrpplXOmubf6P8Fpl2yPDTRUVFqUARrtOhzBIBJh2y/pClZkuPu+Li4ir7ady4sdqPDtlwCHIiAGYKZaRYkzVrwTmCpQgKWoLnDcFD0+0Bshn1PnzWQjmz6Rr0/VcXJLX28SHgZ7ptQCbdmWeeqR4bMiYRVEWwUA+UYrsvvviiCtAh2IrnGtvFc0VExnKVDLvWka0lLjxODmcflvXJ622aFhvgGyDFZcWSnp8ukYEcuEPkbBiwIyK39tdf2vm0aacH5NALfNgwLWC3ZQsDdkSeDIEklH2iXxsmtCKQc/nll6usJ9CzzzBEQg/y6P9GdpQlK1asUKWRKJFEWSnKVZF1ddlll8m7775r8T7oz4Zgzu7du+3yuBBENIXsMXtPBEQgDUFOBDdxbkrvt1fbWlB+XNs+8Lyb9o3T2TrV1XQdet++mgYAWPv48Bj07emQJYjvLZTSoo/hjz/+WGUCLyYHYyovSnGRvYjvD2QVInBHRMZBz2OcXCFgB0NbDZWvd3wtqw+vtilgB6H+oZKUnaQCf5g8S0TOgyWxROTW/vtPO8egCUt69dLObehbTkRm0KcNJ3eAgAkCQyhLRR86DJgATIVF0M60hBOBPQyGQDmtOfQmQz+22bNnqyAPMqn03nI4x78twfAHlFEiEwtZWZaCRyhHxeAGnGP/Ogww2LNnjyrJtRcEmxDgMt0Pnpu9e/dW/rtPnz7q8SBLDSW/pidLZbbVlSW3adOmyvNrChmPKD1GVqH5Puz5vYcsOfNjU9/Hhyw7HM9ff/1VHV9k2OnWrFmjvseuvvpqVdaMALHpc0vux51eLz2hHBY/4iEh4vT0slhMi7X1Q5nwgHDJLMxUWXZE5FwYsCMit7Zjh3aOIRM1BeyQYUdEdQtwYRoqTrWW8RUVIZLV8Cfsx0YIzv32229quMTSpUvVFFGUSKKkFZA5hcwn9FnDMASUSWJyKsocTSeq6tAPDxl1CPbAkCFD1HRSDCxAdh3+XR30v4uLi1NlqJhEu3PnTtWzDhNUsT0E7dDDDdu/5ZZbVH83lIwi6IOSXj3IaA/IILvhhhtUhuDy5cvVYARMkUXgSYdSUQSl8HzgMeI5RL+5l156SQ1TsBYmsmIC7TvvvKMeLwZboPcfYNgHAqN4rjH4AhNf165dqwZIbNy40W6PF0FDPL8IHKKfIAZJ1Pfx4b54LDiul156qZogq8NxxPcbHgtKmXE8kbVJ7v96icvkwuWw+AAGH6qYDPlpSN5e3upUVGr591vfZn0lyDdIjucflz3pe2zaNrLq8DsOwyeIyLkw55WI3BYGSSQk1Byw09sNJSWJYNBg48aOWx+Rx8BUU5QO4ofSUaV+2N/JaarWyMrKkkcffVSSkpJUjzYMBUCAxbR88qGHHlIls5jkicEBGDqAIJ/5dFkEtdCTDFNIdQjUoJwTQwvQ/810EIE57H/dunXy8ssvqwAhhiI0atRIlUyihBKDEZBBgX55Tz75pIwfP16VUJ5zzjmyaNGi00pP6wv7RBBrwoQJKhMOgyHwfJnC8AV9aAR6sSGDCL3bsDZrTZ06VWUmvvnmm2oQA7aB5w3wxyQeGwJ0CKIi4IHsNjxm80Eg9YGBEbfeeqsqh0bG4owZM1QgsT6PD5l4AwcOVEE+lL6awiCSgwcPqkEkCHjjewtBSfPnl4icbOAEAnUYStS6tUPW0ziosepTdyjzkDo3L7/39/GXgS0Gyp8Jf8rqxNXSJbrmwUXmIgIi5GjeUcktzlUlskTkHLwq7N3IhKqUyuBNNd50hYeHiztAGQ/eMONTfXv/QUDOwZ2O8fr1IuiTjnKGk4MeLcKnp/HxIsuXiwy3re2HS3KnY0zOdYwRbEH2EcpHzYNYKlBnMlm0wSFYh9HQbgo91/A+A+8vTLPdyH14yjGu8XXDzfH3sfO66SaRjz4SmTED2b8WbpCfj+k/WsAOnw537ap9HV8zuVzSooUs+ucfuWD4cPHD76Xq7lPb14KDVTDtn6R/pKy8TKKCqw7ggfm75suLq1+UHk16yCcTT02wtlZCVoL0a9ZP9bIj6/Hn2P2V2PkY2xInYoYdEXlsOaxpWSwCduhj5wkBOyJ7wpTOsWPHqsuYglotBM/cOIBGRGTL6+XixYtVT0Zy0Qw7AyDzrXN0Z9mUskmVxmLCq6nBcYPV+X9p/0lOUY6EBYTZtP0QvxA5nHVYWoa3FB/vqgN2iMgY7vtxHRF5PH3gxBln1Hw79rEjql8WEKar4lTTpE0iIk/H10s36mHnCMjkwVRyk4ye5mHNJS4iTtILTh8Q0TS0qbSKaCXlFeWy6cgmm3eHstgThScsbpuIjMGAHRG5fcCutgy73r21c06KJSIiIvJs6OBw+LATZNghUNe8eZWAHQZPNAlpIqXllltMDGoxSJ2vT15v++58/MRLvCQ5O9nmSbNE1DAYsCMit2VLSSzs3Om4fvhERERE5HzQNg4JkBh8bseZNnaDTLhA30ApLC087boBzQeo8w0pG+o83CIlJ0Wyijj4hsgZMGBHRG4pM1MkOdm6gF2bNiLo94lg3e7dDlkeERERETl5OazZMFan6WUXERihhlCYw9AIZMnFZ8ZLWl6azdtGILCkvERSslPstFoiqg8G7IjILSFbDlq2FImIqPm2eDOmZ9mxLJaIiIjIcznjwAlTXl5eEhsSKwUlBaddh0Be12ht0uz6FNvLYiEyIFKScpIkrziv3mslovphwI6IPLocVseAHREREREZPnDCwrAJc5GBkeLt7W2xl92AFifLYpM31DmDD9l7qbmpdbo/EdkPA3ZE5NETYs0DdqtWieSeXmFARDUIDg5WJyIiqhlfL10nYGdYhp2FYRPmwgPCKwNrNfWxq8vwCGTwhfuHS0JWghSVFtl8fyKyHwbsiMijJ8TqBg8W8fYW2bBBpG1bkZkzRfJYCUBUq5CQEMnLy1Mn/hFKRGTd6yUuk3OXxBqWYWflRFdMi7UUsOvdtLf4+/jL0byjKuhWFyitzSrMYpYdkcEYsCMit+5h162bdbfH7b79Vvs09fhxkYce0gJ3r70mUnB6ixAiIpf39NNPS+/evcUZHDp0SGV1bNmyRf175cqV6t+ZmCBUR/bYBhF5FiSkOXsPO11UUJTKoDPPosPgiJ5NetZrWqy3l7cE+wXLocxDUlJWYpf1EpHtGLAjIqfw228iCxbYZ1soaT1yRLvcqZP197v0Um1K7CefaJ+qpqWJPPigyLXX2mddROS8rrvuOhXcMT/t37/fqvsPGzZM7rnnHnGWgJc1HnjgAVm2bFmt29RPUVFRMmrUKPn333+loQ0ePFiOHDkiEbVNDarh+bd1G0REx45pFRYYSNamjdmVJSUiKSnauRMICwiTAN8AKSo7vWy1f/P+6nzzkc113n6jwEaSUZChMvWIyBgM2BGR4T79VGTsWJEJE0R++sl+vUeiokQaNbLtvr6++MNdC9x9+KH2tXnzTn3aSkRVFRYWyrhx49SpqMi1e92MGTNGBXhMT22RautAxcXFDttXaGioCsLV5o8//lDPxZIlSyQ3N1fGjh1bbdZaiZ3+kPX395emTZuqQKGR2yBqqNdLXCbno7+HjIvDa4jZlXh9wyfCThKwQwYcTpamxfZt1rcyYFeXPnbg4+2jAoIJmQlSVl5W7/USke0YsCMiQ/3+u8hNN53697RpyOqo3zb1hJgOHeq+DfT5vfFGkVGjtPKIDz6o35qI3FVZWZksWrRInXDZHP5QyCvOM+Rk6x8pAQEBKsBjevLx8VHZd5MmTapyW2RzIasLcP2ff/4pb7/9dmU2GrLTPv30U4mMjKxyv59++qlKAEkvS/3oo49UcDAwMFB9HQGxG2+8UWJiYiQ8PFzOO+882VrDGGs9sNinTx+1fX1tKAsdOHCg6peFtQwZMkQSEhJsKolFUA/PRf/+/eW1116To0ePyj///FOZgfftt9/Kueeeq9b+1Vdfqfvg8XTt2lV9rUuXLvLee+9V2eb69evVWnE9tmuetWepnHXNmjXqcaFXYqNGjWT06NGSkZFR7fNvaRvz5s2T7t27q2Pdpk0bef3116vsF1978cUX5frrr5ewsDBp1aqVfGDyCwAB1TvuuEOaNWum1t66dWt56aWXan0Oiax5vSTjGVYOa8VkWEtlq1HBUZJfkn/add1juqs+dukF6ZKYlVjnZTUOaizH84/Lsbxjdd4GEdWdbz3uS0RUL6jcuuQSkdJSkSlTtDdJ//wjcsUVIn/9ZdN7FosBu44d67/G227Tgopz5og88wz+oK//Nok8Cf6QCH0p1JB95z6aKyH+Dd/YHYGivXv3yhlnnCHPPvus+hoCbdZC2S0CSfPnz1cBQpg8ebIEBQXJ4sWLVUnn7NmzZcSIEWo/jRs3Pm0bCIAhMIdsOASkkF1WWlqqAo033XSTfP311yrYhNvVJ+MMazLPBHzkkUdU4EsPwCFo99RTT8m7776rvoZgHNaAoOHUqVNVlt748ePl/PPPly+//FLi4+Pl7rvvrnG/KPXF40cgDc+3r6+vrFixQgU9qnv+EbQztWnTJrnssstUoPLyyy+XtWvXyvTp01VAEkE/HR7Lc889J4899pj88MMPctttt6mAZOfOneWdd96RX375Rb777jsVzDt8+LA6EZF7Zdg5fOCEPhnWRhEBEVJWcXrwF5lxZ8ScIZtTN8u/qf9K68jWdVqWr7evOqGXHYZcIOuOiByHATsiMqxHyIUXav3mhg/X+sahygDJHgjaYdjDo4/Wbdv79tU/w043frxIixYiyclaaeyVV9Z/m0TknBYsWKDKRHUo/fz+++9rvR8CagiQIfMLmWi2QvDr888/rwzyrV69WgXWjh07pjLBAJltyM5DAOnmm28+bRv6ffVsODhx4oRkZWWp4Fj7k+kiyHqrK2SqIZCF5wjBwYKTE3mQbXjxxRdX3m7GjBkq6KV/Ddl/O3fuVEFHBOzmzp0r5eXlMmfOHBXgQ4AxKSlJBcaq8+qrr6pMPNNMPdxPZ83z/8Ybb6ig35NPPqn+3alTJ7WumTNnVgnYXXDBBSqQBw8//LC8+eabKjiIgF1iYqJ07NhRhg4dqgKfyLAjIvcL2NUpw848S87GjLm6CPUPVQG10vJSdW6qT7M+KmCHsthJXapmidsiOjhaTYtNy0+TpqG2/44jorpjwI6IGtSvv2p94caM0Rr4AhIzMOABSQnIgkMgDH+Tornvyy9rWW2//FL3gJ09SmJ1WDtKdp9+WuT99xmwI7IV+usg082ofdti+PDh8j5+0E9CRpgjIOhjmpGH0ldkoZn3l0OA7ID+16QVkImHQBRKR5HNNnLkSJVhhnJOW2B4g7e3t+Tl5Um7du1UCWxsbGxlBhsCaTrcBmu84YYbVFadDtl++vCHXbt2Sc+ePSvLf+Gss86qNcMOWYf1gf1OnDixytdQIvzWW2+pTD09uxFr0yEohyAggqeA5xPPJYJ36HmIYCgGcRCRe5XE1inDzjxLDpezs6UhIYs8yDdI9bHDEArzPnZz/p2jgnb1YZ5lh1JcInIMBuyIqMEgUw5ZdHD++SJo83P8OHobaSWv4eFaYM50MMTo0dr5pk344xTlV8YG7AC97J57Dlkv2nr1x0REtUPAwxFlqfaAAF0HCy8cCFaZ98OzZriCtfczDwwiWIegGnqwmTPviVebTz75RO666y757bffVKDtiSeekKVLl8qZZ55p9TZwv27duqkAoqX9m64fa4cPP/xQBg0aVOV2ekCsPqW4juBnlhGD72FkBELfvn1VCS9KlVF+jAAoAqHIfCQiD8+wMwD61EUERkhaXtppAbueTXqKj5ePyo47knNEmoXZ9mGNqaigKNXHDvuJDY21w8qJyBoMjxNRg3nrrVOXly5FFoaWaYe/a5BtN3euSJcuVe+DLDskf+Bv2g0bbN9nfr5WvmqvHnaAklgE7QAJHosX22e7ROQakP2GKanmGV+mUJJp3kQe98vJyVFZZ9XdzxIEhVJTU1WfNgQQTU/R0dEW74P9g6VG9ugj9+ijj6qebejzhpJUW8TFxamSWmuChci8a968uRw8ePC0teuDMVCWu23btipTMtetW1fjdpH1tmzZsmqvt/T8m8N+MbjCFP6N0lhbgokYAoIeeAhKIpiJ/oMoPyYi14b3kKmpNgbs6jAswt4weKK4/PQJ40F+QdI1RmuDUN8sOz8fP/EWb0nISpDyCu0DDCJqeAzYEVGDSEoS0Vs/IUA3bpwWpEPyytVXiyxcqH3NHG4zdKh22ezvKps+GUXWnoW+7HX27rtaGS/KeS+6SOSPP+y3bSJybpjQunHjRtVnbt++fapH244dO06bLqpPTj1+/LjKyEKGGfqqYXgBykQRKMPk2NogYwslohgY8fvvv6ttItj2+OOPq3VY0qRJE5WFhkw6THFF7zpkgiFQ9/fff6vJsNgW1l+fPnbWeOaZZ9TkVAxowDCI7du3q0w/9JCDK6+8UmWtoWQWPeQwMRM9+mqCx7FhwwbVWw7Bvt27d6vyZTzX1T3/5u6//34V9EMfPqzrs88+U4MxHnjgAasfGx4DBnhg/9gGehyiZNbWzEcict5yWPw4m1Z/WFUGW13ADr1VTM8bIOCHPnZSoU1lN9e3aV91jj529ggMHs09qqbGEpFjMGBHRA0CfcGR7HDOOdok2AULtGAXBkJ88QWauVd/3yFDtHOUoBpdDqvD+ywkpSBYV1Qkcu+99t0+katCOST+SMAJwSl3hB5wGFTw0EMPyYABA1TW3LXXXlvlNgj6IEsLpaPIrMNwAvSQwxRUBKR69OihAj2YUFobBLNwn3POOUemTZumMsCuuOIKFXRDBpslyMZDgAyDHZDhhl5tOB4ILF1yySVqGxhWcfvtt8stt9wiDenGG2+Ujz76SAXp8LgxYRWBSj3DDkMrfv31VxXIQ/YfApGvvPJKjdvE+hFwRH8/DLxAQPPnn39Wj7u6599S5iKmu37zzTcq0xCTbDFV1nTgRG3CwsIqB2DgewEBQhwrlD8T2fJ66agemWS9+Hjt/ORLlX3ogbjqAnK1BfysEOIXIoF+gVJYeipr2bSPHfx75F+xR/ktJGQyy47IUbwqLIXiHWTVqlVqMtemTZtUqcmPP/6oPk3W4U0t3lQdPnxYlTr069dPXnjhhdN6oixcuFC94cInrmhgjDeGmKRmLj09XXr16iXJycmSkZFR46ehKG2488471RtKvAnDm9233367yvS42mRnZ6sGy/iUG+UT7gC9d/DGFBPUzHu8kHuwxzFGSUFcHH6ORObP14JctkACyYAB2iec6enoA2X9fWfOFHnoIZEpU7QAm72lpSGTRcsEzMjAdEhxOfw5dn9GHWOUOCKrC4EZ04ECZH/IIMP7DLy/YLDIPXnKMfbk1w3+PnYu77wjcvfdIhhwjYFoFt/g7tqF+nrt3/rlGj6sqnKM9TeSCNbiE+Za7mst/Dm/OnG1Ctg1DqpaXpJTlCPnfX6eVEiFLLlqicqSq4+i0iJJL0iXM1ueKTEhp4YleTL+HLu/EjsfY1viRIb+9kdPFwTQZs2aVe2nqShVwCewq1evVuUOmMSVhhe6k9A35JprrlGfQONTV/QiQamFJZhYZjr5qyZXXXWV/Pfff6ox84IFC1RwEZ9ME1HtvvpKC9ahH11dBjT07q29l8nM1N4L2QIZfPbsX2cOgxzxySs+6sBgDCIiIiJyfScHX9s3w85SNh2CdHbse4esbAyFwKRYcxhE0TZSe0A703bWe18BvgHqPDEr0WIJLhHZl6EBu7Fjx8rzzz8vF1WTfoPAG/q4tGvXTrp37676hiAaiUw6KC0tlbvvvltl6d16660qwIdSCEzsMoc+J5mZmVb1Kdm1a5fqAYNyDmTzDR06VP73v/+pbL+UlBQ7PHIi9/Z//6ed33EHpgLafn9UOOmJtLb2sWuoklhTyP6D9esbbh9ErpQdM3nyZHUqQr04ERHV+nppOnSFnCtghw+cG5QdymDNhQaEVlum2r1Jd3X+X9p/dtkXsvhSclLYy47IAarpful8iouL5YMPPlCpg8jKg82bN6vyVpQJoAcKJqr17t1bBfDQm0SHhsYomUUzYkwtqw2aM6NcFv1JdAgcYj/YRnUBRvyhYvrHCoKLegolTu5Afxzu8njI/scYfdg3b/YTX98KmTKlVE17rYszz/SW5ct9ZNWqcpk2rebJf6b278fLmpe0aYN9N8wnf/36ect33/nIunXlUlJi/dqcBX+O3Z8jjzH+6PwBk2VEVMY8PnFHKZ+lpv9kP3pmg/58k/vxlGOMx4bHiNcrW6b1uiLT10tMGdanO/P3sXM4eFB7DxkXV817yNJSfMNq56BfruH4Oer3sZ/4iVe5l5SVlqmMO1Ndo7rKr/Kr7Di2Q8rL6v9a4u/lLxVlFXIw/aCE+4WLt5f7luxbg++r3V+JnY+xLdtx+oAdylHRaDk/P1+aNWumSlSjo6PVdXrwDb3ukH2HktnXX39dhg0bpiZ3odkzAmhTpkxRQbxWrVpZFbBD4A/T1kyhqTG2h+uqg4lomIxmDk2S3a0RN44Dube6HuPPPuuGglTp2zdVNmyoewqanx/6YgyWpUsLZOHCP1TPuNoUFXnL4cMT1OX4+KVy4sTpI+7tobQU/UHOltWri2TRot/FVfHn2P054hibZomgfUXr1q0lNzdXfdBGDQ8DMMi9ufsxxmtFQUGBaj+D6hl3Zvp6uWTJksqeffx97Bz278dENH9JTFwlixbV8HNnWnFlZfWVo47xETly2tea5Gt/1+5I3SHJm5JPC+jVVaqkym/ym1225Q74c+z+ltrpGCO25TYBu+HDh8uWLVvk+PHj6pMolLsiyw0BNf3TRkwXw1AIwESyli1byvfff6+moD366KPStWtXufrqqxt8rdjXfffdVyXDLi4uTvXdc6ehE/hGPf/889lU003V5xhjKuz06drLyv33x6jGnHWF6bIvv1whx46FSFzcBWJN+8n/Tmb6R0RUyBVXjLQqyFcX554r8uSTFZKeHiS9e1+gqhpcCX+O3Z8jjzH60erQQgK/rzGgydOaxzsaMpIQyMHUUnv98UXOxVOOMYJYQUFBaiqyu79umL5eYvo0Muz4+9g5oG9yXp52DK6++mypMmewoEBkzx5totrhwyKdO4sEBTnV7+Oy8jJZe3itKouNCKw6ES2mLEb8D/hLblmulHcsl7jwOLvs82juUWkU1EhNovX1dvqwQoPh+2r3V2LnY6xXYlrD6X+yMPK8Q4cO6nTmmWdKx44dZc6cOSo4how7QN86XUBAgOp5l5iYqP69fPlyNbRCTz/XywuQpYdAn6WMuKZNm8qxY8eqfA2f+GFyLK6rDvaNkzkcVHf74XXHx0T1P8YrV2ofNDZqJDJxom+9WnNgG2PHimDg848/+km/frXfJyFBO+/QwUv8/Rvu+xPTa1F1j3aaW7b4SevW4pL4c+z+HHGMTbePbHQEFtBCwp2nWjoD/UNL/fkm9+MpxxiPDY/RE34nmT4+08frCY/d2SUnnxou1qiR2bFA+Rp+BtFkWT+38Xg19DFGSWxEcIQKonn7VH29CPAJkM5RnWX7se2yK32XtG5knzeuMWExciT3iKQXpUvL8Jbi6fhz7P787HSMbdmGtyu+edH7xPXr108FyPbgEw+T6OehQ4dUSY4+RRbTY5GlhxMGScBff/0lt99+u8V9nHXWWWpAxSaTEZAI/GHfGEJBRJZ9/rl2fsUVCGDXf3uXX66df/utNpW1Nnv3NvzACd3Agdo5B08QERERuTaHDZxoQJGBkVJcZrkdRfcY+w6eAGTVBfoESnxGfLX7JaL6MTRghx43eiAN4uPj1WVkxyFl/LHHHpN169ZJQkKCCp5df/31asgEJisBykwxHXbGjBmqTxwCd7fddpu6Tr9N+/bt1QAK/dT25JxulMnqferWr18vXbp0UdvWrxszZozcdNNN6ro1a9bIHXfcoXrpNXe12jciB0GLnfnztctTp9pnm+PHi6A6BpNfT75M1DrwAkySbhsMJ8USERERuYf4eO385J+KLinYLxgzM2qcFIvBE/aEibFp+WlqaiwR2Z+hJbEbN25UPep0ev+3qVOnyv/93//J7t275bPPPlP9cKKiomTAgAEqM657d+0FBzBMAiU411xzjWpYiww4ZMM1Qj2dDU3/EOwzndbx1VdfqSDdiBEjVKo+euS98847dnvsRO5mxQr8LGnZbXr2WX2hf8i4cciU1bLs+vSp+fbbt2vn1vS7qy/9MW7YoA0Jc+NqJSK7wKfvpeWOayiPT/79fbQJjERERO6eYRfkFyS+Xr7qd615Tzk9w25P+h4pKSsRPx/7lG76ePtImH+YHDhxQGJDYtUaiMhNAnaY5qr3lLNkvp6uU0v972uvvaZOdd2npa9hIuzcuXOt2iYRncqAGzIE/Xbst93LLtMCdt99h0nM1W8bg+V27tQu9+ghDQ6fG6DfcFaWyL59Wv9hIk+EKejImIfq+mwhWLc+ab3klmi3c4RQv1AZ2HIgg3YeIDU1VX1wu3btWvW+EG1N0BPtxx9/lEmTJlm8D9qnoOri33//ld69ezt8zZ6Ez7Xl10tcdvepuK7ELQJ2vkES4BsghaWFEupvOjVD1KAJBNZyinNk/4n90jWmq9322yiwkSRmJ8rh7MPSKaqT3bZLRC7Yw46InDtg16uXfbeLDLvgYK1UYePG6m+HoBnaW4aEOKacAb1C9ce6dWvD74/IWSEwggFROFU3yRKf9iNY5+/tr/5gaOgT9oP92ZLRd91116n1m5/2oybfCvjw75577hEjbd68WU0wi4yMVJUJN998c2VwQIe2I+PGjVPBArQGefDBB6sEDRBU6dOnj5r0O2HCBDVwS4fboX8w2oVYA9tCi5LY2Fg1/RODw9BuZK/ecNRO3nzzTTly5Ihqq6JvG/8ei8lFLg4fHuNDZFs4w/ci1f31kozhDiWxCNYhaIeAnTl8v+lZdtuObbPrfrFtBO3iM+Mlu8j66ZdEVDsG7IjIrgE7e394jgAcetlBTUm3ejksMt8cVZ7avn3V6bREVPsfE4G+gQ1+wn7qAv1rEegxPem9bx2luLhujbtTUlJk5MiR0qFDB/nnn3/kt99+k//++08FInVlZWUqWId9IBsNbUc+/fRTeeqppypvc+ONN8p5552ngn9ZWVny4osvVl73+uuvy5AhQ2SgFX0PFixYIGeeeaYaFIY2I7t27ZIvv/xSIiIi5MknnxR7OnDggAokIiCo9ydu2rSpGkxGjv9eJHI1KLRyhww7vadcUak2oNFc76bam/QtqVY0hrZReEC4FJQUyMGMgzVW0BGRbRiwI6J6Q1mo/smkvTPs4IILtPNly2oP2DmiHFanv6nT3+QReSIEZBAUwsnV/8BHgAeBHtOTj4+PemzmpZXIYEImE+D6P//8U95+++3KzDyUASIYhmw3Uz/99FOVzJqnn35alQliij2Cg8hEA5R1IngWExOjhmwhiIap9zUFyFAOOmvWLOncubPq+4t+wPPmzavMEsSArp07d6rAGfaJDLTnnntO3Uc/dgisIQuuU6dOMmXKFPVvOHjwoMyZM0deeOEFq3oDT5s2TS644AL55ZdfVCARjw19htHCZPbs2ZW3xfOGACCe+2bNmskjjzxSJeMPz/Fdd90lDz30kMo0wzHBc6Zr06aNeoyff/65el71ACUu47nWISsQmYN4fvv376+y/8zt2LFDPSfILkRWIMps0UfZ2rXox+2WW26pzCrEwDMcG93q1avl7LPPlqCgIImLi1Pbw6A1a+nfL1988YV67AiAYihaDiY/1fC9aO3jQ/9mfG9HR0fL6NGj5corr5TL9ZHtJ6HnM67Hcw4IDg8dOrQys3P8+PEqiEo1v17iMjkHJBKf/BGS1q3FpYUGhEp5RXmtAbuGCKrFBMdIYlaiHM07avdtE3kqBuyIqN62ncysj4tD/0f7b3/ECO180yb8MWT8wAkdA3ZEWpkkMrVw8tR+TAiOnHXWWSrQpWfmIRhjLQTUEHRC716UdQJKSY8dOyaLFy+WTZs2Sd++fdUgLNMSVVP449/f379KH0EEhfQgEfz999/So0cPFazRISiTnZ2tsvGgV69esnTpUnUsly1bJj1Pvqjeeuut8uqrr0pYWFitj2fJkiUqEITAliV6EDM5OVkF9RBcRDDy/fffV0HB559/vsrt8b2FEkJkDmINzz77rFojbNiwQWVGXnbZZep5x7Ewh7JgBJG6deumnksEvR544IHTAm0IiiKoh6FoCEIdPXpUbdfatZSXl6uA2Jo1a1RQFMHRl19+WQV9AUEsrBWDzLZt2ybffvutOjYIktkC20EwEoFAnBCgw35q+l605fHh+wiPAQHfq666Sn799dcqpdU4vgjKXnTRRerfCDhicBy2i+8ZfA/iOjwfVBVfL52T/j6uaVOtP7ErQ0ksAvWWAnJnNDlDDaPAVNfknGS77xsZ7hh6sS99n+pdS0QuPnSCiNyDnvTRENl10LKlSKdOImhNtHKliKUe4kZk2OmfwjJgR+QeEPxA9pEOwZfvv/++1vshywlBDvSFQ9aVrZDdhmwlZNMBgjjICEPATi/rRGYagjQ//PCD6k1nDsEYBE1mzpwpd999twqiIFsNELTRhzOYButA/zeuA2T6TZ8+Xe0P5a+PPvqoyubCY0NgDQE+BIyQ1WUeWNPtQ1NREenSpUuNj/u9995TwaR3331X/YGJ26O09+GHH1ZlunrwEUHDGTNmqMsoe8XtERhCvz48Z3iOEJys7rlHHzgEjxAMRNZb9+7dJSkpSW677bbK22CbCGaZlgB//PHHan3oi4eMw9rW8scff6jjhqxE/fbt2rWr3N5LL72kAmB6fznc/5133pFzzz1XBSv17Mra4LEge1MPniJTDmtA9mN134vWPj6sCYFIXfv27VWAEgM8sB/9+bzwwgsr948ApClsF8cFAUtkGBI5O3cphwVMacUEWATMzNtDIKDWNbqrbD+2XWXZtQxvaff9RwdHS1JOkiRkJkjHqI523z6Rp2GGHRE5bf86S1l2lspiUcZw8KBxJbHoYcd2HUSub/jw4SrDTT8hmOIIrVu3rgzWAbLNkNGE8kIEEPVTfHx8taWGCEIhawd95vRgDcpQEZCrbnpvddtBxlZCQoIKzKD8EQEqBHzuvPNOGTx4sFofsgGReWWJtaVWCGwhG8y0RBhBQjx2BNR0epafDqWzCGZaC/vBNkwDYtivKTymFStWVHm+9YCj6XNe01rwPdOyZcvK4Jc57AOBNtN9IACKAByOrbVQCmua6WjN82Ht40MvQFO+vr4qCw99CAGB4J9//lkFHk0DtCifRnAS5dtYnz7ghMgVuMPACV2AT4A6VZfh1pB97MDH20caBzaWAxkH5ESB5YxwIrIeM+yIyGknxJoH7N5/33LA7mQllypliI4Wh2nVSjtH+6H0dMfum4jsD5lEGNpgDgEv8yAUAlm1sfZ+2K8pBKwQhFmJlGIz5j3xTKHfGE4oddSnUL7xxhuVWV4I4plPeMVt9essQdYeMsIQiMJ6kFWHbWN4Bf6NSbLm9IDV7t27TwuM1QV685nC47J3uSWeczyWV1555bTrcCysWYteglzTPtDfDn3rzLXSf6E00PNh7eMz/14EBOeQBYigIMp/8ThR2qvDdhF0/vDDD6V58+ZqLcisc/WeluThGXZ4rU5LEzH5MEXws4efF7OfQWeC7Dpk2eUU5UiYnN7CoE/TPvLFti/k39TT+3jaS1hAmGTnZKvS2H7N+6kyXCKqG/70EFG9oAXLjh0Nn2E3fDj+KEGmBMq7tPdLRpbDAirVmjfHdEbtzR4DdkTuCdlvaNhvCtlUpoETlCFiCqv5/TAMAFlJeiBE71FXE/SrQ4kqspv0bCVb6GWuKE1EVhnKNQHBM5RNIvCiT1NFAAZZUejvZg5llshO++STT9S/8fj0gGNNActRo0apoQQorUQppTn0U0PgsWvXrqp3H4KaepYdeqchewwBQnvBflDWW1hYWJllt27dutOec6wFzzee97pA9h0yA01LTM33gTJRS0Fhe7L0vVifx4esSpTOouceeiqiv6L+vZ+eni579uxRwToM0zDtmUjkKvQqjdMCdnjDafohCb7v8cbPyWFia3p+usXresVqn64nZCWoDDhMlW0IsSGxkpKTIjGZMdKu8anWAERkG5bEElG97NmDZuciaPtk0qrH7jDMok8f7fLy5cYPnNBx8ASR9YpKi6SwtLDBT9iPPaE/HBrqo88cyv9QImoewEMgBIMIMJETAxeQZYSpqChPfeyxx1TZIUpMURJZG0xVRXANk2kx2RXbXLt2rTz++ONqHdVB2ermzZtVwAiTXzHMAH3T9Kw8BNIQmEMvMpRIYnjAE088Ibfffntlrzwdglu4/wcffFBZUotyVWwX90XwB/+2BMFJ9MJbuHCh6nWG3m54DFg7BlFggAWgV97hw4dVqS2y8VBqiecWWX22lPHWBlmHCAhiEAMCZosWLVI9+kzhOcBAD5R2YpAFjheeH0y7NQ9+VQdZaOecc47q6YZAKMpcEeDCgAdAbz4cRzyvCNziewmP2dahE7Wx9L1Y38eH5xBDKPC4TMthGzVqpEq38X2C4SnLly9Xx4/IlezerZ137ixuIcQvRMoqLP9cRwRGSPtG7Ru0LBaQVRcRECH7MvZJZmE1E+OIqFYM2BFRvejJIgiW2fHvK5v62BmVYQccPEFk3Rv3UL9QKS4vlpzinAY/YT/Yn73KcNBn7Mknn1TBJgxeQNbctddeW+U2mDqKaaAIiCGzDv27GjdurKaFIkCE6axff/21mlBaGwSXcB8EfxBQQbYWhjygr5z50AhTKHdFNh32hQDK7Nmzq5RfYn0YrIFzBASvvvpq9Tgw6dTcM888o8pee5ukTqOnHwJNWBfKIM2HDZiaOHGiCk4hEwvBHvRLQ7AoKyurclhFixYt1OPEujGdFoG8G264QQUR7Qn92tBvb/v27WrwAgKf5qWhKOVEdh+CVwhs4jlEKTCCnbYEDxHIxPcIHiu+F/A9owfEkIGH/oAIqCIbDWvBcA3s254sfS/W9/EhSIdgJ46ZaaAW9/3mm2/U9F2Uwd57771q8AmRq0BbE/09nIVEY5eE4RI1aeg+dqbBwcKSQjlw4oCUV3BqNFFdeFVY2xmYbJadna2mdeHNKcpN3AFKYPDm+oILLjithwqJRx7jhx4SwXvz6dNFZs1q2LUtWSKCtjlxcdqgB1RQ4RUMpagnTohs2oSyH3Goxx7D5D9kZyC7RVwCf47dnyOPMd5GIItHD4wgqwfDDswnXqIBdml5qTgKgnX+Pv7irpA1hfcZeH9hz2w0ch6ecoyRzYlsREuvG+7G9PUSZeOlpaX8fWywzZsxbEV7L4mWdZXy87U+LF27av/WLwcHO/17royCDPkr8S9Vlmrpg6vf9v8mT6x4QrpFd5PPL/q8QdeC3/3H8o7JgBYDpHmY85cT1wXfV7u/EjsfY1viROxhR0T1snVrww+c0KE9Dt4nHT6MPkciQ4eiD5EWrEOvbyM+GTWdFEvkiZANpk84xR/e1UHwzJ0DaEREtrxeknPYudO9susgwFebFFtSVmIxYKdn2O1J3yN5xXkS4n/6sBl7we99rAUDKKKCotTaiMh67vtxHRE5tFGvhf7adodg3eWXa5c/+kg7nzNHO588WcSID+bZw46IiIjINbljwA4lsQiUFZVZ7ufaNLSpNAttpvrc7Uir2o+1IUQFR0l6QbocyuSbZSJbMWBHRHVWXi6SmFi1l1tDu/FG7fy770SSk0W+/Vb79w03iCFMA3ZsMECeqKioSDW0x6m4uNjo5RARucTrJS6T8dwxYOft5S3B/sEqw87oPnb6epBddyDjgBzP10rCicg6DNgRUZ0dOyaCv8/RWqdlS8fs86yztDdVBQUil10mkpsr0qGDVi5rhFattHOsA6W5RJ4GPZjee+89dcJlIiKyjK+XzscdA3aACa3VZdhBr9heDgvYQah/qOrLuTttt90nuRO5MwbsiKjO9L5tGHDnqB6rGDRx003a5bVrtfPrr9e+bgSU4TZtql1mWSwRERGRa0CS44ED7hmwC/YLVkNOqtOnaR91vv3YdocNhGoS0kSO5R9TU2M595LIOgzYEVG9A3Z6lpmjXHONiP/J3vXI7rv2WjEUB08QERERuZa9e7X2LhERpz58dRcY9CA1fJjdtlFbCQ8Il8LSQjV8whF8vH0kJjhGDmYcVJNjiah2DNgRUZ3pASpH9a/TRUWJXHKJdnnsWJEWLcRQHDxBRERE5LrlsJWVGiUlIikp2rmLD57w8/arto8d+srpZbH/HvnXoZl/mJa8N32vChYSUc0YsCOiOnP0wAlTr7wicvPNIm++KYZjwI6IiIjIDfrXIVB35IhbBOxqmhRrOnhi69GtDlyZVhqblp8mB08cZGksUS18a7sBEZGzZdhBXJzI7NniFPTHz4AdERERkWtw14ETgGAdTtZOikXgDJlvjoDsPpTGxmfGS3RItArgEZFlzLAjIpcM2DkTZtgRkTUOHTqk/iDassUxU/mIiMgOATtMVmvWzHET1uwAv2vQo66mDLuu0V1Vr7uMwgxJyHJsI2aUxsLe43s5NZaoBgzYEVG9S2IdPXTC2eiPPynJ6JUQOV5QUJDEx8erUyDGJruw1NRUufPOO6Vdu3YSEBAgcXFxMmHCBFm2bJk4i5UrV8rEiROlRYsW6tS3b1/56quvqr39N998o/5wmzRpUo3bLSsrk5dfflm6dOmijmnjxo1l0KBB8tFHH1XeZtiwYXLPPffY7bG0adNG3nrrLbttj8iVXi9xmYyDilcMnbA6YNe8uUsF7CDMP6zGCbDIwOse011d/jfVcX3szKfGItOOiCxjSSwR1Ul2tkhmpnbZ0zPs8KErZGSIFBTgDbnRKyJyHG9vbxV4gcLCQpfOfhsyZIhERkbKzJkzpUePHlJSUiJLliyR22+/XXbv3i3OYO3atdKzZ0958MEHJSQkRP7880+59tprJSIiQsaPH3/aY3rggQfk7LPPrnW7zzzzjMyePVveffdd6d+/v2RnZ8vGjRslAy9sdlZcXCz++qhvIg99vdQD5WSM/ftFSktFQkO1NivuKNAvsNYecX2b9ZXNqZtlU8omuajLReJIKI2NDoqWAycOSFRQlMSExDh0/0SugBl2RFSvctjGjbU3O54sMlJETyxKTTV6NUTOKS8vr9qTeaCvptsWICpuxW1tNX36dJWJtn79ernkkkukU6dO0r17d7nvvvtk3bp16jbXX3/9aUExBPWaNGkic+bMUf8uLy+XV199VTp06KCy9Fq1aiUvvPBCtfvdsWOHjB07VkJDQyU2NlauueYaOX78eLW3f+yxx+S5556TwYMHS9u2beWuu+6SMWPGyPz586vcDoGAq666SgXikDFYm19++UU9B5MnT1bb7dWrl9xwww0q4AfXXXedCg6+/fbb6nnCCQFB7Ae3w32QMdS5c2d1G1O4LzL88Dw0b95c3QbZegkJCXLvvfdWbo+IyFF27NDOu3Y1mRDrZlDuitfWmoJ2/Zv3V+cbj2w0ZABEiH+IOt9zfA9LY4ksYMCOiOqE/etOwRs9VEpASorRqyFyLGRLIdsLJ1yuDgJS1Z0QIDOFAFh1t0VwyxSyVSzdzhYnTpyQ3377TWXSIWvNHLLu4MYbb1S3O4IJgictWLBA8vPz5fLLL1f/fvTRR1Vp6ZNPPik7d+6UuXPnqkCcJZmZmXLeeedJnz59VDYbtn306FG57LLLbFp/VlaWKmE19eyzz6rnEcE0azRt2lSWL18uaWlpFq9HEO6ss86Sm266ST1+nFAyjABly5Yt5fvvv1eP96mnnlJBxe+++67K/VFWvGfPHlm6dKl6zhBgxP2wTn17RO7O2tdLanhbTw5G7dVL3FaAb4D4evtKSXn1gyd6NOmhSmOP5x93eB87HQZQoDT2UCabQROZY0ksEdWrfx0DdhoE7A4eZMCOPA8yzF577bXKYJUr2r9/v8osQP+2miCrDdlhX3zxhTz00EPqa5988onKSkOQMCcnRwW2UFY6depUdX379u1l6NChFreH2yFY9+KLL1Z+7eOPP1aBsL1796osv9ogMLZhwwZVzqpbvXq1yvizZbjFG2+8IZdeeqkK3CGzEI8VvfL0AClKblHGGhwcrG6j8/HxUVl8OmTa/f3332pdpoFHBELRD8+0FBb3DQsLq7I9Ik95vXz66adZGm4g/eXRrQN2PgEqGFdcVqzOLd7GN0B6NumpMuw2pmyUNpGnSrYdxcfbR5XEHsg4INHB0RIVHOXwNRA5KwbsiKheGXaePnBCxww7oprl5uZWex0CN6aOHTtWYw8oUyjLrC9byoCQZffBBx+ogB2y4RYvXqwy02DXrl1SVFQkI0aMsGpbW7dulRUrVljMCDxw4ECtAbu//vpLZdB9+OGHKsgGCBqirBZfi46OtvpxdevWTZXnbtq0SdasWSOrVq1SAzdQzmo6eMKSWbNmqUBjYmKiKllG5lDv3r2r3AY9ARmcICJny7Aze6lyKwjS4VRSVn2GnV4WqwfsLu12qRgh1D9UsouyZW/6Xukf0F/8fFxrwAdRQ2HAjojqhCWxlgdPMGBHZJmlUlNH37Y6HTt2VH1+rBksgQEPjzzyiMoiwwAIZJTpQx1snfqIICaCYq+88spp1zXTX1SqgX5yU6ZMkddff12tyTTQhyAmtqtD2Sr4+vqqslRk/VUXDB0wYIA6YRrsl19+qYJ/jz/+uHqc1U2hRZ87rAMls8iYw9COf/75x+7HiYjIHtAmNClJu9yz58mRsWgHEONeQw/wey08IFxScmp+c6r62G0S2XRkk5RXlKthEEbA1NjknGRJyEyQDlEdDFkDkbNhwI6I6oQBO8sZdmzDROR60P9t9OjRKlMMQxzMg0voNaf3sYuKilIDFFAKi6DdtGnTqgT+ELRDvzZk4tWmb9++Mm/ePNWHD8E0a61cuVIF5GbMmCE333xzletQ1rt9+/YqX3viiScqy3VRbmtL1h3oQzyQIWc+1RLZeCifxcAK06ChNSxtj4jIUdl1mMcTHi4i+SXaG7iTr/PuBJlrpeWlNd6me0x3CfQNlIzCDDmYcVA6NDYmWIZ+e40CG6nSWJTFNgpqZMg6iJwJh04QUZ2wh11VLIklcm0I1iF4NHDgQBVE27dvnypxfeedd1TmmCkE4z777DN1vd6rDgIDA+Xhhx9W5bKff/65Clxhwqw+QdYchlxg4AUy5dCHDrdfsmSJCgJWF8hCCe24cePkzjvvlAsvvFBSU1PVCdvR13DGGWdUOSHYiMw3XK6uLBX96958802VGYfprQgKYn0oy9V7+yGwiOuRwYdJtsjcQ5ASAzOwbvTdw7ANPBZrYHsovU1OTq5xMi4RkT15QjmsDoG4Cqm57QPKT3vHak8GymKNhIzAwrJC2XdiX62BRiJPwIAdEdkMg830TDL2sNMwYEfk2tq1ayebN2+W4cOHy/3336+CW+eff77Klnv//fer3HbkyJGqZBVZec31H/6TELDC/TEttWvXrmp6bHU9+XBfZKghODdq1CjV5w2lqAiwmffq0yFQiKm0mESLQFqLFi3UWi6++OJ6PX48ll9//VVl7iFIh0Aktv/7779XZv+h9BX9BpF5FxMTo3rW3XLLLWrfeJyDBg2S9PT0Ktl2NcGEWAT/UKKL7REROYInDJwwHSqBeF1tvVpVWawTBOygaUhTSc5OlqTsk3XLRB6MJbFEZLPDh/GLH/2a3K7dR50xYEfk+hD4wuRWnGqCEtGMjAw18MEcAm3o+YaTpYwy8z+akKE2f/58q9f46aefqhOy27KzsyU8PLza4J7pfWpz0003qVNNEMhDGbA5lAfjZOqll16qdf9nnnmmGrxBRORInpZhhww6ZKvVNMhBD9ihj11ZeZma3GoUlMYi0w4DKBoHNVaXiTwVM+yIqF4TYr28jF6Nc9D7w2dlieTnG70aIsdBzzZMF8UJ5ZjuDEEyZMs999xzKgsOJalERHV5vbR1SA3ZR1GRyM6dnhOwC/AJUJNii8qKarxdl+guqt9dTnGO7E6vfQBTQ4sMjJT84nw5cOKAGoRB5KkYsCMim+mTtWzoXe720LQ4OFi7zMET5EmQ3dW9e3d1qi3Ty9WhBDQ2Nlbmzp0rH3/8sU2DIoiIPOn10lnt2iVSWqrNl6jxfayfn/ZpLM5dGIJ1OJWUldSa1da/mZZltz55vTgDTI1NzEqUIzl8Y02ei78piMhmekBKzyojLdOQZbFE7k0vaT18+LCMGDHC6OUQEVEd+9chu67GKhEE6vDGzsUDdl5eXipzrrisuNbbDmwx0KkCdui/h5Le/Sf2S2FpodHLITIEA3ZEZDMG7CxjwI48UXFxsTz99NPqhMtERGQZXy+Nt3mz55TD6sL8w6SkouYMO9OA3ZbULU4TIIsKipL0gnQ5eOKg0UshMgQDdkRks9RU7ZwBu6oYsCNPVFJSIs8884w6laLOiIiIan29xGVyvD/+0M7POksdEO1Nm5sfiyC/IKkor3lKLLSOaC2xIbFSUl6ignbOkiEYHRQth7IOyYmCE0Yvh8jhGLAjIpsxw84y/flgDzsiIiIi5xIfr/Ww8/ERGTXqZMAOb9rcPGCH0lIEvmqD2+hZdv8k/yPOIsQ/RE25xQAKTLAl8iQM2BGRzRiws4wZdkRERETOadEi7XzIEG3ohKfApFgMlaht8IQz9rHTNQluIik5KZKae7LMh8hDMGBHRHUO2DVtavRKnAsDdkRERETOHbC74ALxKMiw8/Pxs27wRHMtYLcnfY9kFmaKs8D6OYCCPBEDdkRkk9xc7QTMsKuKATsiqsmhQ4dUydEWfUwhERE5REGByPLl2uVx48Sj+Pv4i5+3n+pNV5uo4Cjp0LiDU2bZNQ5qrAZQJGYlGr0UIodhwI6I6jRwIiREJCzM6NU4FwbsiFxbamqq3HnnndKuXTsJCAiQuLg4mTBhgixbtkycxcqVK2XixInSokULderbt6989dVXVW7z6aefqsCg6SkwMLDG7ZaVlcnLL78sXbp0kaCgIGncuLEMGjRIPvroo8rbDBs2TO655x67PZY2bdrIW2+9ZbftERFVZ+VKkcJCkbg4ke7dxaN4e3lLkG+Q6gNnjUEtBqnzv5P+Fmd7HI0DG0t8RrxkFWYZvRwih/B1zG6IyF2wf1319OckJ0fLQgwNNXpFRGRL9tuQIUMkMjJSZs6cKT169FBTHJcsWSK333677N69W5zB2rVrpWfPnvLggw9KSEiI/Pnnn3LttddKRESEjB8/vvJ24eHhsmfPnsp/19ZwHFMrZ8+eLe+++670799fsrOzZePGjZKRkWH3x1BcXCz+/v523y4RUXUWLjxVDmvF/AW3E+wfLMfzj1t126FxQ+Wr7V/J6sTVUl5RrgJlziIsIEyysrPkYMZB6dW0l1Otjagh8DuciGzCgF31kHGoB+k4KZY8BTK31q9fr07ISnNV06dPV0EtPI5LLrlEOnXqJN27d5f77rtP1q1bp25z/fXXVwmKAYJ6TZo0kTlz5qh/l5eXy6uvviodOnRQz0erVq3khRdeqHa/O3bskLFjx0poaKjExsbKNddcI8ePV/9H1WOPPSbPPfecDB48WNq2bSt33XWXjBkzRubPn1/ldngsTZs2rTxh2zX55Zdf1HMwefJktd1evXrJDTfcIA888IC6/rrrrlPBwbfffrsyaw9BTmTm4Xa4DzLzOnfurG5jCvedNGmSeh6aN2+uboNsvYSEBLn33nsrt0fkSa+XtWW9kv1UVFQN2HmiEL8QKauwbsJqn2Z91O0zCjNkZ9pOcTYxwTFyOPuwHM09avRSiBocA3ZEZBMOnKgZy2LJ0/j4+MiAAQPUCZerk5eXV+2pEHVKVt62AI2IrLitLU6cOCG//fabyqRD1po5ZN3BjTfeqG53xCQiv2DBAsnPz5fLL79c/fvRRx9VpaVPPvmk7Ny5U+bOnVttsCwzM1POO+886dOnj8pmw7aPHj0ql112mU3rz8rKUiWspnJzc6V169aqrBcltP/991+N20BQb/ny5ZKWlmbxegThzjrrLLnpppvU48cJ20aAsmXLlvL999+rx/vUU0+poOJ3331X5f4oK0bG39KlS9VzhgAj7vfss89Wbo/I3Vn7ekn2tW0bsqhFkNh73nnikTB4wlqYKDs4brC6vCphlTjjY/H18pUDJw5YNUiDyJWxJJaIbMIMu9oDdnv3MmBHZA4ZZNW54IILZKGe/iCiMtYQBLPk3HPPVX3cTPugWcpIq0BKhZX279+vbo/+bTVBVhuyw7744gt56KGH1Nc++eQTlZWGx5eTk6MCWygrnTp1qrq+ffv2MnToUIvbw+0QrHvxxRcrv/bxxx+rQNjevXtVll9tEBjbsGGDKmfVYY3YDkpnEcx77bXX1NoRtEOQzJI33nhDLr30UhW4Q2Yhbo9AH7L/ACW3KGMNDg5Wt9Eh6IByWh0y7f7++2+1LtPAIwKh6IdnWgqL+4aFhVXZHhGRvc2apZ1feKEV7Ur8/LQ3uTh3s8ETthjaaqgsPbhUlcVOHzBdnE10cLQk5SRJSk6KtIlsY/RyiBoMM+yIyCYM2FmXYZecbPRKiBwD/cjQ8w0nXHZFtgT3kGWHIB0gG27x4sWqVBZ27dolRUVFMmLECKu2tXXrVlmxYoUK9uknPWh44MCBWu//119/qXLUDz/8UAXZdMiEQ1+73r17qwAnstliYmKqBPXMdevWTZXnovwXj+fYsWNq4AYeb21mzZol/fr1U/vAY/jggw8kMbHqFD/0BGTfOvJ07vB66WrQhvPLL7XLd96p+hhon6ri3BIE6vBmzg0Ddj5ePlYPnhgSN0T1h9t7Yq+k5p6cOOdEfLx9JNw/XGXZFZRUzbwncifMsCOiOk2JZcDOMkwfg8OHjV4JkWOgh5uebYbgUXVQolkd89IwBIuq4+1d9bNG9FGrr44dO6oeatYMlkAg7JFHHlFZZBgAgYyys88+W12HHm62wHOCoNgrr7xy2nXNanmRRT+5KVOmyOuvv67WVBM/Pz+VyYdMwprgudXL9TAN9ssvv1Q99R5//HH1OC355ptvVJ87rAOBQmTMIRjxzz//VLmdpVJjIk9+vUTPSAaxG97HH4ugk0LPniLqpbqgRPv0+WSrA0+BgJ2fj5+UlJWoktfaRAZGSo8mPWTr0a0qy+7SbpeKs8EaE7MTJTErUTpHdzZ6OUQNggE7IrIJM+xq1qqVdp6QYPRKiJyLLQGbhrptddD/bfTo0SpTDEMczLeJXnN6H7uoqCg1QAFZdgjaTZs2rUrgD0E79GuzJjOtb9++Mm/ePFXW6+tr/VsylAQj0Ddjxgy5+eaba709BkNs375dlR7bAll3oPcERHAB2zK1Zs0aVT6L4IPOmuzA6rZHRGQveHnRy2GRXefJs20QsEOgrqS8RILEug+Xzm51tlMH7PBBW+PAxnIo85A0C2sm4QHhRi+JyO5YEktENmHArmatW2vnZtVgROTkEKxD8GjgwIEqiLZv3z5V4vrOO++ozDFTCMZ99tln6nq9Vx1g6uPDDz+sMmg+//xzFbhCiak+QdYchlxg4AUy5dCHDrdfsmSJCgJWF8hCCe24cePkzjvvlAsvvFBSU1PVCdvRYZDD77//LgcPHpTNmzfL1VdfrSay1hRERP+6N998U2XG4bYICmJ96KOnl+kisIjrkdWIvoEYOIEgJQZmYN3ou4dhG3gs1sD2Vq1aJcnJyTVOxiUiqovFi0Xi40UaNRK58krxaAjWBfgEqAw7W/rYwYaUDU5bdhoWECb5JfkSnxFvU3sLIlfBgB0RWQ3tVvS/qdgjvOYMOwbsiFxLu3btVHBr+PDhcv/998sZZ5wh559/vsqWe//996vcduTIkapkFVl5zfXGlSchYIX7Y1pq165d1fTY6kp8cV9kqCE4N2rUKNXnDaWoyOYzL/3VIVCIgRyYRItAWosWLdRaLr744srbZGRkqGmu2D+y6rKzs1X5rp4xZwkey6+//qoy9xCkQyAS20fgT8/+Q+krypexHfSrQ5+6W265Re0bj3PQoEGSnp5eJduuJggsIviHwRzYHhGRvZSXi+jzfNCtITjY6BUZLzQgVGXYWat9o/bSIqyFFJUVydqkteKsYoJjJCk7SdIL0o1eCpHdsSSWiKx29Kh2jr/doqKMXo1zB+zS01FGhnI9o1dERNZC4AuTW3GqCUpEERSz1LMPgTb0fMPJUkaZeQYAMtQwFMJan376qTohuw2BuPDw8NOCe8iUw8kWCPDhVBME8lAGbA7lwfogDt1LL71UZc2WnHnmmWrwBhGRveFzFrxcYSrs3XcbvRrnEOIXYvXQCb3k9Ly258kX276QFfErZERb6wYqOVqQX5BkFGbIwYyD0jiosRqWQeQu+N1MRDYPnEB2XTXJHx4vIkIk/GQLDQ6eIHIvCJIhW+65555TWXAoSSUiIueCPsKPPKJdxkyfli2NXpFzCPANsLlsdHib4er8r8S/pLis2Kmz7I7kHHHKibZE9cE/uYnIauxfZx0OniByTygBjY2Nlblz58rHH39s06AIIiJqeIhH3XILpnCLDB0qcuutRq/IuQZP2OqMJmeoYFheSZ6sT14vzgoTcPH4Dpw44NSBRSJb8Z0mEVmNATvrB0/s2ME+duQZMGgBgxAgICBA3JmlklYiorq8XuIysnbJvn7+WWTJEvw+EvnoIysrQvz8tDe3OHdjCGihhUJZeZn4ePtYdR+Ulw5rM0y+3/m9rDi0onIQhTOKCoqSpJwkSclJkTaRbYxeDpFdMMOOiGwO2HHgRM04eII8CYYQDBs2TJ1wmYiILOPrZcPCcG29fegDD4h07mxyZUmJSEqKdm4OgToMEPKAgJ2ft59NgydA71238tBKm3rgORqCkGH+YSrLzlmn2hLZigE7IrIaM+ysw4AdERERkWPNnSuyc6dIo0ZawK4KBOrwRtZSwM5DBPgEqKCdrUG33k17S0RAhGQVZcmW1C3izBoFNlLrTMzim3ByDwzYEZHVGLCzDgN25ElKSkpk1qxZ6lRaqv0RwDIvIrKWJ71emL5e4jLZT3GxyIwZ2uWHHxaJjDR6Rc7Z5w2nkjLbvvd8vX3l3NbnqsvL4peJM8Nk28aBjeVQ1iHJLso2ejlE9cYedkRkteRk7ZwBu5px6AR5kuLiYrnjjjvU5alTp6r+OCkpKRITEyP+/v7qzTM1TJADz31hYaF6zsn9uPsxRj9IPL60tDT1+PB64Umvl9ddd51HPGZHmTNHJD5ea9ty551Gr8Z5hfiFSG5Rrs33G9FuhPyy9xdZHr9cHjjrAat74BkhLCBMMrMzJSEzQXrE9jB6OUT1woAdEVmloEBk+3btcvfuRq/GNQJ2SUlaPxW2qSFPgeBc27Zt5ciRIypoRw0b7CgoKJCgoCAGRd2Upxzj4OBgadWqlVsGJclxMGAC0MMuONjo1Tgv9HhLKk+y+X6DWgxSZbHpBemy+chmGdBigDh7aWxyTrK0jmwt4QHhRi+HqM4YsCMiq6xfr7X9QHZdu3ZGr8a5oW8xgnR4vo4e1f5N5CmQMYI/vlEeW4aINTUIlNOtWrVKzjnnHPFz80bpnsoTjjEGL/j6+rp1QJIaHoZ379mjXR41yujVOLdAv8A6TTtHWezwNsPlpz0/ye8Hf3f6gF2of6icKDghSVlJ0q1JN6OXQ1RnDNgRkVVWr9bOzz4bWTRGr8a5+fqKtGih9bDDiQE78jT44xsBBncNMjhLoANB0cDAQD7PborHmMg6+HA0L08ESZpt2hi9GucfPCF1fB9/fvvzVcAOZbEPD3lYBfGcPcvucM5haRXZSgXwiFwRc8+JyCp//aWdDx1q9EpcAwdPEBERETW8ffu089atkeVtwx0RCEfpiAcFxAN8A8TXy9fmSbHQr1m/yimsG5I3iLNDL7v84nxJzj7ZhJvIBTFgR0S1QlXb2rWnMuyodhw8QURERNTw9u/Xzjt0sPGOCNShDMKTAnY+AeLn6yfFZcU23xcZdSPajlCXURbrCtB3LzErUXKLbR+0QeQMGLAjolpt2yaSkyMSHi7Sg8OWrMIMOyIiIiLHBew6djR6Ja6RYefv7V+ngJ1eFgsrD62s8zYcKSIwQnKKcyQxk2/IyTU5d+E5ETlVOezgwZx4ai2UZQADduTuAgICZMGCBZWXiYjIutfLujT/Jxsy7DD9Ky1NJCbGiGU5JW8vbwn2D5aM/Iw63b93bG+JCY6RtPw0WZ24Ws5re544u6igKEnMTpQW4S1UAI/IlTDDjoisDtixHNZ6zLAjT4EJj+PGjVMnXCYiIsv4emlAwO7IEe2cKoX5hdU5O87H20fGdhirLi/YpwWfnR0GThSWFEpCVgKD5ORyGLAjohrh9xoDdnXPsDtwQKS83OjVEBEREbnn+1R96ITNPew8FDLsyivq/uZ0XMdx6nxN4hrJKKhbpp6jRQdHy+Gsw3Ki4ITRSyGyCQN2RFQjBJyOHtWmbg0YYPRqXEfnziIhIVrvvx07jF4NUcMpKSmRTz/9VJ1wmYiILOPrpf2h4hXvtby8RNq2NXo1rjN4Qrzqfv/2jdtL1+iuUlZRJksOLBFXEOQXJKUVpWoABbPsyJUwYEdENfruO+0cwbrAQKNX4zpQ6YKef6BnKBK5o+LiYpk2bZo64TIREVnG18uGK4eNi+P7VFsGT6CXXVl5Wb2z7FylLBaig6IlKTtJjucfN3opRFZjwI6IqoW2Hy+9pF2++WajV+N69BLiVauMXgkRERGR+7F5Qqyfn0izZtq5B2fY+fv4S0l53bM8x3QYI77evrL7+G7Zf+LkQXBygb5aRPdQ5qF6lQQTORIDdkRUrUceEcnNFTnzTJGrrzZ6Na7nnHNOZdgx+56IiIjIvmzuX4dAXfPmnh2w8w0QP28/KSmre8AuMjBShsYNVZcX7lsorgITY1NzU5llRy6DATsismj9ei/5/HPt8jvviHjz1cJmAwdqvf+QqYhegERERETkgAmxVC1kxiHbrK6TYnXjO41X54v2LZLS8lJxlWCll3hJfEY8s+zIJfBPcCKyaMYM7eVh2jQOm6iroKBTzx372BERERHZFwN2dRPqH1qvklgY2mqoylhLL0iX1YmrxVVgYiyy7I7mHjV6KUS1YsCOiE6Tl+crf/6pjY96/HGjV+MeZbHsY0dERERkP2g3YnNJLFUG7OqbFYdMvQs6XqAu/7znZ3EVfj5+qiQ4PjPeZTIDyXMxYEdEp9m2LUZKS72kUyeR9u2NXo379LEjIiIiIvtITxfJytIut2tnckVJiUhKinZO1ZaGVtihwfLEzhPV+drDa12qL1xUcJQcyz0mR3KOGL0UohoxYEdEp9m8uYk6HzvW6JW4vsGDtf5/6GGH945E7iYgIEC+++47dcJlIiKyjK+XDVMO27KlSHCwyRUI1KGBMAN21UIPOy8vr3oH7dpEtpGesT2lrKJMFuxdIK4C2YFBfkFyMONgvXv5ETUkBuyIqAr83v73Xy1gN2aM0atxfeHhIr17a5eZZUfuyNfXVyZPnqxOuExERJbx9dK+Dh60kF1XHUyFbdbMo6fDmgrwCVBBq/r2sTPNsvtl7y92ydpzlMZBjeVEwQlJyeEn6uS8DA3YrVq1SiZMmCDNmzdXEf6ffvqpyvVPP/20dOnSRUJCQqRRo0YycuRI+eeff07bzsKFC2XQoEESFBSkbjdp0qTK69LT02XMmDFqH/gkKy4uTu644w7Jzs6ucW179+6ViRMnSnR0tISHh8vQoUNlxYoVdnz0RM5p506R48eDJTCwQs491+jVuIchQ7RzCy9fRERERFQH8fHaedu2VtwYgbrmzRmwMymJ9ffxt0t22fntzpcg3yBJzEqUTUc2iavw9vJWvfyQZVdYWmj0coicL2CXl5cnvXr1klmzZlm8vlOnTvLuu+/K9u3bZfXq1dKmTRsZNWqUpKWlVd5m3rx5cs0118i0adNk69atsmbNGrnyyisrr/f29laBt19++UUF4T799FP5448/5NZbb61xbePHj5fS0lJZvny5bNq0Sa0TX0tNTbXjM0DkfH7/XXtZOPfcCjXllOqvVy/tfMcOo1dCZH/4Xfn999+rEy4TEZFlfL00MGBHVWDoAoJ29gjYBfsFy5gOWlnOvF3zxJU0CmwkmYWZkpydbPRSiCwyNBd77Nix6lQd08AbvPHGGzJnzhzZtm2bjBgxQv2iu/vuu2XmzJlyww03VN6uW7dulZeRcXfbbbdV/rt169Yyffp0dZ/qHD9+XPbt26f21bNnT/W1l19+Wd577z3ZsWOHNG3atM6PmcjZLVmiTYcdNcp1Utqd3RlnaOcM2JE7Kioqkssuu0xdzs3NZZkXEZGVr5f+/v5GL8mlMWBXd6huC/MPk5yiHLts79Jul8qPu3+U5fHL1fCJ6OBocZXnISIgQuIz4qVZWDMVfCRyJi7zrrq4uFg++OADiYiIUNlusHnzZklOTlZZdH369FHZb71791bBuDP0v5DNpKSkyPz58+XcGmr9oqKipHPnzvL5559L3759VSnt7NmzpUmTJtKvX78afwnjpNPLbktKStTJHeiPw10eD1WVmyuyerX2snDeecVSUuIyLxFOrWNH/N9P9T9OTS2RqChj18OfY/fnyGNsug93+n3n7Phz7P54jN2P+eslggXmXyfrHTqE96leEhdXKiUlJh80I3uxvLzquUHPsTP/HAd5B0lpSamUl5XXe1sdIztKzyY9ZduxbfLjrh/lht6nkmmcXZhvmCRlJ0nCiQTp0LiDWx1jsg97H2NbtuP0f40vWLBArrjiCsnPz5dmzZrJ0qVLVV85OHiy0yh63SH7DiWzr7/+ugwbNkyVvzZu3LhyO1OmTJGff/5ZCgoKVN+8jz76qNp94pcnymbRCy8sLEwFBBGs++2331TGXnVeeukleeaZZ077+u+//y7BVUYXuT4cB3I/K1a0lOLifhIbmyeHDv0hCQlGr8h9xMaOlKNHQ2TOnH/kjDPSxRnw59j9OeIYFxae6vuyZMkSCQwMbPB90in8OXZ/PMbuo7rXSx5j25WViSQkTFABuwMHlkl2toUeZCkpVc8N5MzHOEXs8/ycF3iebJNtMm/7PBlVNkp8vHzEVfiIj+w9sFfwnzseY7IPex1jxLas5VXhJKNcECT78ccfqwyM0PvcHTlyRJWpfvjhh6qnHAZPIIA2d+5cueqqq1T2280336xujwy3li1byvPPPy+33HJL5XaQfZeZmakCeY8++qjKsEOJqyV4SrAORD4ff/xxNcwCAT70wduwYYMKHFqbYYchF1g7Ble4Azwn+EY9//zzxY9NW91KerpIz56+kpbmJVOm7JKPPmrNY2xHF13kIwsXesvbb5fJbbfV/5PM+uDPsftz5DHG72n9w6yMjAw1KIoaHn+O3R+Psfsxf71ESSyPcd3gQ+WOHf3Ez69CsrNLxcc0NlRQILJnj0hcnMjhwyKdO4tRjZmd+ec4LT9N1h9eL83DtQGQ9VVUWiQTvpugesLNHDFTzm3tWtPrkrKSVIZdl5gubnOMyT7sfYwRJ0ISWlZWVq1xIqfPsMMb/w4dOqjTmWeeKR07dlS95RB00wNnpj3rUL7arl07SUxMrLId9J3DCVNnkXl39tlny5NPPmkx+IagIDL78ItUfwIR3MNB+uyzz+SRRx6xuFbsGydzOKju9sPrjo/J0z34oAjmuXTrViEXX7xf/Pw68BjbEdphLlyIKbw+4ufnHJ848ufY/TniGJtun99Tjsfn3P3xGLuP6l4veYxtl5Sknbdu7SWBgWbPHcrNvL1F0FNVPzf4+XXGYxwSECJ+/n5S7lUufj71X1uQT5Bc2OlC+Xzb5zJv9zwZ3m64uJKo0ChJykuSlo1aSqOg6qvqXOkYk33Z6xjbsg1Dp8TWRXl5eWUWG/rJIUC2B5+gmEQ/Dx06pIZL1LQNMM2Gs5SiiFJYU/i3fl8id7JokciXX2rvaT78sEz8/Ph9bm89emjnHDxBREREVD+HDpkNnECQDqWvpr2h8EcxkjMYRLEo0DdQBersMSlWd0nXS8RLvGRd8jpJyHSt3joh/iHquTiUeUhV3BE5A0MDdpiOtGXLFnWC+Ph4dRnZcUgZf+yxx2TdunWSkJAgmzZtkuuvv14NmZg8ebK6PbLfbr31VpkxY4bqE4fAnT4RVr/NokWL5JNPPlHTXRHIW7hwobrPkCFDVM87WL9+vcq8w7bhrLPOUunqU6dOla1bt6oy2gcffFCtb9y4cQY9W0QN4+uvMZFZu3zvvSIDBvAXVENPiuV7ACIiIiI7TohFoA7TvcwDds2bM2BXDX8ffwnwCZCScvsNS2gR3kKGthqqLv+w6wdxNZhuiwEUKBcmcgaGlsRu3LhRhg8/lSp73333qXMEyv7v//5Pdu/erUpQ0QMOk1sHDBggf/31l3Tv3r3yPpgI6+vrK9dcc40aKDFo0CBV0qr3h0D/OfS+u/fee1VGHXrKXXzxxVXKWpFRh2CfPq0D9cQYMIH+deedd576OvaJoRX6hFoiV4dEUrR+/Oor7d9Dhog8+6zRq3JfaJ+CioysLK2MA21ViNwBejDhgzH9MhERWcbXS/sH7E7mX1AdoG9dqH+oHM09atftXtbtMvkr8S/5de+vclv/2yTYL9ilsg4hPiNeooKixMfbOdrYkOcyNGCHaa41pZvOnz/fqvrf1157TZ0sQUBw7dq1Nq+jf//+anoTkTv3rEOwDmWwTz4p8sQTWkCJE8kbBt6XI2j3339alh0DduQu8Hv4uuuuM3oZREQu93qpJwuQHTLsqE7C/MMkqfxkQ0A7GdRykMSFx8nh7MOyeP9iVSbrSmKCYyQ1N1WdkDFIZCSX62FHRPW3ejUGqWiXf/5Z5OmntWAdOaYsdvt2o1dCRERE5EY97KhOAv0C7d6vzdvLWyZ309pTfb/ze5frB4e+figVPphx0K79/YjqggE7Ig9TWChy003a5euvFxk/3ugVeWYfOyJ3UVpaqvrD4oTLRERkGV8v7QNzA0+2HmfArp4QmBIv+293QqcJqrx0/4n9siVV61fvShoHNVZ97FJyUoxeCnk45tQQeZgXXhDZvVukaVORairJqYFwUiy5I/SHHX8y8o9hUugrS0REtb9eso9d3SQmagO8goNFYmKMXo1rC/ANEF8vXyktLxVfb/v9/g4LCJMx7cfIT3t+Uqc+zfqIK0HvunD/cDlw4oA0CWniUn34yL0ww47Iw8oHXnlFu/zuuyInZ7OQgzPsdu4UKSgwejVERERErj1wwqsBssM8LcPOz9evQUo/J3WZpM7/OPiH5BTliKuJDIyUrKIsOZx12OilkAdjwI7Ig6BXHfobjxwpcolr9X91C+3aacMmUMqxYoXRqyEiIiJyPexfZ98MO39v/wYJ2HWP6S7tGrWTorIiWXJgiUtO0W0c2FgOZR2S7KJso5dDHooBOyIPgayuL77QLr/4otGr8Uz4FFjvGbhggdGrISIiInLDCbF+fiLNmmnnVOuAiBD/kAYJ2CHgNamzlmX3856fxRWhtLegpEASMhOMXgp5KAbsiDzEk0+KlJeLXHSRyIABRq/Gc5kG7FxsaBYRERGRcwXsUDqSkqKd6xCoa96cATsrhQeEN9g01As6XiB+3n6y6/gu2X18t7iiqKAoScxKlBMFJ4xeCnkgBuyIPMDGjSLz52sZXs8/b/RqPNvw4SJBQSKHD4ts3270aoiIiIhct4edCtQdOVI1YEc2wUCFigb6FBl94Ia1GaYu/7T7J3HV56e0olTiM+KlvKLc6OWQh2HAjsgDvPGGdn7VVSLduhm9Gs+GYB16CALLYomIiIish7jSvn3a5fbtjV6Newj0DVTnDRW0u6jLRep80f5FklucK66oSXATScpOkqO5R41eCnkYBuyI3NyxYyI//KBdvuceo1dDwD525E78/f3l3XffVSdcJiIiy/h6WX9paSIZGVrVSKdORq/GfQJ2fj5+UlLeMFmKA5oPkDaRbSS/JF8W7lsorsjfx1+V9h44cUBKypjNSY7j68B9EZEBPv1UqxJA37p+/YxeDcG4cdr5unVaWceBAyI5OSIdOmgnZOERuQo/Pz+5/fbbjV4GEZHLvV6WsIzTZrt3nyqHVe+X8o1ekXsE7AJ8AlQfOwSmGmL4xORuk2Xm2pnyw84f5LJul6mvuZro4GhJykmSw1mHpV3jdkYvhzwEM+yI3BiGTMyerV2+9VajV0O6Fi1E+vTRyjratRM5/3yRiy8W6dlTJDpaZM0ao1dIRERE5Hx27dLOu3QxeiXuA0E6BO2KSosabB/jOo5TveDiM+NlY8pGcUU+3j4SERAhBzMOSl5xntHLIQ/BgB2RG/vjD5GDB0UiIkQuv9zo1ZAp0+PRurWWARkSIpKfL7JkiZErI7JNWVmZrFy5Up1wmYiILOPrpf0y7Lp2NXol7iU8sOEmxUKof6gK2sF3O78TV4WAXXZxthzKPGT0UshDMGBH5Mbef187v/ZaLRhEzuP++0VWrRJJTBQ5dEhk/XqRp56qOv2MyBUUFhbK8OHD1QmXiYjIMr5e1h8z7BpGmH+YmoTakFAWC38m/CmpuaniilDKGx0ULQlZCXKi4ITRyyEPwIAdkZs6flzk11+1y7fcYvRqyJyvr8jZZ4vExZ36GvqxAAJ4RERERGRlhp2fn0izZto52SzAN0CkYYbEVmrXqJ30a9ZPyivK5ec9P4urCvEPUQM64jPi1WMhakgM2BG5qYULUXoh0quXSPfuRq+GrMGAHREREZFleXkiCQna5S6RqdpUNR0Cdc2bM2BXR+hh5+3tLWXlDVuqfUnXS9T5T7t/ktLyhs3oa0hNgptIUnaSHM09avRSyM0xYEfkpn4++cHVxIlGr4RsDdglJ4sUN1wbESIiIiKXs3evdh4dXSHRRclVA3Zkt0mxDWl4m+HSKLCRpOWnyerE1eLKgzr8vP1k/4n9Df6ckWdjwI7IDaEtij644MILjV4NWSsmRiQoSJsei952RERERGTWv64TyxAbImCHIFRRWcNNigU/Hz+Z0GmCujx/93xxZdHB0SrwmJydbPRSyI0xYEfkhpYt06aNtmwp0rev0asha3l5sSyWiIiIqMb+dZ0buNmaB/L28laTXB2RLXZRl4vU+d+H/5aUnBRxVT7ePhIZECnxmZwWRw2HATsiF/TbbyIbNtReDovsOgSByHW0baudM2BHREREdAoz7BpWRECEQwJ2cRFxMrDFQKmQCvlx94/iyiICI6SgpEBdrkCJDJGd+dp7g0TUsNatExk7ViQwUOSff0R69qx6fXn5qemw7F/nephhR67Gz89PXn311crLRERkGV8v7ZVhx4BdQwjyC1JBNEe4uMvFsj55vfyy5xe5pd8t4uvtumGJqOAoOSEn5Fj+MWnp39Lo5ZCbcd2fDCIP9fzzp/rUXXaZyMaNIqGhp65fv14kNVUkPFxk2DDDlkl1xIAduRp/f3958MEHjV4GEZHLvV6WcGiC1UpLTw2d6IKSWC2piezcx85LvFSmmFcDl+gMazNMooKiJL0gXVYeWikj240UV37e4OCJg9IkrInqBUhkLyyJJXIhW7aILFwo4u0tEhsrsmePyPTp2pACPcijvw9EFp4/f1+4bMAunu0wiIiIiCrf4xYXaxUmrVux9LChAk8YCuGIslhk1E3sPNEthk/ojucfl8RMTo0j+2LAjsiFvPSSdo7Muu+/1wJ3X3wh0qKFyKRJIt27i6xerb2Zuesuo1dLdcEMO3I1ZWVlsmHDBnXCZSIisoyvl/XvX9e5s/b+txJKi5s1086p3gG7AJ8AhwTs9OETyOhDaWxilusHuiIDI+VAxgHJLMw0einkRhiwI3IRyKZDkA4efVTk7LNF/vc/LYvuyBFt0AQmw55zjsi2bSKDBxu9YqpPwC4lRaSoyOjVENWusLBQBg4cqE64TERElvH1su42bdLO8eF0FQjUNW/OgJ0dILsuxC9Eisoc8wa0WVgzGRyn/cHi6sMnICwgTApLC+XAiQNSXsE+i2QfDNgRuYg339RKXydMODVoAuWwmZkiK1dq2Xdffy2yYoVIx45Gr5bqKjpaJDhYu5zo+h82EhEREdXb4sXa+YgRRq/EvYUHhEtRqeM+Mb6k6yXqHMMnHLnfhtIkpIkkZSdJam6q0UshN8GAHZGLWLtWO7/xxqpfDwoSOfdckUceEbniCrMyAXI56PHLslgiIiIizbFjIhs2aJfH9E7FtA6jl+S2QgNCpazCceXaQ+KGSGxIrGQVZcmKQyvE1WHgBE7IsnNUaTG5N/5pT+Qik7FQEgs9ehi9Gmpobdtq5xw8QURERJ5uyRKtyqRPr3JpXpHMgJ2DJsU6go+3j0zoNEFd/nXvr+IOooOjJS0/TQ5nHTZ6KeQGGLAjcgEHDmiTsVAq2bq10auhhsYMOyIiIqKq5bBjR3FQR0ML8g1y2KRY3fhO49U5hk+4Qympt5e3RAZoAyhyinKMXg65OAbsiFzAzp3aedeuLHn1BAzYEREREWGyrpZhBxeMZsDOERl2ODkyYNcyvKX0b9ZfKqRCFuxdIO4gIjBC8orzZP+J/RxAQfXCP/2JXMB//1UzGYvcEgN2RERERCLr14ucOCESGSkyaAADHw0N2XVBfkEOmxSru7DzhZVlse4S4EJvvsSsRDmSc8TopZAL8zV6AURkfYZdt25Gr4QcGbBjDztyBX5+fjJjxozKy0REZBlfL223aJF2Pnq0iC//cnUIlHMezzvu0H2e1/Y8eWXNK5Kckyybj2yW/s37i6sL8A1Q2Yp70/dKo6BGEuwXbPSSyAXxZY/IBTBg51n0PoWpqSJFRSIBAUaviKh6/v7+8vTTTxu9DCIil3u9LOHwBKsDdmPHmnwRwc5mzbRzsrsQ/xApF8dmuSGwNbr9aJm/e778vOdntwjYQVRQlCRmJ6qpsWc0OUO8vLyMXhK5GJbEErlA747du7XLLIn1DNHRp96DHj1q9GqIiIiIHA8fXG7erF0eM8bkCrxJat6cAbsGgpJYR06KNS+LXR6/XHKLc8UdIEDXJLiJJGQmqMmxRLZiwI7IyR08qGVZBQWdKpUk94YP35o21S4fYdsLcnLl5eXy33//qRMuExGRZXy9tM1vv2nn/fuLxMYavRrPgWw3X29fKSl3bAZo95ju0jayreqft/TgUnGrAKiXl+xL3+fQYR7kHhiwI3KRgROcEOtZ9IAdPl0mcmYFBQVyxhlnqBMuExGRZXy9tM3ixRbKYanBBfkGqaBdUaljB08gqDWh0wR1+Zc9v4g7iQmOkaN5RyUxM9HopZCL4Z//RE6O/es8EwN2RERE5KlKS0WWLNEuX3CB0avxLEZNioULOl4gPl4+sv3YdonPcJ/paz7ePtIosJEcyDggmYWZRi+HXAgDdkROjgE7z4ReysCSWCIiIvI0f/8tkpUlEhUlMmCA0avxzEmxjs6wg+jgaBkcN1hd/nXvr+JOwgPCpbC0UJXGlpWXGb0cchEM2BG5SEksB054FmbYERERkaeXw44eLeLjY/RqPE9oQKiUVRgTVLqwkzZ8YuG+hVJaXiruJDYkVpKyk+Rw9mGjl0IuggE7IidWUnJqQiwz7DwLM+yIiIjIUy1apJ2zHNYYwX7B4u3lLeUVjh+OMrTVUIkMjJT0gnRZl7RO3K3cGJl2e9P3SnZRttHLIRfAgB2RE1u1SqSwUCQ6WqRtW6NXQ47EDDsiIiLyRMnJIlu3YgiBlmFHnjN4Qg9qje2gTRpZsHeBuBsEIwtKClgaS1ZhwI7Iif34o3Y+cSLLATwNM+yIiIjIE+nDJgYO1D60JsfD0AkVsDNg8ASM7zRenf+Z8KdkFWaJu0FpLMpiU3JSjF4KOTlfoxdARJaVl4v89JN2+aKLjF4NGZlhV1GhfcpM5Iz8/PzkgQceqLxMRESW8fXSOtu3a+dDhpzsD5OWJhITY/SyPArKYZEJhn5rRugc1Vk6Nu4o+07sk6UHl8ql3S4Vd4IswhC/EFUa2ziosYT4hxi9JHJSDNgROakNG7SSgLAwkREjjF4NGRWww/vUjAyRxo2NXhGRZf7+/jJz5kyjl0FE5HKvlyX4JU+niY/Xztu1O/lGCOUGkZFGL8vjoNdaSZlx36PIsntz3ZtqWqy7BeygUWAjlWWHoGSv2F7ixU/nyQKWxBI5eTksmu0GBhq9GnK0gACRRo20yyyLJSIiIk8L2J3WvxlZiegZwuxEhw2eEC9UelQYsn/0sfPx8pH/0v6T+IyT3xRuBAG6JiFNJDErUY7k8s0+WcaAHZETwu9FPWDHcljPxcET5ArKy8vl0KFD6oTLRERkGV8vrXsPfOiQdrlNG7MrEahr3pwBOwcG7Px9/KW4rNiQ/aNUdHDcYHV5wT73Gz4B6BMY4BMge47vkfySfKOXQ06IATsiJ7Rrl8jevSid4Dh7T8bBE+QKCgoKpG3btuqEy0REZBlfL2uHNiDZ2dUE7MiQwROFpYWGrWFCpwnqfNG+RW47UTUqKEoyCzNVP7vyCgbyqSoG7Iic0A8/aOfnn6/1sCPPxAw7IiIi8iR6dl1srEhwsNGr8Wy+3r4S5h9maMBuaKuhag1p+Wmy+chmcUd6aWxCZgKnxtJpGLAjcjL5+SKzZmmXr7jC6NWQkZhhR0RERJ6k2v51ZNhghJJy4wZPoCR3ZLuR6vLi/YvFXSGTMcg3SJXG5hbnGr0cciIM2BE5mQ8/FDl2TCsDuPxyo1dDRmKGHREREXliwI7lsM4h2D9YKsSYoRO6MR3GqPNl8cukqLRI3BV69uUU58i+9H0sjaVKDNgROZHCQpFXX9UuP/ooe+p6OmbYERERkSeWxDLDznkGT/h6+UpJmXFZdn2a9pHYkFjJK8mT1YdXi7tCaSweJ6bGJmcnG70cchIM2BE5kU8+EUlJEWnZUmTqVKNXQ0Zjhh0RERF5EpbEOl/ADsMnjOxj5+3lLaPbj1aXf9v/m7gzlADjOUdpbE5RjtHLISfAgB2RkygpEXn5Ze3yww+LBAQYvSIyGgN2RERE5ElYEut8AaTQgFApKDV2qvHYDmPV+erE1ZJddHKMsBuXxqKPHabGuutkXLKerw23JaIGtGaNSGKiSHS0yA03GL0acqaS2IwMrVw6MNDoFRGdztfXV6ZPn155mcjdlJbie9voVZA74OtlzSoqWBLrjKICo+RItrH9WTpGdZT2jdrLgYwDsjx+uUzqMkncWWxorBzOPiwxITHSKqKV0cshAzHDjshJrFypnZ9/vkhQkNGrIWfQqJGIv792+ehRo1dDZFlAQIDMmjVLnXCZyJ1s2iQSEyMyfLhIQoLRqyFXx9fLmmHoWkEBenmJtGKMwmkgw84Z6Fl27jwt1jSzMcQvRPYe38vSWA/HgB2Rk/jzT+383HONXgk5C7xh1ctiOXiCiMjx2T4PPCCSmal9qNarl8g33xi9KiL3L4dt0eLUB5ZkPPRU8/f1N3xCq97HbvORzXI01/0/yWZpLAEDdkROoKhIZN067TIDdmSKfezI2VVUVEhaWpo64TKRu1i6VAvUIXAwcKBIVpbIlCkif/9t9MrIVfH1smYsh3VOyPQK9A00vI9ds7BmamJshVTIkgNLxBPopbFJ2UlGL4UMwoAdkRNYv17rURYbK9K5s9GrIWfsY8cMO3JW+fn50qRJE3XCZSJ3gFjKY49pl9FyDH1mx4zR/v3HH4YujVwYXy9rxgmxzsnH20caBTYydFKsbkyHMR4xLda0NDbMP0z2pO+RrMIso5dDBmDAjsiJymHPOUcrgyQyD9gl8YM1IiKHmTdP618XGqoF7jAfAD1mYcsWo1dH5J4YsHNejYIaSXFZsdHLkJFtR4qvt6/sPbFXDpw4IJ4gMjBSCkoKVGlsaXmp0cshB2PAjsgJsH8dVUfPuNy92+iVEBF5Tlnevfdql++7Txs6Ab17a+f//mvc2og8oSS2TRujV0KWymK9vbylvKLc0HVEBEbIkLgh6vJvBzwjyw6ahjZVZbEJmZx+5GkYsCMyWEmJyNq12mUG7Mhc167a+c6dRq+EiMgzAgbDhmlZzZ06idx//6nr9IAdsoAwiIKIGjDDDm+QU1JOlRv4+Rm6Nk+HwRPoY2f04AnzabFGBxAdBVmFyLTbf2K/ZBRkGL0cciAG7IgMtnEjepqIREWJdOtm9GrI2ejfE/v3ixQbX4lAROS20CsUwbqEBC1Yt2KFSHj4qesbNxZp3Vq7vHWrYcskckvl5SKJiSYZdgjY6Q18mzdnwM4JAnZBfkGGD56Aoa2Gqoy/1NxU2X5su3iK8IBwKSorUv3sWBrrORiwI3Ki/nXe/IkkMy1baj2USku1oB0RETWMp5/WgnUdOmjBOsQIzOlZduxjR2Rfx45pH0zivXCLFkavhsx5eXlJ46DGqpea0ZDpd25rrSxpyX7PmBariw2JlZScFJbGehCGB4gMtnKlds5yWLIEQ0j0sthdu4xeDRGR+5bCfvyxdhnnloJ10KePds4+dkT2dfjwqepXDHkh5xMRECFlFWXiDEZ3GK3O/4j/w6OyzVAai4m9+07sk/T8dKOXQw7AgB2RgZA1tWaNdhllOEQ1lcWyjx05I19fX5k6dao64TKRK3r+ee138siRImefXf3tmGFH9cHXy+rp5bBxcUavhKoT4h+iAkbOECAb1GKQCiCeKDghG1M2iidBaSyOAUpjnaGnoCOk5aVJZqFnNo/lbwoiA23eLJKbK9KokUiPHkavhpwVB0+QMwsICJBPP/3U6GUQ1dnBgyL6t/Azz9R8Wz3D7r//RIqK8P3f8Osj9329LEGfNqqSYdeqldEroeqE+odKkG+QKosNCwgzdC0IHI5sN1Lm7ZonSw4skTNbnimepElwE0nKSVJDKLrFdFMly+6qrLxM9qXvk+bhzdXgDU/DDDsiJ+hfh0/z2b+OasuwY0ksEZH9PfecSFmZyOjRIoMH13xbZP/gQzZk4/FDFCL7B+yYYee8/H38JTww3CkGT8Do9lpZ7IpDK6S4zLMms/l4+0hMcIwcyDighm+4s4zCDHXyVAwREDlBwI7968iaDLvdu7U/KomcSUVFheTl5akTLhO5km+/tT67DpDEwD52VFd8vaweA3auITo4Wk0qdQa9m/aWJiFNJLc4V9YeXiueOLnX39tfdh/fLXnFeeKujuYelZziHPFUDNgRGQSBl7/+0i4zYEc1adtWK7tC+RUaoxM5k/z8fAkNDVUnXCZypbYU06Zplx98UGTQIOvup/ex+/13BGAabn3kfvh6WT0G7FynLFYqtOCz0by9vGVUu1HqMspiPTWAit5ue9P3SnlFubibgpICOZJzxC0fm7UYsCMyyNatItnZIuHhp978E1ni4yPSpYt2mSVYRET1d/y4yKRJIgUFImPHirz0kvX3nTDhVHaenpWHD+G2bRMpLGyY9RK5Ow6dcA0hfiES5BckhaWFTlUWuyphlVtnmVUHveuahjaVhKwEOZx1MurtRtIL0lV2HXoneioG7IgMLocdOlQLyBDVhIMniIjs57PPtIyejh1F5s617fcwprq/8452GQG7yy8XadNGpFcvkWuvbbAlE7ktzN44ckS7zKETzl+GiVN+iXNkiHaJ7iKtwlupMt0/E07+ceWBvQXD/MPU1NiswixxF8jiTMpOUo/PnYdq1IYBOyKDsH8d2YKDJ4iI7AfZcHDNNSKRdRg6d+edIi+8oF3+7juRpCTt8vffaxn0RGS9lBStvNzfXyQmxujVUE0QOIkKinKawRNYz+gOoz26LBYwPRXlo/tO7FNTVd1BVlGWpOene+RkWFMM2BEZoLxcZNUq7TIDdmRLwI4ZdkRE9bdjh3Z+xhl138Zjj4m8/rrIJZdo5bE4Bz2QR0S29a9r2VLEm3+dOr2IwAin6imml8WuS1qn+rl5qtiQWFUWm5yTLO7geN5xNf030DdQPBlfEokM8N9/IhkZIqGhIn37Gr0acqWSWGTYOUGfXyIil4V+c3q2cn0CdnDffSI//CBy2WUiM2ZoX8O/mQ1NZD0OnHAtIf4hqkyxpKxEnEGbyDbSKaqTlFWUybL4ZeKp/Hz81FCQvcf3qsm5rqy0vFSVw4ZiyImHY8COyAAbN2rn/fuL+PkZvRpyBR06aJ865+ae6vNCRES2i4/Xhk0EBoq0a2e/7fboIXLRRdqHKi++aL/tErk7DpxwLQiiYPBEXonzDHkY036MeHpZLDQOaiy5Jbmy5/gely6NRSksSmLDA8LF0zFgR2SAf//Vzvv0MXol5CrQ16VFi6pvbImcgY+Pj1x66aXqhMtErlIOi1YD9v6Wffxx7RyDLA4etO+2yfXx9bLmDDsOnHANvt6+qo+dswyegFHtR6nzf4/8K0dzj4onaxrSVBKzEuVQ5iFxVam5qao/oa+3r3g6BuyIDMCAHdWF/kY2IcHolRCdEhgYKN9//7064TKRJ/Svq06/fiLnn6/1qv3iC/tvn1wbXy8tY0msa2ZyoWzRWTQNbSp9mvaRCqmQ3w/+Lp4MpbEY1LA3fa8czz8urgaB4KN5RyUiIMLopTgFBuyIHAxv4rds0S4zYEe2aN1aO2fAjojIOQN2cPXV2vk337DnKJE1GLBzPShVRB87DAVwFmM6aGWxi/cvFk+H44OS2N1pu6WwtFBcrRw2rzhPQvxCjF6KU2DAjsjBDhzQ+pDhg9UuXYxeDbliwI4lsUREzhuwmzRJJCBAZPduka1bG2YfRO6EATvX7GMX7BfsVGWxI9qOEB8vH5VZdjCDPQliQ2PlWP4x2Ze+Typc5NMjrBNTbgN8AlRJLBkcsFu1apVMmDBBmjdvrg7ITz/9VOX6p59+Wrp06SIhISHSqFEjGTlypPzzzz+nbWfhwoUyaNAgCQoKUrebhHdKJ6Wnp8uYMWPUPgICAiQuLk7uuOMOyc7OrnV9NW2XqL7lsGhO7cuyfLIBS2LJGeXl5anf4TjhMpEzKy4W2bOnYQN24eEi48Zpl7/+umH2Qa6Jr5eny88XOX7cQsAOU9maNeN0Nifl4+0jMSExKhPKWaAMdHDcYHX5t/2/iafz9vKW2JBYFbxEEMwVZBdlqwy7iECWwzpFwA6/qHr16iWzZs2yeH2nTp3k3Xffle3bt8vq1aulTZs2MmrUKElLS6u8zbx58+Saa66RadOmydatW2XNmjVy5ZVXVl7v7e0tEydOlF9++UX27t0rn376qfzxxx9y66231ri22rZLVFfsX0d1xZJYIqL62btXpLRUC6q1bNlw+5kyRTtnWSxRzZKStPPQUJHISJMrEKhr3pwBOyfWKLCRlFU41yRSvSwW02JdJausIQX6BkqQb5AqjUUwzNmh5x7KrLFu0hia3zN27Fh1qo55gOyNN96QOXPmyLZt22TEiBFSWloqd999t8ycOVNuuOGGytt1w9ivk5AZd9ttt1X+u3Xr1jJ9+nR1n+pYs12iumLAjuqKJbFERPYrh23Iahtk2CEAgdfrv/8WGawlfRBRDeWwXqUlIkjMiIlhoM4FhAWESYBvgBSVFqlzZ3Bu63NVgAoZZduPbZeesT3F00UFR0lSdpLsPr5bDebAUApnhJ57WCd711XlMgV5xcXF8sEHH0hERITKyoPNmzdLcnKyyqLr06ePpKamSu/evVWg7Yxq6hxSUlJk/vz5cu6551a7r7psF4qKitRJp5fdlpSUqJM70B+HuzweR8MHPf/+ix87L+nRo1RKSpzvkx8eY+eFyhARP8nKQvlIiUTUMVucx9j9OfIYm+7DnX7fOTv+HNfNtm0oLvGRbt3KpKSkvMH2g5YXF17oI3PnestXX5XJgAG274vH2P2Yv17qPZo8+RgfOoTnwFdatiyXkoICkeRkLdrtJtz55zjAK0CCvYMlrzBP/IKcIwjk7+Uvw1oPk8UHFsuS/UvkjOgG6n1gorysvMq5M2oS1ESSMpIkxCdEOjbu6JT94dIL0iUzP1OahDQ5/bksEykrLTPs58jeP8e2bMfpA3YLFiyQK664QvLz86VZs2aydOlSiY6OVtcdPHiwstcdsu9QMvv666/LsGHDVPlr48aNK7czZcoU+fnnn6WgoED1zfvoo4+q3act2zX10ksvyTPPPHPa13///XcJDg4Wd4LjQLY7cSJQjh0bLd7eFZKc/JssWuRcaeSmeIydU1jYWMnJ8ZevvkKbgPqltvMYuz9HHOPCwlPTx5YsWSKBmKhDDsOfY9ssXz4QH3+IyH+yaFF8g+6rVaumIjJIFizIk1GjVtR5OzzG7qO610tPPsbLlnUSka5SUXFYFq3Yon0xJUXcjbsf43xxnuETfcr7yGJZLMv3LZcr/K5wWHAqdWuqODMf8ZH9B/YL/nNmx+TYaV/zEi/ZsX+H4D93+DlGbMtaXhVOUtyNH6Qff/zxtMEO6HN35MgROX78uHz44YeyfPlyNXiiSZMmMnfuXLnqqqtk9uzZcvPNN6vbI8OtZcuW8vzzz8stt9xSuR1kyWVmZqqA26OPPqoy7N577z2La7Flu7Vl2GHIBdYejmYpbgDRYHyjnn/++eLHVHWbLVrkJZMm+UrXrhWydWupOCMeY+c2cKCvbNmC18tSGTeubi/fPMbuz5HHGL+n0X4CMjIy1KAoanj8Oa6bbt18Zf9+L/n991IZNqxh3wKj32jHjn7i51chmf/f3n3AR1GmfwD/JZteSS/03jsIijQFFBDEgvWPiliw3HnWU08OvVO5s93Zu1jOrohIUSnSFKUovfeW0Fv6Jtn/55mXTYEEUnb3nZ35fe/2M0Oy2bxxspPdZ55ytLDaFX48xtZz6vkyJCTE9sd47FgH3nsvEOPGFWHcA9lqKkzLlkB4OKzA6s/jzKxMLN2zFHVj6pomayuvMA+DPhlkbD8c/iFaJbby6veTbDAJ1qV2TEWgQ+uIgLOSgQ5BgUHokt4F0SHRMAvpW7do1yJjv6KBE3uO70H7lPZoEHtyAp+fP48lTiRJaMeOHTtrnMj0GXbywr9Zs2bGrWfPnmjevLnRx06CbpJxd2pvOZkE26RJE+w8pclTamqqcZOps5Ih17t3b4wbN67kMcqqzuOWJfeR26nkoFrtBG3Fn8kXVq1S2y5dAkz/34/H2JwaNQKWL5eKkaBat3fhMbY+Xxzjso/P3ynf43/zqpNrqlu2qP0OHWp/Dj2bpk1VZV9WVgC2bw9GTVsh8xhbR2XnSzsfY6mAFY0bOxAsteSBgaqm3GL/Pax6jOMi4xAeFg4nnAhzmCPDPsIRgXPrnYuftv+EebvmoU2Kb/rQS7DO7AG7pOgko0/cpiOb0CWti2n62R3MO4isoizUja5rTLc9jQNwBDm0P4c89TyuzmOY+zeqAsXFxSVZbF27djUCZBvkSkyZ6Of27duN4RJnegxRNhuurJo+LtHZSKBFcOAE1VSDkxeWOCmWzMLhcGDIkCHGTfaJzEquuUpdiXQpSU72/veTZJO2bdX+mjXe/35kfjxfnnnoBPkfGRAQFRyFrIIsmEm/Rv2M7dztc3UvxXRSo1Kx98RebD2i2oCZwb7sfQiU/1UUrLM5rRl2WVlZ2Ly5tIZ627ZtWL58uZEBl5CQgKeeegrDhw83Mt6krPTVV181hkGMHDnSuL+kD44dOxbjx483Sk8lmOae/uq+z/Tp07Fv3z50794dUVFRWLNmDR588EH06tXL6E0nFi9ejBtuuAGzZ89G3bp1q/S4RDWxbp3anmF2CdEZcVIsmY30YJo2bZruZRCd1fbtatu4sXcnxJYlAbvfflPTafkSkk49X1pxEEF1MWDn36QMNiUqBWv2m+uqRO8GveEIcGDLkS3YdWwX6sfyF8xNSmLjw+Ox6dAmo/xUAng6ZRdkGwG7ikphSXPAbunSpejfv3/Jv++77z5je+ONN+KNN97A+vXr8cEHHxjBOgngSdBtwYIFaOu+XAkYgbSgoCCMGjXKGCjRo0cPo8+duz9EeHi40fvu3nvvNTLqJAB3+eWX4+GHHy7X9E+y6cr+0Tzb4xJVV1ER4I5Pt5D+ukS1CNgxw46IqGYBu5PXa32CGXZElZOp9ydOqH0G7PyXO9BS7Co2TYZUTGgMuqZ3xeI9izF3x1yM6jBK95JMJSokCjnOHCPQKlmS0aHRWqfDStAuISZB2xrMTGvATqaunmnmxaRJk6pU//vcc88Zt4pIQPCXX36p9jrO9rhE1SUZUQUF0uuwtKyRqLpYEktE5D8BO3dGPQN2RKdzVwvEx6tSdRMNGqVqkOEFESERRgBIAkFm0a9hPyNg99O2nxiwq0BSRBL2nNiDNQfWGP3sQhwhPl+DxGCkPFf6H5plaInZmCMETmQDGzeqbbNm0sNE92rI3zPsMjJUA3UiM0w9lAFRcpN9IrPSmWG3aRPP2cTzZWXlsLyQ7d/Cg8ONjDYJ2JlJ/0b9EYAArNy/0ggKUXkSIHP3s9twcIORIelrx/KPGZNrWQ5bOQbsiHzEPcOE5bBUG0lJ0gNH7e/erXs1RKWtJeRGZGbbtvk+YJeeDtSpo9pilJllRjbG82Up9q+zjpTIFOQV5sFMkiKT0C29m7H//ebvdS/HtP3s5NjJAIrtR05e1fKhg9kHUVBUgLAgc0wYNiMG7Ih8nGHHgB3VhmSLsyyWiKzsvfeAli3VsAZ/z7ArOylWBk8QUSkG7KxDMuwCAwNRWFwIM7m42cUlAbszteKyMwmWSVnzuoPrkJmV6bPvK78rUpIrPfSocgzYEfkIA3bkKZwUS0RWJQM0b71V/c28/37pb+OZx83LU60E3FNifYmDJ4gqxoCddcjQgqhgNcjATC5sfKHRm23r0a3YePjkmzE6jZSkysAQGUJxLO+YT77nkdwjRkksy2HPjAE7Ih8H7CRrgKg2OCmWiMxEBirJtMfaWrECuOYaoPhkG52ffwbmzoVHuC9wREWpBve+xMETRGd+XjJg5/8kKJYYkYisgiyYiQzBOL/B+cY+y2LPLDkyGVnOLGMIhS/Km/dn7zeyHqUslyrHgB2RD+Tmlr4oYYYd1RZLYonILCZPVhcR5LZyZc0fJysLGDZMbS+4ALjtNvXxJ5/0fP86Xw+iY0ksUcU4dMJaEiISTFcSK4Y0G2Jsf9jyA4qKi3Qvx9TSItOMstj1B9d79b9VfmG+8X2kFJfOjAE7Ih/YvFmV9Ujj6cRE3ashf8eSWCLSTYYojBoFXHYZkJmpMuxGjgROnKjZ482Zo96816sHfPUV8Le/AcHB6uO//OKf/etODdht3SoDB3z//YnMSF4Xu4dnMcPOGmJDY41+aLnOXJjJefXPMwJDktH1e8bvupdjao5AB1IjU7HtyDbj5i2Hcg/hRP4Jo5SazowBOyIf96/z9ZV9sh6WxJKZSJPpvn37GjfZJ3v4/nvgf/8DHA7ggQdUoE3+1klmXE36zi1cqLZDhgBxcSrj5sYb1cf++U//DtglJ6uLdfLfZd06339/Mg+eL0sdOADk56vXxXXr6l4Near8VPqRZTuzYbZy3QFNBpRk2dGZhQaFIj483siy23N8j1e+R+aJTKMUVvrm0ZnxvxCRD7B/HXkrw87d64lIl/DwcMydO9e4yT7Zw7x5ajt6NPDss8DnnwNBQcBnnwFvv13zgN35qtWQ4eGHS4OD7kwcfwzYSUCiTRu1v369778/mQfPl6eXw6amqmxa8n8BAQFIjUo1XYaduKjpRcZ2zvY5cBY5dS/HL4KvEuhcvX81DmQf8OhjS5/DAzkHjMnCdHYM2BH5ACfEkifJlWi5MC+N3vfv170aIrKjBQvUtndvtT3vPGDCBLX/6KPVK42VPq9Ll6r9Xr1KP960aWkA74svPNPDztcTYt2aNCm/DiK748AJ65bFSvao2XrZdU7tbAzFOJ5/HIt2L9K9HL/qSbhy30oczTvqscc9nHvYyMKMDIn02GNaGQN2RD6wYYPaMmBHniBXotPT1T7LYonI16QPmzvA5g7Yib/8Rf2dO3QIePnl079OMoJlqMSpliwBnE4gLe30gNrVV6utZPD5a4adcP9cDNgRnWHghLzAkRMBU+78lpTESnaW2abFSm+2gU0GGvssi626lMgUI7i2at8qZBfUvtRZpsJKmW14kL0zjKuDATsiH2CGHXka+9iRWWRnZyMpKcm4yT5Z32+/AYWFKtu3bABMSmLHj1f7zz2nBlG4HT8O9O2r+rmdOk22bDnsqX1er7xSZRQvXlzzYJdk8O3bpzdg5/6+7sAh2RPPl6cH7Mpl2LmvSDJg57ekL1lyZLLpAnZly2Ln7ZhnyrJds5Y5p0Wl4WDOQaM8Vqa71sax/GNGhh3LYauOATsiL5NMA7mJ5s11r4aswn1FmpNiyQwOHjxo3Mh+5bCnBtgkI651a+DIEeCll9THpDx28GAVmJPgmUyAPVv/Ojfpb9WvX+3KYt0XNqKj1UALHZhhR248X54hYEeWkBCeYGRSyc1M2ia1Rb2YesgrzMP8nfN1L8dvyGCI9Oh07DmxB+sOrkNRcVGNH+tQziEUFBUY04SpahiwI/KyTZvUViboRbJUnzyEGXZEZJb+dWXJ1Fh3lp30tOvfH+jZE/jlF6BOHfX5qVNVlp4oKlKfqyxgV7YsVgZa1IQ7SCZZbromtbsDdhKkkOxEIrsrF7CTmvi9e9WWLFEWGx4SjhxnDsyWLTaoySBjn2Wx1c+cTI1MxbYj24zpsTUJ2snX7D6+G5HBfENcHQzYEfkoYNesme6VkJUwYEdEOkiwadGiygN2YuRIoEsXlU03dy6wdq0K1s2aBYwape4zbpzarlmjSmejooAOHSp+vMsvV4G+5ctLW0z4U/864W7LJf/99uzRtw4is9i6tczrGQnUZWQwYGcREcERiAuLM3VZ7C+7fvHoIAU7CA0KNcqdNx7aiE2HN6HYVVytrz+Sd8QoiZWALlUdA3ZEXrZli9oyYEeexJJYItLhjz+kD5cqLW3btuL7SM85CdTNmQN8/DHwyivAsmVA167A3/+uet3NnKky5txZc5KFJx+vSGIiMFD1CsdHH1V/zRLo0x2wk4Cj+0ILy2LJ7g4fBjIz1b6U0JM1hxXkF9Wu35k3NI1vihYJLYzpp7O2ztK9HL8jpawybVey7DYd2lStsmfpg1dcXGxk61HVMWBH5KOAXdOmuldCVsIMOyLSWQ4r5asSmKuM9IuTctjrrgPuugto0qS0NHTMGLV/7bWqbFb06nXm7zt6tNq++abK3Kuq9euB995T+5dcAq3cZbEcPEF2J5m17tcykl1L1iNZVCGOkFoPKfCGoc2HGtvpm6brXorfZlDGh8UbQbsth7dUKWgnfetkOmx0aLRP1mglDNgRednmzWrLgB15I8Pu6FE1fZGISHf/uqqSLLuWLVXmnAxjGjAAuPnmM3+NlMXKee/AAZW1VxXyHuJPf1JlqMOGAYNU6yJt3Bl+zLAju3MH7CrL0iX/J1NA5WbWslgZpLBy/0rsPMZSlZqIDIlEnbA6WHNgDbYe2XrWoJ0MmzhRcILTYWuAATsiL2NJLHlD2WmHLIslnQIDA9GtWzfjJvtkXfJ6/Ndfq5YRdybp6SrzTYJv0pNOymPdFyEqI+Wy99yj9l94Qa3lbL75RvXNCw0F/vMfaMdJscTzpcKAnfVJQCw1KtV0gyeElHT2rNvT2J+xeYbu5fitqJAoxIbGGkE7GUZxpqBdZlYmHAEO4/eCqof/xYi86MQJ9YZEMMOOPI1lsWQG4eHhWLJkiXGTfbIuGZYgfaekH1unTr7//lJKKxcr1q0DfjjLgL+cHODee9X+Qw+Z428wS2KJ58vyAbs2bXSvhLxJMrBkMmtNJop625DmQ0rKYqvTh43KkxLX6JBorD6wutJsRcmy3J+93wjuUfUxYEfkg+w6KfuJYQYweRgDdkTkS0uXqm27dkBEhO+/f2wscMstav/5589833/9S2UfS+beww/DFFgSS6Qww84+fewkCyvbmQ2z6deon9GLbc+JPVixb4Xu5fg1KXONDI7Eqn2rKgzaSTms/A5IGS1VHwN2RF7E/nXki4AdS2KJyBeWLFHbbt30reHPf1bDLqTU1T1MoqKLZc88o/alFFZHcPFMGXaSqZhvvj7sRD5x8CCwf7/a54RYa5OhE1J+asY+djLt9MLGFxr70zZN070cS2RThgeHY0XmCmw9XNrTrthVbARFI4JM8ofYDzFgR+RF7F9H3uTu+cQMO9IpJycHjRo1Mm6yT9bPsOveXW+WmgytELffDsyde/p9pBRWAmIDBwKXXQbTSE6WkkjVf2/XLt2rIR14vizNrpPnMifEWl9CRAIKiwthRoObDTa2s7fNNqaYUu2DdpJRuWr/Kmw8tNEog5XedodzDhvZllQzDNgR+SBgxww78gaWxJIZyFXUHTt2GDf2gbEuObTugJ3ODDshAbtrrlHTX6+4Ati0qfRzU6cC332nhlS89BIQEADTkLWwLNbeeL5kOazdSH8zybTLLzRfWnHXtK5IikjC8fzj+GXXL7qXY5ny2LiwOGMQxaJdi7By30oEO4KN3wGqGQbsiLyIATvyJpbEEpGvSIDp8GEgJARo315/4EvKYXv0UGu65BLgyBHVhuKGG9R9/vIXoFUrmA4HT5DdMWBnv6EEZu1j5wh04OJmFxv70zdP170cy5BedQ1iGqBeTD00iG1glEVTzTFgR+RFDNiRL0pi9+4FCpjJT0Q+6F/XsaMK2ukmpaWTJ6vz4MaNKtNu2DAVuDvnHOAf/4ApuQN2zLAju2LAzl4CAwKREpWCHKc5S8DdAbuFOxfiRP4J3cuxDJkOTJ4RVJU7rVy5Eu3atUNgYKCxfyYdOnTw0NKI/Jv0z3FnPrGHHXmzH1JursrWaNFC94qIyKrMUg5bVmqqKn/t1Qv46Sf1sXr1VCBPzo1mxJJYsru1a9WWATt79TaT4QNSBm62QE6L+BZoEtcEW49sNXrZjWg1QveSiKofsOvUqRMyMzORnJxs7MsTrWzfBfe/ZVtUVFSVhySyPAmgyNMkMlIFVog8TV7zSGna4sXA8uUM2BGR9zPsdA6cqIhcJ/7sM2D4cCAsDJgyBUhLg2mxJJbs7MABdZPXL5wQa6++ZhHBEcgtzDW2ZiLxiyHNhuCVJa9gxuYZDNiRfwbstm3bhqSkpJJ9IqpeOazJLiaRhXTurAJ2v/8OXHWV7tUQkRUVFwPLlpkvw85t6FCpBlETJ929Pc3KnWHHgB3ZuRxWAtcR5orbkBeFB4UjNjQWR/OOmi5g5y6LlYDd7xm/I+NEBtKiTXzVh2ynSgG7hmVe/ZTdJ6LKsX8d+UKXLmr7xx+6V0J2JVen27RpU7JP1rNhA5CVpd5gmzUrxl/K66RkV+zbp6bcyjRbsg+7ny/d5bAn/xOQTcjvenJUMjKzMmFGqVGp6J7eHUv2LsHUTVNxa5dbdS+JqOZDJz744ANMmzat5N8PPfQQ6tSpg/POO88YUU5EikyrE+xfR97OsBOSYVemUwGRz0RERGDNmjXGTfbJen77TW07dWKAqbakYMXhUOfrTHO+dyUvsvv5UgbECDNOcCbvkgw76YdfWFwIMxrWYpix/W7Dd0a/PSK/Ddg9/fTTCD/ZyXfRokV45ZVX8MwzzyAxMRH33nuvN9ZI5JeYYUe+ID3s5M3fwYPAnj26V0NEVvTjj2rbr5/ulfi/wMDSHnsy4ZvIjgG75s11r4R8LTYsFlEhUcgqyIIZXdD4AkQGR2Jv1l6jNJbIbwN2u3btQrOTKUOTJ0/GlVdeidtuuw0TJkzAggULvLFGIr+0davaMmBH3iRN1t2lJSyLJSJPk1li7oDdxRfrXo011K2rtgzYkd1s2qS2pw3JCg5WkWzZkiUFBQYhJTIFWU5zBuzCgsIwqOkgY3/Khim6l0NU84BdVFQUDh06ZOz/+OOPGDhwoLEfFhaG3Nzc6j4ckSVJqYu7QtzdYJrIF2WxRL6Wk5ODtm3bGjfZJ2uR84q87IuJAXr21L0aa0hPV1sG7OzHzudLp1OGF1aSYSeBOnliMGBnaQkRCXC5XMbNjIa3GG5sZ2+bbdpMQLKfagfsJEB3yy23GLeNGzdiyJAhxselFwMHUhAphw/Li7LyDaaJvB2wY4Yd6SAvvNeuXWvczPoinGru++/VdsAAvpf2FAbs7MvO50sJ1knGrrTucz8HyH597GRKbLYzG2bULrkdGtVphPyifMzcOlP3cohqFrB78MEH0aNHDxw4cABff/01EhISjI8vW7YM119/fXUfjsiSdu1S2+RkVbJI5ItJscywIyJvBewuukj3SqyDATuye/86Gw7IJQDhweGID483bfaaTLN1Z9mxLJbMotqzvrp27YqMjAwkSySijD/96U9ISUnBo48+6sn1EfmlnTvVtkED3SshO5DJje5AsZSunbyOQkRUK0eOAL/+qvYZsPN8wI6DgsiO/es4cMLekiOTsevYycwGExrSfAheXfIqVu1fhS2Ht6BpPJuRk59l2En6tkSfT5WdnW30sSMiBuzIt6S31MlZQCyLJaLTgm41bZU1axZQXAy0bg2w64nncOgE2dFpAyekqZ08CWRLtlEnrA5Cg0KRV5gHM0qMSETvBr2N/W83fKt7OURVz7C77777jK0E68aNG4cIaUBwUlFREX777Td0cqd5ENkcA3ako4/d5s2qLFZ6TRERzZ0LXHIJEBsLLFgANGlSva//4Qe15XRYz2JJLNm9JNYggbqMDKBOHTbItJGokCjEhMQguyDbmMxqRiNajcDcHXMxffN03H3O3QhxhOheEtlYlTPs/vjjD+MmGXarVq0q+bfc1q9fj44dO+L999/37mqJ/AQDdqRr8MRPP+leCRGZwbx5wNChUgGhAkODBgH79lX966Vc86uv1D4Ddt4J2MmAqjxzJpkQeT/DjmwpMCAQKVEpyHGad0pyz3o9kRSRhKN5RzF/x3zdyyGbq3KG3U8n3wWOHj0aL774ImKkBouIzjh0on593Sshu7jsMuCxx1SD+IULgfPP170isgvJvHdPia+oZQb53pIlKlgnpbADB6o3ylu2AEOGqKD+2V7CyfDKW28Fjh0DzjkHuPBCX63cHiShSLrISLBOEowaN9a9IvIVu54vc3NLL2azhx1JWaz8/hcVF8ER6IDZBAUGYViLYXhv+XtGWeyAJixdIT/qYTdx4kQG64jOghl25GutWgG33KL2H3xQveEm8gVpkbF9+3bjVrZdBunz7LMqs07K46dMAX78EUhKUiXzcn44m4kTgRkzgNBQQIonHOZ7P+XXJE7DwRP2ZNfzpVwwcAerExN1r4Z0iwmNQWRwpKmz7Ia3VNNif939KzKzMnUvh2ys2gE7Ijozdw9dwYAd+dITTwCRkWqqo7uUjYjsRYL1kmUrxo1TmVyS0fLll+pj77wDrFtX+ddv2wbce6/af/JJNXCCPI+DJ8iu/etslFhIlZChE/Hh8ch2ZsOs6sXUQ7e0bnDBhe82fqd7OWRjDNgReZi8+JapeiEhQHKy7tWQnaSmAg88oPYffhgoKNC9IiLyNQm4SZml9HDv3r304337AiNGqL9Pcn6oyPbtwAUXAMePA+eeWxq4I8/j4AmyE/avo1MlRSahoMjcL1QvbXWpsf1uw3codhXrXg7ZFAN2RF4qh5X+dYF8hpGPScAuJQXYuhWYPFn3asgOcnNz0b17d+Mm+6TXzz+rbdeuQHh4+c9NmKDKW6VMdv7804N1/fqpbbNmwBdfsBTWmxiwsye7ni/dATv2r6OyZbEyfTW/MB9m1b9Rf2Oq7d6svViyd4nu5ZBNMZxA5MWAHZGvRUUBt92m9t98U/dqyA6Ki4uxdOlS4yb7pJe7HLaiwTPS61KGSYj77lON4EVmJtC/P7Bjh3pDPXcuUK+eDxdtQwzY2ZNdz5dlS2KJRHRotHHLKsiCWYUFheHipmpMugyfINKBATsiL02IZf860mXMGNUjZs6c0qvaRGSvDLtevSr+/PjxQHQ0sGwZcOmlwIEDaqKsZNY1baqCde7+auQ9HDpBdsKSWDpVYEAgUiJTkFto7kzTS1uqsti52+fiWN4x3cshG2LAjsjDOCGWdGvYELj44tIG80RkD4cPA2vWnDlgJ70up05VA2pmzgSaNFHTY2WK7A8/lAaSyLs4dILsQjJ5JYtXyEUBIre48Dhja+b+cK0SW6FFfAuj396MzTN0L4dsiAE7Ig9jwI7M4Pbb1XbiRA6fILKLRYvUtmVLFYCrTJ8+wIwZKmiXlaV63UkQj2+mfYclsWQX7izSiAigTh3dqyGz9bGLCI5AjjMHZhUQEIDhLYcb+9+s/wYuGcVO5EMM2BF5GAN2ZAZS4iZvCKXcjcMniOzVv66y7LqyevdWGXbDh6shFOec4/XlURlpaWorAdMTJ3Svhsj7ATvJKpV2HURle8QlhCeYuo+dGNp8KEIdodhyZAtW7FuhezlkMwzYEXkYh06QGQQFqV52gsMniOzVv66igRMVOfdc4NtvgQEDvLosqmRAUEyM2meWHVnZ7t1qy0E2VJHEyETkF5l3UqyQ4RgXNb3I2P963de6l0M2w4AdkQcdPw4cO9mPlAE70o3DJ8hXEhMTjRvpk58PLF5c9Qw70o997OzJbufLshl2RKeKDY01stfyC80dtLuyzZXGdtbWWTiSe0T3cshGGLAj8sKE2Lg4NYWPSPfwicGD1f7bb+teDVlVZGQkDhw4YNxkn/RYvVoF7RISgObNda+GqoKTYu3HjudL9+83M+yosuw1uZm9LLZNUhu0SWwDZ7ET3238TvdyyEYYsCPyIPavI7O57bbS4RPyZp6IrGntWrVt1459ovyFO+OIATuyQ0ksM+yoIoEBgUiJTEFuYS7M7oo2VxjbSesnmXqyLVkLA3ZEHrRli9o2aqR7JUTlh08cPKh6VRGRNa1fr7atW+teCVWVO+PIHdAgsiKWxNLZxIXHGVuzB8Gkj11USBR2H9+N33b/pns5ZBMM2BF5kLtPGMuRyCw4fIK8LTc3F/369TNusk96rFuntgzY+Q8G7OzHjufLSktig4PVuGTZkq3FhMYgIjgCOc4cmH2q7SXNLzH2v1r3le7lkE0wYEfkQQzYkRndckvp8ImtW3WvhqymuLgY8+bNM26yT3owYOd/GLCzH7udL4uKgIyMSjLsJFAnJQAM2NmeBMLiw+NN38dOXNFalcUu2LkAmVmZupdDNsCAHZEHMWBHZiQ9Ffv0UfszZ+peDRF5mtMJbN6s9hmw8x/uAAYDdmRV+/apoJ3DAaSk6F4NmVliRCIKigpgdo3jGqNrWlejfHfy+sm6l0M2wIAdkQffMG3bpvYZsCOz6ddPbefN070SIvI0CdYVFqrp5OwT5X8ZdhLUKDD/+1SianMHo6XyVYJ2RGcqiw0ODIazyAmzu7L1lcZ28obJKCwu1L0csjgG7Ig8ZPt2dRUxIkJl+BOZSd++pQE7l0v3aojIG+WwrVpxQqw/SUwEQkLUOdldNkhkJRw4QVUVHRqNyJBIZDuzYXb9GvVDQngCDuYcxNztc3UvhyyOATsiD5fDNmsGBPKZRSbTo4dqE7N3L/vYEVk5YEf+Q14rsCyWbDlwgugUQYFBSIpM8os+dsGOYAxvOdzY/2LtF7qXQxbHsAKRh2zcqLYshyUzkszPc85R+wsWMAWHyErWr1db9q/zPxw8QVbm/r0ul2EnPWTk6qFsicqQwRPSG84fyPAJR4ADv2f8jk2HT2ZtEHkBA3ZEHsKBE+QvZbHz5/PUT54VERFh3EgPToj1/4CdOxOJrM9O58sKS2IlUCc14AzY0SmiQ6KNibF5hXkwu9SoVPRv1N/Y/3zt57qXQxbGd21EHsKAHZmde1LswoXMsCPPiYyMRHZ2tnGTffKt4mJm2PkzZtjZi93OlyyJpeqICokygnb+UBYrrml3jbH9YcsPOF54XPdyyKIYsCPyEAbsyOzOO09Nadu+PQAHDoTrXg4ReYAEerKzVY/Kpk11r4aqiwE7sl1JLFElAgICkBKVglxnLvxBx5SOaJ3YGvlF+fjx0I+6l0MWxYAdkQfk5wM7d6p9BuzIrKKjga5d1f7q1Qm6l0NEZ3DoEDBzppo+fibr1weU/O0JCvLN2shzOHSCrEqmH3NKLFVXbFisEbjzh152ss6r215t7M84OAOFxYW6l0QWxIAdkQfI1E0pS4qKAlJSdK+G6Ox97NauZcCOPCMvLw9Dhw41brJPtZeTA/TqBQwaBPTuLc/XswfsWA7rn5hhZy92Ol8eParOZYIBO6qqmNAYRARHIMd58pfH5AY1HWQMyzjkPITZ22brXg5ZEAN2RB4uhw1gezAysfPPV9sNG+J1L4UsoqioCNOnTzdusk+198AD8hxV+4sWAZ07A+PHl775LZvB8vXX6o9Ou3YaFkoeC9jJ0Ew+fazPTudLd3ZdfDwQzi4cVEUydCIuPM5v+tiFOEIwsvVIY//j1R/DJX+YiTyIATsiD2D/OvIXbdqobWZmpJEVSkTmMm0a8Prrav+DD4ChQ4GCAuAf/wBatgQ+/lgF6sT8+XWxaFEgZODkLbdoXTbVUGqq6i0qsZt9+3SvhshzOHCCaiopIgkFRQXwF1e0ugIhASFYf2g9lmUs070cshgG7Ig8GLBr0UL3SojOrFEj6XPlQkGBo+TFNBGZw5EjwM03q/177wVuuAH47jvgiy+Ahg1V2eT//Z/6uPS4+/DDtsZ9H32Ub4r9lQTr0tLUPstiyUo4cIJqUxYbHBgMZ5ET/qBOWB1cEH+Bsf/xqo91L4cshgE7Ig9ghh35C2lKL0E7sXkz67eJzGTGDGD/fqBZM+Dpp9XHpM3CyJHSqw745z9VgOd//5Ns2SAcOhSOxo1duP9+3Sun2mAfO7IiDpygmooOjUZkSCSyndnwF8OThyMAAViwcwG2HdmmezlkIQzYEXkAA3bkT1q0UPV0DNgRmcvPP6vtJZcAYWHlPyf/fuwx4McfVU+oI0fU8/ff/y467b7kXxiwIytiSSzVVFBgEJIik/ymj51ID01HnwZ9jH1m2ZEnMWBHVEtZWcCuXWpf+gsRmV2zZq5ygWYiMoeFC8sPh6nIBRcAixcDAwcWY8iQrbj0Uja49ncM2JEVsSSWakMmr7rkf340xOH6dtcb2xmbZ+Bo3lHdyyGLYMCOqJbck/ySk1XWA5HZSbmd2LSJGXZEZnHsGLBqldrv1evM923aVIZTFOG221ZxMrkFuAMaDNiRlbAklmrbx04mxuYV5sFfdEzpiJYJLZFflI/J6yfrXg5ZBAN2RLW0bp3atm6teyVE1cuwY0kseUJkZKRxBVxusk818+uvavqrBONkcijZBzPs7MNO50uWxFJtRAZHGkE7f+pjFxAQgGvaXWPsf7XuKxQWF+peElkAA3ZEHgrYtWqleyVE1QvYbdsGFBXpXg0RlS2HPVt2HVmPO6DByd1kFXl5wMGDap8ZdlTT4FdyRLJfZdiJQU0GGVNjM7MysWDHAt3LIQtgwI6olphhR/6mfn2ZFluEgoIA7NypezVEVHbgxJn615E1NWigttIP1+nUvRqi2tu7V23Dw4G4ON2rIX8VExZjbItdxfAXoUGhuKzVZcb+52s+170csgAG7Ihqaf16tWXAjvyFwyEldznG/saNuldD/i4vLw8jR440brJP1SdBGimJFcyws2eGXVSU+j3gOdna7HK+LDtw4rQ+m8HBQFqa2hKdgZTERgRHIMepXrP6iytbXwlHgANLM5Ziw6GTzc6J/DFgN3/+fAwbNgzp6elG2uvkyeWbMz7++ONo1aqV0eMhLi4OAwYMwG+//Xba40ybNg09evRAeHi4cb8RI0aUfO7QoUO4+OKLje8RGhqK+vXr4+6778bx48ertMb8/Hx06tTJWN/y5cs98FOTlciLa/ekTQbsyJ+kp2cZW06KpdoqKirCV199Zdxkn6pPXl7k5qpMFLZXsJ/AQKBdO7W/erXu1ZA32eV8ecaBExKoS09nwI7OSoZOxIXHIatAvWb1FylRKRjQZICx//7y93Uvh/yc1oBddnY2OnbsiFdffbXCz7do0QKvvPIKVq1ahYULF6JRo0YYNGgQDhw4UHKfr7/+GqNGjcLo0aOxYsUK/Pzzz7juuutKPh8YGIhLL70UU6ZMwcaNG/H+++9j1qxZGDt2bJXW+NBDDxnBPqKKbNkCFBZKE2E21SX/woAdkTn710nwhuzHHbBzTwom8mccOEGekhSRhIKiAvib0Z1GG9tZW2dh+9HtupdDfixI5zcfPHiwcatM2cCbeOGFF/Duu+9i5cqVuPDCC1FYWIh77rkHzz77LMaMGVNyvzZt2pTsS8bdHXfcUfLvhg0b4s477zS+5mxmzJiBH3/80QgKyj5RZeWwkhFxWso/kYmlpampWwzYEZmnfx3LYe2rfXu1ZcCOrFYSS1TbstigwCBj4qps/UWz+Gbo07AP5u+Yjw9WfIDxfcfrXhL5Kb/5rS8oKMBbb72F2NhYIytP/P7779izZ4+RRde5c2dkZmYa5asSjGvnvlR5ir1792LSpEno27fvGb/fvn37cOuttxpluhEREVUun5Wbm7vs1ul0GjcrcP8cVvl5amv1akmFcKBly2I4ndYobeAxtj45tunp7oCdC04nx85bjS+fx2W/h5X+3vnSkiXyciwA3bsXwulUU5zPhudqa2ndWq76BWHVqtJzMo+x9Zx6vpSWO6d+3Ap27XIYhVypqUVwOv1nYIA38HlcO2GBYYhwROBE7gnEhsXCjIqListt3UZ3GG0E7KZvmo5bOt2CtKg0TSu0gCKgqLBI2/PI08/j6jyO6QN2U6dOxTXXXIOcnBykpaVh5syZSExMND63devWkl53kn0nJbPPP/88+vXrZ5S/xsfHlzzOtddei2+//Ra5ublG37x33nmn0u/pcrlw0003GWWz3bp1w/btVUtjnTBhAp544onTPi5ZelUN+vkLOQ4EzJ7dRWZuIiBgA6ZPt1anaB5ja0tLCzO2W7e6MGXKDAQFVS1IQP7FF8/jso3Tf/jhB4SFqd8tqprs7CDs3DnU2M/M/BHTp1fvxSDP1dZw/HiI1J5g27YAfP31DwgPL70IyGNsHZWdL612jNes6Q0gHvv2LcP06Rm6l2MKVjvGOmRDXWw2q8wVmeX+HYc4dIzqiBVZK/DGnDdwe73bta3N3wUgAKs3r4b8zwrPY4ltVVWAS6JTJiBXmL755ptyAyPcfe4yMjJw8OBBvP3225gzZ44xeCI5ORmffPIJrr/+erz55pu47bbbjPtLhlu9evXw5JNP4vbbS58Ukn139OhRI5D3yCOPGBl2r732WoVreemll/DFF19g3rx5cDgcRsCucePG+OOPP4wMvupk2MmQC1l7TIwaS+3vJBosv6gDBw5EMJvF4txzHVi2LBCff16Iyy4zxVOp1niMrU+O8Q8/zMT11w9Hbm4AVq92okUL3asif30ey99paT8hjhw5YgyKoqpbtCgAffsGoW5dF7Ztq3q2K8/V1tOgQRAyMwOwcGEhzjlHMu14jK3m1PNlSEiIJY9x06ZB2LWr9HfZmNJ26BCQkGC7YRN8HtdexokMLNu7DPVizdkUUTLrJFiX2jEVgY7yjWhlUuydM+5EiCMEk0dORmKESjyi6tlzfA/ap7RHg9gGlngeS5xIktCOHTt21jiR6TPs5IV/s2bNjFvPnj3RvHlzo4+dBN0k4+7UnnUyCbZJkybYuXNnucdJTU01bjJ1VjLvevfujXHjxpU8RlkSFFy0aJHxWGVJtp0ECD/44IMK1yr3P/VrhBxUq52grfgzVZeEujecnNTdvn2Q5V5/8BhbmzS2b9pUTSTcvj0YbdvqXhH56/O47OPzvFF969apbfv2ATX6b8f/5tbqY5eZKb8TQeX6GfIYW0dl50srHWMZfptxMqmuUaOTr48lYLd/vy0Ddm5WOsa+FhcZZ7zHLnAVGJNjzUqCdacG7LrX7Y4OyR2wcv9KfLr2U9zT4x5t6/NrDsAR5ND+HPLU87g6j+F3s8iKi4tLsti6du1qPHk3uKMmJ6OfkhEnwyXO9BiibDbcqRl2MnF2+fLlxm369OnGxz///HM89dRTHv6JyJ8nYGVlAUFBQLNmuldDVH0tWqis0I3WquYmH5OWD1lZWcbNau0ffEGC5mWHDpB9cVKs9dnhfClxucJCdWEwJUX3asgKIkMiERkciVxnLvyNVBHe3PlmY//rdV/jWN4x3UsiP6M1w07+WG3evLnk39u2bTMCZJIBl5CQYATHhg8fbmTBSVnpq6++agyZGDlypHF/SR+UPnPjx483Sk8lSOee/uq+jwTbZIBE9+7dERUVhTVr1uDBBx9Er169jJ53YvHixbjhhhswe/Zs1K1bFw0alE+1lK8TTZs2NcpticpmRUiWEi+YkT9q2dJVbtrxqb75BkbmHctl6WwvRlkGW3Pu4Ewls7LIRjgp1vrscL6UC9oiNVVd1CaqrcCAQCRFJGHzkc1GXzh/06t+L7SIb4GNhzfi8zWf47auqpUXkekz7JYuXWpMd5WbuO+++4z9v//970bvuPXr1+OKK65AixYtjEERhw4dwoIFC9C2TO2WBOhkKMWoUaOMoNyOHTuMklZ3f4jw8HCj993555+P1q1b49577zWCgDLMomzTP8nS4/Qeqg53YmerVrpXQuT5gJ30VL38cmDwYMlK9v3aiOxAWisww47c3L8D7t8JIn8O2DHHgTypTngdFBWXDuPxt0D96E6jjf3P1nyG7AJzD88gc9F63UOmuZ5p5sWkSZOqVP/73HPPGbeK9O/fH7/88kut1iGZeCaZzUEmsmmT2jL7iPxVq1aVB+w+/1xtZRj3nDnAgAE+Xhz5DWkv4R7yJEOgKurlShWTfmXSh11Kx3jxh6Qlc0AAcOAAsG8fEB+ve0Xk7fNloDz5LWb3brWtW1f3SshKokOiERoUirzCPFP3savMBY0vMAYm7Dy20wjajek8RveSyE9Y768EkY8Dds2b614JUc24g83Sb+bw4dKPS++Zb78t/fc77/h+beQ/CgsLjWFMcpN9qjp3JpX8HQkP170a0k1amrl74rIs1prscL50Z9gxYEfe6GOX48yBP3IEOnBbF1UK+9HKj3A8/7juJZGfYMCOqIYYsCN/J+053SUrZWb3YMEC4OBBICystJedZAERkWexfx2dioMnyN+xJJa82ccut9D/Bk+4DWo6CE3jmiKrIAsfr/pY93LITzBgR1QD0u5w2za1z4Ad+TN3GV7Zslh3N4LrrgOkxWhBAfC//+lZH5GVsX8dnYp97MjfsSSWvMWf+9i5g45ju4419j9d/SmO5B7RvSTyAwzYEdXA9u1AUZEqYUpP170aIs8F7GTAhDtgJ0MnxowpLYtlK08iz3JnUTFgR26cFEv+jhl25Is+dv6qX6N+aJXYyijtfX/F+7qXQ36AATuiWpTDSq8ZaRBNZJWA3eLFwN69QHS0GjQhWXZSGivZHkuWaF0qkaVIcHzNGrXPklg6NWAnvxuc0E3+Ri7sMcOOvMXf+9i5J8be0e0OY/+rtV/hQPYB3Usik2PAjqgG2L+OrBqw+/prtb3kEkCGfcbFAZdeqj42daqmRRJZkExgzs1VAfGmTXWvhsxCLgTKuTcnR/2OEPmTo0eB7Gy1z4AdeauPnT8H7MR59c5Dx5SOyC/Kx3vL39O9HDI5BuyIaoABO7JawG7LFjUpduJE9e8rryy9j2TaiblzNSyQyKLcPcratAEcDt2rIbOQ3wX5nRBr1jCFn/yLvJYQaWlq6jGRp8WGxaLY5d/px2Wz7L5Z/w32ntire0lkYgzYEdUAA3ZkFdKDUabFSk/GBx5Q02Dl93r48NL79O2rtr/9pjKCiMqKiIjA/v37jZvsU9W4s1rdwRmi0wdPMGBnNVY/X27erLbMGiZviQqJQogjBAVFBfBn3dK74Zz0c1BYXIh3fn9H93LIxBiwI6rFCxIG7MjfSQ9Gd5adO7vub38DgoLKl2hJYE+mxf76q551krmvFCclJRk32aeq4YUfqgwDdtZl9fOl+/WxvG4g8lbALiI4wu/LYoU7y27apmnYfnS77uWQSTFgR1RNErSQKbGCb7TICtwBO9G4sRo0UZa8p3Bn2bEslsgzGLCjyjBgR5YL2AUHqzpZ2RLVgiPQgfjweOQ6/b/ko31Ke/Ru0BtFriK8uuRV3cshk2LAjqiatm1Tk9ukjDA1VfdqiDwbsHv00YpfT/frp7bz5vluXeQf8vPzcddddxk32aeqYcCOzhawk+BHQQFfqluJ1c+XZwzYSao+A3bkAXHhcSh0FcIK/nTOn4xhGj9t/wl/ZPyhezlkQnwVQFTDN1nyYsSC1QxkQx06qG2DBsANN1R8H3fATkpi8/J8tzYyv8LCQrz22mvGTfbp7E6cADIz1T4DdnQqSUSKj5feogHYvTtK93LIg6x+vmRJLPmqLNYR4DD6v/m7JnFNMKLlCGP/v7/9Fy6XS/eSyGQYsCOqJmZFkNUMHQq88gowfToQElLxfeT3XTJKJSGAfeyIPPOmNikJiI3VvRoyG7kY2K6d2t+xI0b3coiqfCFi375Thk44ncDevWpL5OE+dlYoixW3db0N4UHhWHNgDWZunal7OWQyDNgRVRMDdmQ1gYHAXXcBbdue+Q0ky2KJPIN/R6iqZbEM2JG/2LJFbRMTgTp1Tn5QAnUZGQzYkUfJlNjYsFhkO7NhBYkRibix443G/suLX0ZeIUtZqBQDdkS1KIklshMOniDyDP4doaoG7HbuZMCO/APLYcnXQa6CogJYxfXtr0dKZAoysjLw0cqPdC+HTIQBO6JqYmYE2T1gJyWxMi2ZiGr3xpZ/R6gyzLAjf8OAHfm6LFaGNRQVF8EKwoPDcU+Pe4z995e/j4wTGbqXRCbBgB1RNUiz/Z071T7faJEdp8kmJKjnwe+/614Nkf/ihR86G3cPu0OHwnHggO7VEFW9JJYBO/JVwE6CXLmF1uhjJwY2GYguaV2QX5RvDKAgEgzYEVXD1q2ADO+JjgaSk3Wvhsi3pI/d+eer/YULda+GyH8xYEdnExMDtGihpgUuW8aR9GR+zLAjXwoLCkNMSIyl+r0FBATgwXMfNDIHZ2+bjcV7FuteEpkAA3ZENSxjkuAFkd0wYEenCg8Px7Zt24yb7NOZHT8O7N+v9hmwozPp1k0F7JYu5QsOq7Dy+ZIBO/K1hIgESwXsRPOE5rii9RXG/nO/PIfC4kLdSyLNGLAjqgZmRZDdlQ3YSbYpUWBgIBo1amTcZJ+q9nckJUVlaxNVpnt3Buysxqrny9xcYPdutd+0qe7VkF1Eh0bDJf+z2AvSsV3Hok5YHWw9uhVfrPlC93JIM+v8pSDyAQbsyO66dJEMAemrBGzYoHs1RP6Hf0eoJhl2Fns/ShZsGSNiY1WvWyJf9bGT0ljp+WYlsWGxuKv7Xcb+m8vexKGcQ7qXRBoxYEdUDXyjRXYXEgL06KH2WRZLoqCgAA8++KBxk306M/4doarq2NEFh6MY+/cHYNcu3ashT7Dq+bJsOSxbxpCvRAZHIjwoHDnOHFjN8BbD0TqxNbKd2Xh58cu6l0MaMWBHVA18o0XEPnZUntPpxHPPPWfcZJ/OjH9HqKrCwoCGDY8b+4vZe9wSrHq+ZP860jWkISkiyZIBO0egAw+d95CxP3XTVA6gsDEG7Iiq0Z/DfYWbL0jIzhiwI6p9wI5/R6gqmjc/YmyXLNG9EqLKuVtk8LxGOspHi13FsKL2Ke0xss1IY/+pBU8h15mre0mkAQN2RFW0ZUtpf47ERN2rIdLn3HOlcbZ6TmRk6F4NkX9hhh1VR7NmR40tA3ZkZuvWqW3r1rpXQnbsYxfiCEFBkXVKzMu6u/vdSI1KxZ4Te/Da0td0L4c0YMCOqAZvstifg+wsJgbo0EHtM8uOqOpkWIvcBAN2VBXNm6uA3dKlQLE1k0jIAhiwI10iQyIRHmzNPnbun++x3o8Z+5+t/gwr9q3QvSTyMQbsiKqIWRFEpfr2Vdvvv9e9EiL/sXGj2tavD0RG6l4N+YP69U8gPNyFEyc4mZvM6cCB0gsRLVsajfqAvXvVlsjLggKDEB8eb+ly0Z71emJYi2FwwYUn5j2BvMI83UsiH2LAjqiaDXUZsCMCLr1UbadMAYqKdK+GyD+4Ay7Gm1qiKnA4XOjSxWXssyyWzJxd17DhyQsREqiTfhmyDQ4G0tLUlshLJGDnLLZ2gPi+nvcZAzZ2HtuJ15e+rns55EMM2BFVETPsiEr17g3ExQEHDwK//KJ7NUT+FbBr0UL3SsifdO+uAnazZ+teCVE1y2ElUJeezoAdeb2PnWTaFRYXwqqiQ6Pxt95/M/Y/WfUJlmcu170k8hEG7IiqiAE7olJBQcCwYWp/8mTdqyGdwsPDsXr1auMm+3T2klhm2FF1XHaZCth98UVp6SH5JyueL9evV1v2ryNdokOiEREcYdk+dm7nNzi/XGms1X9eUhiwI6qCnBxgzx61z4AdkTJiRGnAzqXeT5INBQYGom3btsZN9qlyzLCjmujZ04VOnYC8PGDiRN2rodqw4vmSAydIt2BHMOLC4mwRwJLS2JTIFOw6vgvP/vKs7uWQD1jjLwWRj/rXxcerGxEBgwYBYWHA1q3A6tW6V0NkbtLr0f23hBl2VB0ymf6uu9T+669zWiyZCwN2ZAYJEQlwFlm7j527NPaf/f+JwIBAfLfxO/yw5QfdSyIvY8COqApYDkt0OmkuLUE7wbJY+yooKMDjjz9u3GSfKrZjB5CfD4SGAg0a6F4N+ZvrrgPq1FEXSDid239Z7XyZlQXs3Kn2GbAj3YEsyVq1ch87ty5pXXBzp5uN/acXPI09x0+WgZElMWBHVI2AXbNmuldCZM6y2G++0b0S0sXpdOKJJ54wbrJPZ+5fJ39HHA7dqyF/ExEBjB6t9l99VfdqqKasdr50l/knJQEJCbpXQ3YfPBEZHIlcZy7s4JYut6BDSgdkO7Px19l/RV5hnu4lkZcwYEdUBcywI6rYJZeocq0//gAyM3Wvhsj8b2xZDks1dccdaisZdkeO6F4NEcthyTxCHCGoE1bHCGDZgUzFffqCp42fef3B9ZiwcAJcbChtSQzYEVUBA3ZEFZOr6h06qP3583Wvhsi8GLCj2pLXIK1aqR52P/2kezVEDNiR+frYFRT5f6l5VaVGpeJfF/4LjgAHpm2ahs/XfK57SeQFDNgRVQEDdkSV69tXbefN070SIvOXxHJCLNXGwIFqO2uW7pUQMWBH5hIdYp8+dm7d0rvhnh73GPv/+fU/WJ65XPeSyMMYsCOqQkNdd6kfA3ZEp2PAjujsmGFHnjBggNoyYEemC9hJT769e9WWSNPgicgg+/Sxc7u23bW4qOlFKHIV4dE5j+JILnsmWAkDdkRnsXmz2iYmqgltRFRenz5qu2YNcPCg7tUQmU92NrB7t9pnwI5qe4FEhpZI5r9MHibSReJy7tfIJQG7jAwG7EhvH7tw+/SxcwsICMDfev8Njeo0wv7s/Rj30zgUFRfpXhZ5CAN2RGfBcliiM5Ngdtu2ap997Igq/zsiUxTj43WvhvxZbCxwzjlqf/Zs3ashu2cNFxYC0dFAvXq6V0OkJEYk2qqPnVtEcITRzy7UEYpf9/yK//72Xw6hsAgG7IjOggE7orNjWax9hYWFYfHixcZN9ul0LIclb5TFzpypeyVk5/OlTIcXHTuqafFEZulj5wh02KqPnVuz+GYY12ecsf/p6k/x9u9v614SeQADdkRnwYAd0dn166e2c+fqXgn5msPhQPfu3Y2b7NPp1q5VW5nwSeSpgJ1k2MnEWPIfVjpfugN2XbroXglR+T52EUERtutj53Zxs4vxwLkPGPtv/f4WPl71Mawgu8BeZc5lMWBHdBYM2BFVvY/dqlXA4cO6V0Nk3kwUotrq2ROIjAQOHFDnXCKd57XOnU/5RHAwkJamtkQa+tjFhcfZro9dWde0uwZju44tmRz79bqv4c9+3PIjbp96O/7IOHnSsRkG7IiqGLBr1kz3SojMKyVFZQ9Ju4wFC3SvhnypoKAAzz77rHGTfTrd8uWVvLElqoGQkNI2BJwW61+scr6Uv/VnDNilpzNgR9rYtY9dWWM6j8GoDqOM/QkLJ2DqxqnwN9KD76OVHxmTbyUA+/maz3UvSQsG7IjO4PhxYP9+tc8MO6IzYx87e3I6nXjooYeMm+xTeYcOAbt2qf0OHXSvhqzi/PPLB4PJP1jlfLltG3DsmAoet2mjezVE5UWFRNm2j13ZybF/PufPuLrt1ca/n5j3BCavnwx/IcfumV+ewYu/vWj8+5Lml+CpC56CHTFgR1SF7LrkZCAmRvdqiMyNATui07kDKk2aqAmfRJ7QurXarluneyVkR+7sunbtmEhH5uxjFxkciRxnDuxMgnbSz+7yVpfDBReeXPAkXl/6uumnxx7NO4o/zfgTvlz7JQIQgHt73osxXcYYQVg7YsCO6AzYv46o+gE7CVDIlXciYjkseTdgt369Kk8k8qVKy2GJzNLHLizO9gE7d9DukfMfMUpkxbt/vIu/z/078gvzYUYbDm3AjZNvxJK9SxAeFI5nBjyD69tfDztjwI7oDDZvVlsG7IjOTlrWSK9HmVq4cKHu1RCZ641tp066V0JWIhmbQUFAdjawe7fu1ZBtA3YdioC9e6XWV/eSiMpJiEiwfR+7skG7O7rdgcd6PwZHgAMzNs/AbVNvw4HsAzALyfr7bPVnuGnyTdhzYg/qRtfFxEsnon/j/rA7BuyIzoAZdkTVw7JYoooz7BiwI0+SMkT3MCzJsiPSErBr5wQyMhiwI1P2sQsMDERRcZHupZjGiFYj8PLglxETGoM1B9Zg1ORRWJaxTPeykJmVib/88Bc8t+g5OIud6N2gNz4c8SGaxXPio2DAjugMGLAjqh4G7IhK5eaWBlNYOkaexj52pENmporRBQQAHdoV614OUaUBu4igCOQW5upeiqmcU/ccIxjWJK4JDuYcxNipY/HCoheQV5inZbDE/1b+DyO/HImfd/1slDI/eN6DeGHQC4gNY9NfNwbsiKpQEuu+ik1EVQvYLVsGnDihezVEeq1eDRQVAYmJqmScyJNatVJbZtiRjuy6li2BqCjdqyGqWGhQKGLCYtjHrgL1Yuph4vCJGNFyhDGM4pPVn+C6SdcZQTNf+XX3r7ju6+vw39/+awRVO6V0wkcjPjKm2koJL5UKKrNPRGVIsOHAgdJeMUR0dg0aAI0bA9u2Ab/8Alx0ke4VkbeFhYXhp59+Ktmnisth+fqTPI0BO/8/XxZL01c/w4ET5C8SwxORcSJD9zJMKTIkEo/1eQz9GvUzpsfuPLYT93x/D86rfx7+fM6fvVaOunr/arzz+ztYuEs1u44NjcU9Pe7BJS0uQWAAc8kqwoAdUSUk4CASEoBYZuUSVSvLTp4/c+cyYGcHDocD/fr1070MU+KEWPImlsT6//nSHwN2kkEveF4js4sOjUYAAoyBBszaqtj5Dc7HVyO/MqbHfrr6U/yy6xfj1rdhX9zY8Ua0T25f6/92MpF2wc4F+GLtF/g943fjYzL84qq2V+HWLrcaPfWocgzYEVViyxa1bdpU90qI/C9g9/777GNHxAmx5E1SkujuKXb0KFCnju4VkdW5XCp7XvTsqXs1RGfvYxcWFGb0ZwsPDte9HFP/d5Ist8taXYbXl76OWVtnYd6OecZNymcHNhloZOK1Tmxd5Sw4CdIt2bsEP23/CbO3zUZWQZbx8aDAIAxuNtgIBjaq08jLP5k1MGBHVImtW9WW5bBENetjt2QJkJ0NREbqXhF5k9PpxFtvvWXs33bbbQiW8ZWEnByWjpF3xcQAdesCe/aoslgGUPzvfOmPr40lQCyn+W7dJIJX5pPywbQ0tSUygfCgcEQGRyLbmc2AXRU0iG2ACRdOwO1db8f7y9/HzK0zsfv4bkxcPtG4xYXFoWtaV9SPrY+0qDREBEeUDI+QoKgE5fac2IMdx3Zg3YF15QZ+pESmYEjzIbiy9ZVIiUrR+FP6HwbsiM6SYceAHVH1NGqkbtu3A/PnA4MH614ReVNBQQHuvvtuY/+mm25iwO6kWbOAvDzV19Hda4zI0+R3iwE7/z1fhoSEwJ/8fLInvQTrwiX+Ubafv5z7OV2HTERKOZMik3Do4CHdS/Erkvn2eL/H8VCvh4xSVsm4W7xnMY7kHcGsbbOq/DjJkcno06APBjQZgC5pXdijroYYsCM6S4YdS2KJqkdaXQwYALzzjgpaMGBHdjRlitoOH86BE+TdgN3s2Rw8Qb6xUPWJx/mdsgBnqO7lEJ2V9EeTSahUfZJBd1HTi4ybs8iJFftWYN3Bddh7Yq8xzKOguMC4XyACjQxGub9k3kmmXtP4pmgR34K9Az2AATuiSjDDjqjmBg5UAbuZM3WvhMj3pI/8d9+p/Usv1b0asjIOniAdGXa9mmYCTmbTkX/0Zwt1hBolm9LPjmom2BGMbundjBv5FvMSiSpQVKTK+QQz7Iiq74ILVFbRqlWq3w2Rnfz2G7B/v+ox1qeP7tWQlbnLrZlhR952+DCwdq3aP69jtu7lEFU5YBcdEl0y9IDI3zBgR1SBXbuAwkJAWouwHQdR9SUmljbal3ItIjuWww4Zov6OEHk7w06qAgpUdRKRV7inw7ZsUYykuELdyyGqEinJlCEHuc7SAQhE/oQBO6Iz9K9r3BhwOHSvhsh/y2IFy2LJbr79trR/HZE3yVBOmcQtlQHbtuleDdmif925xbqXQlQtsWGxRuCu2MXfXfI/DNgRVYD964hqTwZPuAN2Lvb7JZvYtEn1EwsK4sAV8j5pPdCsmdrfvFn3asgW/et6FuleClG1B0/IUIQcZ9mxxkT+gUMniM6QYceAHVHNnX8+EBYG7N2rAhht2uheEXlDaGgopk6dWrJvd199pbZ9+wJ16uheDdlB8+bAihUqWEz+db50+cnVrPx8YMkStX/+ecWAU/eKiKpOhk3UCauDg9kHjZ52RP6EATuiMwTsOHCCqOYkWNe7t8qwk55e7oCdvD9Zvhxo2RKIiNC9SqqtoKAgDB06VPcyTCEnB/jvf9X+qFG6V0N2CtgJBuz873zpdPpH5GvxYhW0S04GmjV1ARxyQn4mOTIZe47v0b0MompjSSxRBVgSS+QZl12mto8/rl7wFxcDf/4z0KULMHq07tURedZbb6npsI0aAdddp3s1ZBcsiSVv++knte3fMxcBhWWCjMHBqpGibIlMXhYbFBiEwmIOTCH/woAdUQWYYUfkGbffDgwbpq7MjxgB3HQT8Mor6nNffln6XCP/JRki77//vnHzl2wRb8jLA555Ru0/+ijfv5LvMMPOf/jr+XLOHLXt33a//BCln5ATXXo6T3jkFwG7yJBIZBVk6V4KUbUwYEd0iiNH1M09JZaIai4wEPjf/4C2bYGMDOCjj9TH5LklpbEvv6x7hVRbBQUFGD16tHGTfbt69131O16/PnDjjbpXQ3YM2O3YIc9H3ashq50vc3OBRYvU/gXdT+heDlGNSHZdUkQSsguydS+FqFoYsCM6hTvjJzUViIzUvRoi/xcTo3rYJSQADocK4L32WmmQ4/hx3Sskqh3JIP3Xv9T+ww8DISG6V0R2kpICREWplgPbtuleDVnNL7+oQHDd9GI0q5+vezlENRYfHo9iV7HuZRBVCwN2RKdg/zoiz5Pn0/r1qsfStdcCgwYBrVoBJ04AEyfqXh1R7XzwAbB7t6oMu/lm3ashuwkIKO1jx7JY8lY57AV9i43fNSJ/LosNDQpFXmGe7qUQVRkDdkSn2LBBbd0vfonIMxITVTN+IWWx99yj9l96SZXHEvkjaec0YYLaf+ghNR2ZyNcYsCOvD5zoU6R7KUS1EhUSheiQaJbFkl9hwI7oFCtXqm2HDrpXQmRtN9wAhIerMvR163SvhqhmpMR7+3ZVlnjrrbpXQ3bvY8dJseRJkgUvE97FBf1YSkj+LSAgAClRKcgtzNW9FKIqY8CO6BQM2BH5RkQEcN55an/uXN2rIaq+wkLg6afV/gMPqN9pIh04KZa8YcECoKhItbVo2ICp8OT/YsNi4XK52MuO/AYDdkRl5OSUvthlwI7I+/r1K19yQ+RPvv1WZTRJuffYsbpXQ3bmLollhh150k+zVRls/74MbpB1+thFhEQgx5mjeylEVRJUtbsR2cPataqXVnKyKm8iIu/q3780w04mHEpvO/IvoaGh+OKLL0r27WTGjNLybpnSSaQ7w27HDjXRk5OK/eN8KZk+Zvbjj2rKxAW9naUfDA4G0tLUlsjPhAWFGdNi92ftN3raEZkdA3ZEFZTDtm+veyVE9tC9uyojPHhQBczbtdO9IqquoKAgjBw5EnY0e7baDhigeyVkd3KRUYLGWVmqL6hM4Sbzny+dMrXGpCT4u3J1IAIDXbhoQJmBExKok5HYRH4qKSIJu4/t1r0MoiphLgNRGexfR+RbkgXSq5faZ1ks+RMJisiwiaAgoHdv3ashuwsIYFkseda0aWp7XocsJCToXg2RZ8tigwKD4Cwyb8CcyI0BO6IyGLAj0lsWS/6nsLAQX375pXGTfbtwZ9f17MlyWDIHDp4wP386X06dqraXnH9M91KIPB6wiw6NRlZBlu6lEJ0VS2KJTpI2IgzYEekbPME+dv4pPz8fV111lbGflZVllHzZKWB34YW6V0KkuDPsGLDzn/NliEmbDWZnA3PmqP1hfSRgF697SUQe4wh0ICUqBRsObkBceJzu5RCdEd8WEZ2UmQkcOqSCBW3a6F4NkX106wZERgKHDwOrV+teDdHZSWCZATsya4YdS2KptmbNkuAi0LhRMVo3ztO9HCKPiwtTgbpiFycgk7lpDdjNnz8fw4YNQ3p6OgICAjB58uRyn3/88cfRqlUrREZGIi4uDgMGDMBvv/122uNMmzYNPXr0QHh4uHG/ESNGlHzu0KFDuPjii43vIdOY6tevj7vvvhvHjx+vdF3bt2/HmDFj0LhxY+MxmzZtivHjx6NAxm6RZbmz61q0AMLCdK+GyD6kf/X556t99rEjf7BqlRqUIoHmHj10r4ZIYUksebwcdnCR0R+RyGpiw2IRERyBHGeO7qUQmTdgl52djY4dO+LVV1+t8PMtWrTAK6+8glWrVmHhwoVo1KgRBg0ahAMHDpTc5+uvv8aoUaMwevRorFixAj///DOuu+66ks8HBgbi0ksvxZQpU7Bx40a8//77mDVrFsaOHVvputavX4/i4mK8+eabWLNmDf7zn//gjTfewKOPPurh/wJkJiyHJdLHnaU0Y4bulRCdnTu7rk8fNTiFyEwlsTt3quwooppmEE+b5jL2hw1isgJZU1hQGBLCE9jHjkxPa6OZwYMHG7fKlA28iRdeeAHvvvsuVq5ciQsvvNBo1nrPPffg2WefNTLi3NqUqWeUjLs77rij5N8NGzbEnXfeaXxNZSQjT25uTZo0wYYNG/D666/jueeeq9HPSubHgB2RPpdeCjz0kAqEHD0K1Kmje0VElWM5LJlRSooagJKVBWzbBrRqpXtF5I9+/x3IyAhAVEQR+nTPBTJ1r4jIO5Iik7Dj2A7dy2M3OzAAAE9USURBVCA6I7/pDC3lqG+99RZiY2ONrDzx+++/Y8+ePUYWXefOnZGZmYlOnToZwbh27dpV+Dh79+7FpEmT0Ldv32p9/2PHjiE+Pv6sjWTl5uYuu3U6ncbNCtw/h1V+nrJWrpSnQwDatCmE06muLNqRlY8xmfcYN24MtG0bhDVrpD1CIa6/3r7PQX87xmW/h5X+3p0p+2TBAvX3ondv+Xn1rMOMz2PSf4ybNQvC8uUBWLeuEE2b8jxqNqeeL6Ul0Kkf1+2rr6QAy4FBPY8h0FEIp5z0ZKKtDBRKTlZ3MtF6zY7navOKCopCSEAIcvJzjIy7miouKi63JS8oAooKi7Q9jzz9PK7O45g+YDd16lRcc801yMnJQVpaGmbOnInExETjc1u3bi3pdSfZd1Iy+/zzz6Nfv35G+WvZANu1116Lb7/9Frm5uUbfvHfeeafKa9i8eTNefvnls2bXTZgwAU888cRpH//xxx8REREBK5HjYCVOZwDWrr3EeAN24MAcTJ+eC7uz2jEm8x/jdu1aYs2aVnjzzf2Ii1uiezmW4ItjnJdX2pD8hx9+QJjFm4BmZETixIkBCA4uwu7dM5CRoTcoYrbnMek9xhER3QDUxdSp6xAYqF4nk3lUdr400/P4k0/6A4hBw45bMf23PeqDe/fqXpbfM9MxpvIO47BHHidzBdNRvSUAAVi9eTXkf1Z4Hktsq6oCXC6XKS6/yRWmb775ptzACHefu4yMDBw8eBBvv/025syZYwyeSE5OxieffILrr7/e6DV32223GfeXDLd69erhySefxO23317yOJJ9d/ToUSOQ98gjjxgZdq+99tpZ1yUZfHJfCQKeLchXUYadDLmQtcfExMAKJBosv6gDBw5EsHSKt4gVK4Du3YNRp44L+/YV2rrBrlWPMZn/GLufh+HhLuzdW2g09CfzH2P5Xp9++mnJxTEz/U55w6RJAbjmmiB06VKMX38t0rYOsz6PSe8xHjcuEP/+twO3316El19mtofZnHq+FGZ6Hm/cKBfPghEU5MLeH/5AnTbpwK5dQMuWQHi47uX5JZ6rzW3bkW1Yu38t6sbWrfFjSGadBOtSO6Yi0KF1RIBl7Tm+B+1T2qNBbANLPI8lTiRJaFLFebY4kekz7GRCbLNmzYxbz5490bx5c6OPnQTdJOPu1J51MglWes7tlI67ZaSmpho3mTormXe9e/fGuHHjSh6jsvLZ/v3747zzzjPKcc9GvrfcTiUH1WonaKv9TGvWqG2nTgEICbHOz1UbVjvGZP5j3LWr9AyV7OkAzJkTjMsv170i/+eLYyyPX7aPrNWtXau2nToFIjhY/wtzsz2PSe8xlriK2LLFgeBgh3cXRrU+X7rLoszyPJ42TW0v6FuMpFiXKoMNDFRbE6zPn5nlGFN5CVEJCDwSiOKAYgQF1i40IsE6Buy8xAE4ghzan0Oeeh5X5zH87jdKpre6s9i6du1qBMhkIETZP3zbt283hkuc6TFE2Wy4ijLrJKtOvsfEiRONPnlkXcuXq22nTrpXQmRfktnqDtJNmqR7NUSVZ4IKDigiM2reXG03b9a9EvJH33yjtiOG6cseJvKl2LBYRIdEc1osmZbWDLusrCyjP5zbtm3bsHz5ciMDLiEhAU899RSGDx9uZMFJWemrr75qBNJGjhxp3F/SB8eOHYvx48cbpacSpHNPf3XfZ/r06di3bx+6d++OqKgorFmzBg8++CB69epl9LwTixcvxg033IDZs2ejbt26JcE6eTzpW3fgwIGSNUqWHlnPH3+oLQN2RHpddhkg7UK/+06GDQEhIbpXRGcjE9ulF5O46KKLECSZGDYI2J2cf0VkyoCdFJrIdekKCj/IROdLM9m7w4lff1VZH5deUgQc1b0iIu+TrLqUyBRsOrwJdcLq6F4O0Wm0vqpeunSpUXLqdt999xnbG2+8EW+88QbWr1+PDz74wAjWSQBPgm4LFixA27ZtS75GAnTy5mDUqFHGQIkePXoYfe7i4uKMz4eHhxu97+69914jo04Ce5dffjkefvjhck3/JEvPnZYu9ckSSJSb9MMryyQt/8iD5JAyw47IHHr2BGSu0MGDwLJlwLnn6l4RnY38bb3kkktKLsRZOWB37BiwfbvaZ4YdmZEM8YyKkueiXAgHWrXSvSI60/kyxERXpaZ8q97j9OhehPQ0FwN2ZBsJEQlGwK7YVYzAAFbVkblofVUtWWxnCoBNqkJNlNT/ShZcZRNcJSD4yy+/VGsdN910k3Eje9ixQ70Jk1Ly1q11r4bI3qT7QO/eqixnwQIG7MhcVq1SW7mWV2YQPZGpWgtIlp1UDmzaxIAdVd03U1TPw8vKlsPKi2Pp983ea2RhklkXGRyJ7IJsRIdG614OUTkMIZPtubPrJHHTRBc6iWxLAnZi/nzdKyEqj+Ww5E9lsRKwI6qKo0eBOfMCT+9fJ4G69HQG7MjSQoNCkRiZiBMFJ3Qvheg0DNiR7bEclshc+vRR24ULgSL2vSYTWblSbRmwIzNr1kxtOXiCqmr6dOmvF4DWjXPRsgXb/5D9JEUkobC4kO2vyHQYsCPbY8COyFwkGCI9mKRUffVq3ashKsUJseQPmGFH1TV5stqO6MfGdWTfstiI4AjkFubqXgpROQzYke0xYEdkLjKzoFcvtc+yWDILyfZ097Bjhh2ZGQN2VB15ecCMGWr/MgbsyKYiQyIRHx6P4/nHdS+FqBwG7MjWjhxRQycE34ARma+PnQyeIDKDrVtlqjwQFlYaECEyc0nszp0qGEN0JrNnq6nCddOL0a1Nju7lEGmTGpWKgqIClsWSqWidEktklvKmRo2AOnV0r4aITu1jJxl28rpJJh+SOYWEhOCVV14p2bf634t27QCHGqZIZErJyUBMDHD8OLBlixqqReZgxvPlN18XGzkcI4Y6+beWbC0uPK6kLFa2RGbAgB3Z2h9/qC2z64jMpXt3NbV53z7VOJ0ZTeYVHByMu+66C3Zpn8C/F2R2EnRp0wb49Vdg7VoG7Mx8vnQ6ndpL/ad8p6J0l13MdEyyt6iQKCREJGBf1j4G7Mg0WBJLtrZkidp266Z7JURUlpQd9uih9tnHjszg99/VtmtX3SshOjsJ2AkJ2BFVZvFi4MDBANSJLkSfc8sED4ODgbQ0tSWykZTIFJbFkqkwYEe29ttvausODBCR+frYTZmieyV0JkVFRZg7d65xk30rktfty5ap/S5ddK+G6OwYsDMns50vp09X24t6Hi8fm5N/pKczYEe2I4MnOC2WzIQBO7KtAwdUE3F3+R0Rmcv116vSLgnYuYMlZD55eXno37+/cZN9K8rIAPbvBwIDgfbtda+G6OwYsDMns50vp01T2yG9juleCpFppsVKWSynxZJZMGBHti4DEC1bcuAEkVnfcErQTjz2mO7VkJ25y2FbtwYi2NaG/Chgt2EDUFioezVkRnv3lvZyvvg8BieI3DgtlsyEATuC3QN2LIclMq/HHweCgoDvvwcWLNC9GrJ7wI7lsOQv6tcHIiNlqIGaFEt0Kvm7Krp3LUJyPKO6RGXLYiXTLtuZrXspRAzYkX2xfx2R+TVtCowZo/bvuAN49FHg6aeB7dt1r4zshAE78jdSvi0ZoYJlsXSm/nVDLirWvRQiU5EedsmRyTiWx1Jx0o8BO7IlyXB2Z9idc47u1RDRmYwbp6bGrlkDTJgA/O1vwIgR0rxb98rILhiwI3/EPnZUGWeOEz/+oAJ1Qy7iH1Oiispii+V/Lga0SS8G7MiWNm0CjhwBQkOBDh10r4aIzqRuXZUJ8PDDwD33ALGxwIoVwAcf6F4Z2WVA0a5dar9TJ92rIao6ZthRZX6eX4QTWYFISnShW5eTAQmZCJuWxsmwRCfLYqNDonEi/4TupZDNBeleAJEO7uw6yZYICdG9GiI6m/791c3dm+mBB1Sm3VVXAVFRuldHVuZuyt68ORATo3s1RFXHDDuqzLTvHcZ28KAio3zaIIG69HSt6yIyixBHCNKi0rDp8CbEhsXqXg7ZGAN2ZEvsX0fkv+6+G3j9ddVI/ZlngH/8Q/eK7C04OBjPyIE4uW81LIclfw/YrV+vWgg4VIyGNDLL+fKHWeqX4eKBLIclqkxSZBI2H9mMwuJCBAUybEJ68DePbB2wY/86Iv8jpezyfueKK4DnngNuuw2oV0/3quwrJCQEDz74IKyKATvyV40bq/NlXp4a1CNDfMhc50unjPH1scxMYNUalVY3oD8DdkSViQuPQ2xoLI7nHzdKZIl0YA87sp0TJ4Dly9V+z566V0NENXHZZcD55wO5ucBTT+leDVkZA3bkrySjrlUrtc+yWHKbNUttO7fMQVKS7tUQmZdk1dWLqYesgizdSyEbY8CObGfmTLmiCTRrpq4+E5H/CQgoDdS9+y6wbVv5zx87BtxxB3D//cCUKcDRo1qWaQtFRUVYsmSJcZN9K8nIUKXXonNn3ashqj72sTMXM5wv5XWwGNjjuJbvT+RPEiMSERoUirzCPN1LIZtiwI5sZ9o0tR06VPdKiKg2+vQBBg5UAfh//rP04wUFKgPvjTeAF14ALr0UaNgQWLJE52qtKy8vD+ecc45xk30rmTq1tH1CQoLu1RDVPGC3Zo3ulZAZzpcuFwN2RNURExpjBO2O5vHKL+nBgB3ZirxQmT5d7TNgR+T/3IG6Dz8ENmwAiouB0aOBn35S02PHjAEaNACOH+dwCqo+yc4Uw4frXglRzbRtq7arV+teCZmBZFpK5nBYmAvndzpZ5ifDL9LS1JaIygkICEB6dDoKigrgkjeSRD7GgB3Zyh9/qGa7kZEqO4eI/JtMer7kEjUBUXo1SZDuk0+AoCDg66+Bd94pzSaQbKlNm3SvmPxFTk5prycG7MhfdehQGqgpLNS9GtLN/few93nFCAs9GXyQQF16OgN2RJVICE9AVEgUe9mRFgzYkS3LYQcMUJPTiMj/TZgAxMWpfRlCIcE6CdQNGqQ+1qJFaUbtSy/pWyf5FwnWScVao0ZAu3a6V0NUM9KrVy5S5ucDmzfrXg2ZJWA36EJr9Rsl8qbw4HCkRqXiWP4x3UshG2LAjmyF5bBE1iPBlIMHgcOHgY0bgT17gBtvLH+fe+5R24kTOYCCql8OK0NOiPxRYGBpWezKlbpXQzpJ0HbuXLU/8AIG7IiqQwJ2Uh7rLHLqXgrZDAN2ZBsHDgC//ab2hwzRvRoi8vSbUsmya94cSE4+/fOSVSvN17Ozgffe07FC8ifSC/G779Q+y2HJ37Vvr7arVuleCekkvV2l1F/+RrZvx15cRNWREJHA4ROkBQN2ZBvff6+GTnTsCNStq3s1RORLkiHlzrKTsljJNCCqzOLFwP79QGws+52SdfrYMWBnb2++qbZXX60uchFR1QUGBKJ+TH3kFOZw+AT5VJBvvx2R3iuL4uKLda+EiHT4v/8Dxo8HduwA3nijNIBHtRMcHIzx8h/25L6/W74cuP56tT94MPuwk/9jhp156Dpf7t5dmjU8dqzPvi2RpSRFJiEmJAbH848jNixW93LIJhiwI9tYtEhtzz9f90qISIeICOCJJ4Dbbwf++U/gpptUBhXVTkhICB5//HFYwYcfqt8PGTYhzfrl94TIKgG7rVuBEyeA6GjdK7KvU8+XTqdv+mHJICaZpt63r2oPAWcwkJbGKxJE1RAWFIZ6sfWw/uB6BuzIZ5gQTbYgzejXr1f7PXvqXg0R6XLzzUCrVsChQ8Azz+heDZnJv/+thpVIsE4GEy1bBjRrpntVRLWXmKhiM2LNGt2rIV8rLATefvuU7DoJ1KWnM2BHVE0pkSkIDgxGXmGe7qWQTTBgR7bw669q26KFeuFKRPYUFARMmKD2//Of0ol5VHPFxcVYs2aNcZN9fyOtaP72N+Dhh9W/ZSsTYmWICZFVsCzWvudLKYXduxdISgIuu8wn35LIsuqE1UFyZDKO5B7RvRSyCQbsyBZ++UVtzz1X90qISLdLLwX69wdyc4ELLgD++legoED3qvxXbm4u2rVrZ9xk3988/zzw9NOlWXYS0GVDdrIaBuzseb6UCxIvvqj2x4wBQkO9/i2JLC0gIAD1Y+ujyFWEwuJC3cshG+BLUrJV/7rzztO9EiIyw8RYyaC65Rb1ZkZKY6+5RveqSAdpHyUBO/Hcc8BDD+leEZF3A3YrV+peCfnS7NnAvHnSOw+4807dqyGyhqSIJCSEJzDLjnyCATuyRe+OxYvVPjPsiEhERamePpMmAQ4H8M03zDyxIwncZmYCKSnAn/+sezVE3tOhg9rKeU4uVJD1ucv93b3r6tfXvSIia3AEOtCwTkPkFuai2OV/rUDIvzBgR5a3ejWQlQXExJycjEVEdJL087n8crX/3//qXg352ptvlg4jYe91srLWrdXFCRnClZGhezXkq951csFaJqQ/+qju1RBZi/Sxk0mxx/KO6V4KWRwDdmSbctgePdSLVSKisv7yF7X9+GNg/37dqyFf2boVmDlTlUjfeqvu1RB5V1iYCtqJBQt0r4a8TeZZjBun9iV7WLKIichzQoNC0TC2IY4XHIeLacvkRQzYkW0GTrB/HRFVRErlu3cH8vNLM67I+qQkWgwaBDRurHs1RN43dKjaSgsAsrbp01W/QqkuefBB3ashsqb06HTEhsbieP5x3UshC2PAjmyTYcf+dURUEcmwuvdetf/qqypwR9YfNvHee2r/ttt0r4bIN9zl/xLM4XnO2j74oHQybHy87tUQWVN4cDga1WnEgB15VZB3H55Ir337gC1bSktiiYgqcuWVKgthzx41iOLaa3WvyH8EBwfjgQceKNn3B7NmqfLn5GRg2DDdqyHyjW7dgLp11XlOpocOGaJ7Rfbji/Pl0aOqf5244QavfAsiOqluTF1sO7QN2cjWvRSyKGbYkaXNn186Ha1OHd2rISKzkvdNMnhAfPSR7tX4l5CQEDz77LPGTfb9wRdfqO3IkRw2QfYRGAiMGKH25cIEWfN8+eWXKoOyXTugY0evfAsiOiksKMzIshOcGEvewIAdWdq8eWrbt6/ulRCR2Y0apbY//ABkZupeDXlLQQEwebLav+oq3ash8v1kbDFlClBUpHs15A3ui07yN01aPhCRd6VFpRnbI7lHdC+FLIgBO7JFwK5fP90rISKza94c6NlTTdf79FPdq/EfxcXF2L59u3GTfX8oh5WSsdRUoFcv3ash8q0+fYC4OODAAeDnn3Wvxn68fb7cvl1NAZZA3XXXefzhiagCIUEqWzbPmYfC4kLdyyGLYcCOLOvgQWD16tIXqEREZ+Pu9/Phh7pX4j9yc3PRuHFj4yb7/lIOK30LHQ7dqyHyLSkBd/dt5IUJ650v//c/tb3gAqBePY8/PBGdQVJ0Eg5kH9C9DLIYBuzI8v3r2rYFEhN1r4aI/IGUSMob2uXLgVWrdK+GPI3lsESlmVdvvKFKY8kaXK7Si03uFg9E5DuN6zSGCy7kFebpXgpZCAN2ZFnsX0dE1ZWQAFxyidrn8AnrmTkTOHYMSEtjOSzZ10UXAXfdpfb/7/+AtWt1r4g8YfFiYNMmICICuPxy3ashsp/E8ETUj63PLDvyKAbsyLIYsCOimnBnJnzyiepnR9bx+eel5bAyMZPIrv7zH/X66MQJ4NJLgePHda+Iast9kUkGi0RH614Nkf0EBASgSVwTRIRE4FjeMd3LIYvgy1WypCNHgJUr1T4DdkRUHYMHA1FRwJ49wNKluldDniIBia+/VvvXXqt7NUR6Sen/l18CDRoAmzcDr7yie0VU23L/zz5T+yyHJdInJjQGTeOa4mj+URQVcxQ31R4DdmRJMiFLenm0agWkpOheDRH5k7AwYMgQtf/NN7pXQ54cNpGTo/4uyDRgIrtLSgKeekrtv/iiDETQvSKqqe+/Bw4dUtOvL7xQ92qI7K1BbAOkRqXiQA5LY6n2GLAjS2I5LBHVhpQUCQbsrOO999T25pulbEX3aojM4eqrVZbd/v3ABx/oXg3VthxWBooEBeleDZG9BTuC0Sy+GVwuF3KcOfBHkh14MOcgCosLdS/F9hiwI0tauFBt+/TRvRIi8keSYRcSAmzYAKxbp3s15hYUFIQ777zTuMm+Ga1fDyxaBDgcLBcjOrU09r771P5zzwFFrODyu/OltIFxT/vl+Y3IHJIikox+dpJl529BL5lyu/vEbiPwuPfEXiPwSPowYEeWIyVPv/+u9jkFkIhqIiamtKyIWXZnFhoaildffdW4yb4ZTZxYGoiVkjEiKnXLLUB8PLBlCzBpku7VWJs3zpcyTEd62LVrB3Ts6JGHJCIPDKBontAcdaPrIuNEht8EvbIKsowgo2QIdkzpaPTkO5R7SPeybI0BO7LkWPvCQqBePVXmQURUEyyLtQb5e/Dhh6XlsERUXmQkcPfdpdNjyX9IDODNN9X+mDEs9ycyE8lQa5PUBjFhMX7Rz66gqABHco+gXVI7tEtuh4SIBLRKbIX8onzkOtnkVBcG7Miy5bCSXccXLkRUU8OHq3OITIrdtUv3asxLrhofOHDAuJnxCrI0Y8/MVA32hw7VvRoic7rjDiAwUJWOb9yoezXW5enzpfx9Wr5cMveAG27wyBKJyIOiQ6PRNqktXHAZwTCzKnYVIzMrEw3rNETjuMYIDFBhovTodGPq7f6c/Zx6qwkDdmTZgN355+teCRH5M5kw7S6rnzxZ92rMKycnB8nJycZN9s06bEJ6O0m/LiI6nZSKX3RR+QEGZP7zpTu7buRIVdZMROaTEpWC9sntkVuYi+P5x2FG+7P3IzEi0ciocwQ6ypX2SnmsTL3dl71P6xrtigE7shRplvzLL2qf/euIqLZYFuvfZPLld9+p/dGjda+GyNxuvFFtpYS8uFj3auhsjh0DPv1U7d9+u+7VENGZ1I+tb2TaScDuRP4JmImsRzLqWie1Rnhw+GmfDw0KRevE1ggJCsHRvKNa1mhnDNiRpaxeDZw4AURHA+3b614NEVklYDd/PnCIPXf9zscfqx523burhuxEdOY2ALGxwM6d6pxH5vbJJ2rQWuvWvEhN5A+k1FR6w2U7s3Ew5yDMQCbYHs47jObxzY0Mu8rEhccZQTsZSiFTZMl3GLAjS5bD9uwJBAXpXg0R+bvGjdXUPcnedWdqkX+Q9lDvvqv2OWyC6OzCw4GrrlL77kEtZF5vv12aXceezUTmJ+WlTeOboktaFzgCHNh9YrcRMNNJylylT530rjubejH1jH528jXOIqdP1kcM2JHFsH8dEXkay2L9kzRjX7MGCAsDrrlG92qI/Kss9ssvgexs3auhykgW5B9/qEEh//d/uldDRNWRFp2GruldkRKZgr0n9uJw7mEtQ7ukPDfEEYIWCS2MibZnI2WzLRNbomFsQ2RkZXAIhY8wYEeW8vPPasvSACLydMDuxx/5BtafTJyotpdfDtSpo3s1RP7hvPOApk2BrCxgyhTdq6HKzJihtueeCyQk6F4NEVWXlJh2S+9mBO4kELbr+C4UFBX47PvL95J+dFIKGx9e9Yk1Ethrm9wWqdGpRrBRpsuSdzFgR5axa5e6ORxAjx66V0NEViH9MJs0AfLygO+/170aqgq5UO0ONsh0WCKqGimtdJfFMqvY/AG7wYN1r4SIaiooMAgNYhugZ72eaFSnkVFq6ouhDhJkkww5+Z5yq66woDBj6q30vGPQzvsYsCPLkNIA0bYtEBWlezVEZKU3sCyLrVxQUBBuvPFG4yb7ZrBuHbBnjyqH7dtX92qI/Iv7fCdBIblQQeY6X+bnA7Nmqf0hQzy7PiLyvciQSHRM7YjOqZ1R5CrCrmPezbbLzMpEckQyWiW2giPQUaPHiAqJMtYs2XkM2nmXOV5ZE3nA8uVq26mT7pUQkRXfwD7/PPDtt8DBg0Bi5YO0bCc0NBTvv/8+zETKl0WfPqqRPhFVXbduQL16wO7dwOzZwNChuldk3fOl0+msUb9mac+QmsrXvERWIWWxMvhBSmU3HdpklMhGh0SjTphne3rsy9pnZMi1SW6D8ODavUCKDo1Gp9ROWJ653AjayfAK+TnIs/hflCyDATsi8hbpEyTnFunr9K9/6V4NVTVgN2iQ7pUQ+WdW8YgRap9ZxeYzfXppOSynwxJZS0xojBEEk2y7/KJ8HMw56NFgnfSgc2fGeYI7aJcQnoA9J/ZwEIUXMGBHlsGAHRF5i0zimzBB7b/yiprQR4pMNsvOzjZuOqacVVQuNneu2mfAjqhm3AE76QVZxPdfpjpfsn8dkbVJmapk20nQLiAgwChhrc3rK/najBMZRrBOgmvJkckeXa8E7TqndTam3u4+sRv5hfkefXy7Y8COLOHoUWDbNrXfsaPu1RCRFV10EdCvnwoIPfGE7tWYR05ODqKiooyb7JthWnhuLpCWBrRrp3s1RP5Jysnj4oADB9Rzisxxvty+XfXolAFrAwd6ZYlEZBJp0WnoktbF6BcnJbI1CYQ5i5yqvPZkUC0pMslrffgkGNgkrgn25+z3yfAMu2DAjixh5Uq1bdAAiPdMhi8RUTlSeuTOspMWRGvX6l4RVeSHH0qz61guRlQzwcHAsGFqf/Jk3asht2nT1Pa884A6nm1tRUQmJJNYu9ftjsZxjXEg54BRIluVslMZAnEo55AxDVay9eQx5LG8SXridUjpYGQGFroKsfv4buQVcnJRbTFgR5bAclgi8oWePVWpWHExcOONKtuOzIX964g8Oy1Whu2QObh7Cg4frnslROQrEcERRiBMsu1kYIT0itufvR85zpzTprNKgEyCepJVF+IIMb6mY0pH4zF8OTyjZ92eaBDbAIdzDxslvZLpRzXDKbFkCQzYEZGvvPgiMH8+sHQp8OCDwEsv6V4Rue3bV/r3YMAA3ash8m/yHJLSy61bgR07gIYNda/I3g4dKu3P6Q6mEpE9SCCsfmx9pEalYl/2Puw6tgvHC44bATEXXFD/dxkBvdiwWLRKbGWU1ErQTgdZg5TIyuTYbUe3GQMvHAEOoyQ3KJAhqOrgfy2yhBUr1JYBOyLyNim9/+gjYOhQ4OWXgd69gZEjda+KxKxZatu5M5Ds2Z7KRLYTFQV07w78+iswbx5www26V2RvU6eqASAdOgBNm+peDRHpIIMj6sXUQ93oukY2XVZBFpzFKnstAAFGvzu5ybAK3WQNKVEpRpDuQPYBI3C398ReY/0SgKSq4X8p8ntOJ7B6tdpnwI6IfGHIEOCRR9T+7berIQekH8thiTyrb1+1dWd2kT6TJqnt5ZfrXgkRmSEYJj3jJBgmWWxyk4w6GS5hhmBdWRKck8CdlObKVoJ2tZl6azcM2JHfW78eKCgAYmKARo10r4aI7OIf/1DZdkeOlA46IH3ktR8DdkSeJZOxhWTYkT5ZWaXnN5bDEpE/kgBju+R2iAmNMcp6qWoYsCNL9a8z2QUFIrKwoKDSUtgvvoBtORwOXHnllcZN9nWRTOvMTCA8HOjVS9syiCxFnkvuPna7dulejX3Pl99/D+TlAU2aAO3be3WJREReI8G69intjd56MoyCzo4BO/J7f/yhtiyHJSJfu+oqtZ0yBcjJgS2FhYXhyy+/NG6yr4s7+0QygkJDtS2DyFKio4GuXdU+s+z0nS/LlsPy4jQR+bPEiERjIEWoI5RBuypgwI78vgRKmvCKnj11r4aI7EYassvkxOxsYMYM3auxN5bDEnkH+9jpdeJE6WtdlsMSkRVI773OaZ2NqbZ7TuxBsatY95JMiwE78vvsuk2bVAnUsGG6V0NEdiOZDu4sOzuXxeomQz/mz1f7DNgReRb72On19tsqaNeyJS9OE5F1JEQkoGt6V8SHxWPX8V0oKCrQvSRTYsCO/Npnn6ntJZcAUVG6V0NEduQO2EkGhGTa2U12drYxkUxusq/DwoWqv1PdukDr1lqWQGRZ558PBAYCmzezj52vz5dOJ/Df/6r9++9Xx4GIyCrqhNUxgnaN6zRGRlYGcpw27S9zBjztk98qLgY+/1ztX3ON7tUQkV1JfydpBC497KZP170ae3JP6ZXsOvZ3IvKsmBjg3HPV/ltv6V6NvUjmtgRJk5OBUaN0r4aIyDvTYzukdECbpDY4nHsYx/OP616SqTBgR37r11+BnTtVQ+TBg3WvhojsSgJE7mmxX32lezX27GX69ddqf8gQ3ashsqb77lPbV15R5Znkm3Pbc8+p/T/9SQZW6F4REZF3OAIdaJnQEu2T2yO7IBuHcg7pXpJpaA3YzZ8/H8OGDUN6erqRGj558uRyn3/88cfRqlUrREZGIi4uDgMGDMBvv/122uNMmzYNPXr0QHh4uHG/ESNGlHzu0KFDuPjii43vERoaivr16+Puu+/G8eNnjtwePnwY119/PWJiYlCnTh2MGTMGWVlZHvzpyVPlsHK4pYcdEZEu7j87338PFLAFh08tXgxs3w5ERjJgR+TNc5z0UDt6lFl2vjJzJrB8ORARAdxxh+7VEBF5l8SDmsQ3MYZRIAAcRmGGgJ30bujYsSNeffXVCj/fokULvPLKK1i1ahUWLlyIRo0aYdCgQThw4EDJfb7++muMGjUKo0ePxooVK/Dzzz/juuuuK/l8YGAgLr30UkyZMgUbN27E+++/j1mzZmHs2LFnXJsE69asWYOZM2di6tSpRnDxtttu8+BPT7VRVFTa4J3lsESk2znnACkpgFwLYmN233K3Rhg+XL2xJSLPk95pDz2k9l94AcjP170ia5Pedffeq/ZvuQVISNC9IiIi36gbUxfd07sjITzBGEaRV5gHOwvS+c0HDx5s3CpTNvAmXnjhBbz77rtYuXIlLrzwQhQWFuKee+7Bs88+a2TAubVp06ZkXzLu7ihzWaphw4a48847ja+pzLp16/D9999jyZIl6Natm/Gxl19+GUOGDMFzzz1nZOuRXt9+C+zbB8THAwMG6F4NEdmdvJmVSdXvvKPOTwMH6l6RfXqZui/eXH217tUQWdv//R/w978De/YA773HrC9vkkETa9cCiYnA+PG6V0NE5Ftx4XHGMIqNhzZix9EdyC+071UirQG76igoKMBbb72F2NhYIytP/P7779izZ4+RRde5c2dkZmaiU6dORjCuXbt2FT7O3r17MWnSJPTt27fS77Vo0SKjDNYdrBNSjivfR0pyL7vssgq/Lj8/37i5uctunU6ncbMC98+h8+eRN2hPPCG/ugG4/fYiBAQUG1ciyTrHmLyLx9g7hg4NwDvvBGHKFBdeeKFQ6/ADXx7jst/D13/vfv45AHv2BCEmxoULLyy01d8CPo+tz2zHWM5pf/lLIB580IE77wRmzSrGo48WoX17Dnup6flSSsBO/bgMmXj8cfU691//KkR0tMtW5zarMdvzmDyPx9g7HHCgVVwrxIfEY+uRrXAVubT9N/b0Ma7O45g+YCflqNdccw1ycnKQlpZmlKgmyuUmAFu3bi3pdSfZd1Iy+/zzz6Nfv35G+Wu8pF+ddO211+Lbb79Fbm6u0TfvHUmDqIQE/pJlHFMZQUFBxuPJ5yozYcIEPPHEE6d9/Mcff0SExep05Djo8uuvqVi5UnoWOtGmzUxMn86To9WOMfkGj7FnFRQEIjR0MHbtCsKrr/6MJk2O2eIYywW1rjIq9+T3CwkJga+89VZ7AE3QtesuzJ79B+yIz2PrM9MxbtQoEBdc0BE//VQfkyYFGjd5PdagwQl0756JoUO3ITy8UPcyTauy82XZY/yvf3VHTk46Wrc+hPj4hZw+bhFmeh6Td/AYe9cRHMFKrLTEMZbYVlUFuFwyg0g/ucL0zTfflBsY4e5zl5GRgYMHD+Ltt9/GnDlzjCw3Cah98sknRq+5N998s6S/nGS41atXD08++SRuv/32kseRQNvRo0eNQN4jjzxiZNi99tprFa7l6aefxgcffIANGzaU+7h8TwnIlS2xPVuGnQy5kLXL8AorkGiw/KIOHDgQwcHBPv/+8tvao0cQli8PwF//WoR//pONKK12jMn7eIy958orHZgyJRDjxhVh3Dh95yc7HGPpZdq4cRAyMwMwZUohLr7YFC9nfMYOx9juzHyMV68G/vEPB6ZNC4DTWZpel5jowiOPFOPuu4uZdVeDYzx7dgAGDw6Cw+HC4sWFRvYi+TczP4/JM3iMrc/Tx1jiRJKEduzYsbPGiUyfYScTYps1a2bcevbsiebNmxt97CToJhl3p/ask0mwTZo0wc6dO8s9TmpqqnGTqbOSKde7d2+MGzeu5DFOve/+/fvLfUz65cnkWPlcZeR7y+1UclCt9uTV9TNNmaImZkVFwSjJCA52+HwNdmHF31sqj8fY8+Sak5ynpk51GG9mdbPyMZaLnJL0Lsn0F18cBIv+mLY+xmTeY9y5M/DNN2o4wqZN0k4G+Pe/ZT8A99/vQHi4gz3uqkGOb0BAMB54QP37rrsC0KWLuY45We95TJ7FY2x9wR46xtV5DK1TYmuiuLi4JItNUsolQFY2E06in9u3bzeGS5zpMUTZbLiyzj33XCMbb9myZSUfk8w++boePXp48Keh6mbXuSuO776bE7OIyHwuuUQNoPjjD+C333SvxtpefFFtb7pJXvjoXg2RPclzT66by+w3GZLw2GPq4/J6LStL9+r8y1tvAWvWqNe3jz+uezVERGQGWgN2WVlZWL58uXET27ZtM/YlO05KYR999FH8+uuv2LFjhxE8u/nmm40hEyNHjjTuL+mDY8eOxfjx440+cRK4c5eruu8zffp0TJw4EatXrzYCedOmTTO+plevXkbPO7F48WIj804eW7Ru3RoXX3wxbr31VuNzP//8M+6++26jlx4nxOozdaoMGpGsS+D++3WvhojodElJwA03qP2//lVdaLA6+Xst2fByk31fWLdO+sOq4KhcwCEi/YKC1BTZpk2BffuA//xH94r853x5+DAwbpza/8c/gLg4fWskIiLz0BqwW7p0qTHdVW7ivvvuM/b//ve/w+FwYP369bjiiivQokULY1DEoUOHsGDBArRt27bkMWQirATSRo0ahe7duxvBPcmGizv5ly48PNzofXf++ecbgbh7770Xw4cPN4ZZlG36J8G+stM6Pv74YyOId+GFF2LIkCHG18uUWtKfXXfXXWrMPRGRGcmbLemOMG8eMGMGbEH+jlangW5tvfSS2l56qfSx89m3JaIqZNw9+aTaf/ZZ4MAB3Ssy//lS+nHefLPDCNq1awecbMtNRESkt4edTHM908yLSZMmVan+97nnnjNuFenfvz9++eWXaq9D+tzJUAsyB5mQJRXKMmzX3d+DiMiM6tcH/vxn9Wb14YeBiy4CHPrb2VmGvKn94AO1f889uldDRKe66ip1/pOqiKefZqbd2Xz0URtMnx6IsDDgvfdUpiIREZFf9rAje2fX3XmnKjkjIjIzCdTVqQOsWqXesJ5snUoe8M47QG4u0LEj0KeP7tUQ0amkVP1f/1L7r74KbNyoe0XmfX371luBmDy5ufFvCdZ17657VUREZCYM2JHpvfEGsGQJs+uIyH/I5FJ3PyLp6dS7t2rITrXnzq7705+AgADdqyGiigwcCAwZoqbI3nuv7tWYkwTn7r5bpV8/8kgRrr1W94qIiMhsGLAjU9u8uTRIJ1kqKSm6V0REVDXyJvWVV4CoKEA6M3TtCixYoHtV/m39ehX4lD5ZV1yhezVEdCZSCivPVWlrIjdSwzjKns+ioly44oqNGD+eadhERHQ6BuzItKQJ7403SnNe6UWosimIiPyFZH/JkBwJMF14IZCXp4YkyIRTqpmvv1Zb+e8pJcdEZF4tWgB/+Yval21BAWxt+fLyZfxSNrxtWyFGjVpnlBETERGdin8eyLRkjohkpURHAxMnqp4oRET+OITiu++Anj2BI0eAwYPLZ1n4u8DAQPTt29e4yb4vAnbMriPyD489pqojNm2Ssk/YlvTx69sX2LMnEOHhfXHOOX3x5z8HIjZW98qIiMjMGAIhU1q5srT/00svAQ0b6l4REVHNhYcDU6YAzZoBO3YAjz8OywgPD8fcuXONm+x7y9atwB9/qIs3kqlIROYXE6NaA4gXXlCv6ewmO1tdZDh+XC7chGPPnrn47Tfvni+JiMgaGLAj08nPB0aNUo2K5U2ZlMUSEfk7mXD91ltq/3//U2/eqOomTVJbyVLhtHAi/3HllaoPsbs01p0pa5dJsLffDqxerTIN5TwWF6d7VURE5C8YsCPTeeIJlWGXmKje3HIKIBFZRb9+QKtWQFaWCtpR1bEclsh/PfwwcMcdKoB1/fVVH8CTkQG8+CIwdSqwe7f6en8ha33qKeDjjwGHA/jiCyAtTfeqiIjInzBgR6Yi5U7//rfal2BdcrLuFREReY5cgJA3reL11/3rzWdlsrOzkZSUZNxk3xv27AF+/VXtX3aZV74FEXn53Pfyy6pyQiopqjKAZ9cu4PzzVVbesGGqH6gMbfDSacajCgvVud7d3uWZZ9xr9/75koiIrIMBO6qyY8eAm292YOfOaK88fnGxmqgo26uv5psyIrKmG24AIiJUidTChbCEgwcPGjdvmTZNbWVwR3q6174NEXmRZJl98knpAJ6LL1bB+MqCdZKRLL0r69YF2rVTXy/nTLMOr8jNBb7/HvjHP1Sg8c03VaDyv/8F7rvPd+dLIiKyDgbsqMoefFBKuALxzDPdvXJ186OPgEWLgKgo4PnnPf/4RERmUKcOcN11av+113Svxj9Mn662l1yieyVEVBtysUKmZjdvDuzcCZx33umZdnPmAOeeq4J1TZqo14arVpWeByRTT+5jFvJzSBBRMgBlCvj48cBvv6lhQ998A9xzj+4VEhGRv2LAjqrsySel94YLu3dH489/dnj0sY8eBR56SO3//e/qaioRkVW5y2K/+spcbzzNSMrnZs1S+0OG6F4NEdWW9Cj+8cfSoF2vXsC77wKff66CWxdeqDLvpN/n3LkqECYGDQLGjlX7N9989sE9RUUqOCiPLTf5np5sQyBlrxMmqOnf//oXcOgQUK+e6tEnffcki5oTrYmIqDaCavXVZCvST+6jj4owaJADH30UiAsuAG66yXODJvbvVy/OeCWSiKyuSxdV+i9vUOUNnbwp7dpVfU4ymGfOVEGqbdvUG1q5iCF9PRs0gO1Ic3r5b5KaCnTqpHs1ROQJjRoBv/wCDB+uMuhuuaX85yUw99xzQGRk+Y8/+yzwww/q3Chf++23QGzs6Y8vJbeSySwlqmVJGa6cS91BwJpav169BpZMOvf0anevPSndJSIi8gQG7Kha+vRx4Zpr1uOTT1rjzjtVKUOLFrV7THkz6i4LkyuSISEeWSoRkam9/766UPHTT+pNpGSZyEREmZKdl1f+vpKpIf2c5L4NG8JW3GVwUmrGqeFE1sq0mz1blZP+/rsKdEnJrGQgV1b+Lm1TPv1UZdvNmwf076+CcmWHlMn58vLLgU2bVFmqXGCWzDr5XnLftm1VcO2qq9R+dc4rcvFAJr9KMNHpBGJiVInuqFE8PxERkecxYEfVdsUVG5GR0RI//RSIW29VbyADa1FcLc15CwrUiy55AUZEZAdhYcDkyerN5LJlKlOkbPaJZGp06KDeiErD8i1bVBaHnHMbN4btAnYshyWyHgmoyVCG6ujRQ2UlX3QR8McfQMeOwJVXqo9L1rIMqZEAnWQkyzm2c+fSrDgppZWMvn/+U93kAkjTpirjzn1LSlKD1iRLLzhYZfllZalsOmlhIBdW3OekN96ofbYeERFRZRiwo2qTK6BvvlmEzp0DMX++Ki1w9xSpro0bVZaJkCuWRER2ItkZUvoqGSOSnSFln9LXqU2b8tkaUkIrgT3JGJFm7F9/rTLyzCAwMBDdunUr2fckCVJu2KD+7gwc6NGHJiI/JkE4mRgr2clSHvvKK+rmJuWyb79dPvNO2q5Iib0E9T77TJXW7tihbtUhQT6pCJHvUd2sOm+eL4mIyHoYsKMakeyPp59W/eZkWIRcZaxJbyWZpCVNgaX0Qd6EEhHZcWqsewhFZaSRuWSUyLl2xQqVkfzww6rpubQVGDAAuPFGPSVZ4eHhWLJkiVcee8YMtT3//Ir7VBGRfUlLljVrVM/PKVMAOQ1J64C77qq8XYsE/6W3ndxkaIVk6O3aVf4mwyPkfCPnZjnHShlsUBAgcTbJ4uvTR2UGeuJ86ZS6WiIiokowYEc1Ji+I5CqlNA2WYNubb1bec6QiMq1Lvl5IWQIREVUuPR34+WcVmJMMu7LnzY8/BqZOBd55R73JtGL/OiKiU0ngTDLd5FaTDGdpM0BERGRWzMWmGpOrlB9+qMq39u5V/ZbkjWRVLhbKFdGRI1WPEemDx8l/RERnJ72UvvhC9XwaOlRl5kl/O+mzJEE8KROTjDsrkJ5R0iReVOdiEBERERGRFTBgR7UijXqlPOuBB9TgCQng/etfZ/4amYoob76kFKF3bzVdi4iIqkbOtdKOQDLqZML288+rzDsZRLF9O3D11VW7cOIpOTk5aNSokXGTfU+R/lIykEj+zkhPPyIif+et8yUREVkTA3bkkXKEZ58FPvigdOrr8uWn30+y6aTHiPT/kDeVzZoB33wDhIb6fMlERJbSvbvKRpNy2F9/BcaN892fd5fLhR07dhg32fcU99TcmjR2JyIyI2+dL4mIyJoYsCOPuf564LLLVIPem25SmRFu0sBXSmYvvVQF62RAhWSHJCToXDERkXVIht3EiWr/hRccWLw4Bf5K/o5Mm6b25e8GEREREZHdMGBHHiMZEK+/roJwUiZ7++1Abi5w+LCaYChvvqTPkkw2XLsWaNlS94qJiKxlxAhVLitefLELtmyBX5ISX/nbER8P9OqlezVERERERL7HgB15VEqKmhYr3n8f6NoVGDhQlcgmJwNLlwITJqjG6URE5HnPPCOtB4qRnR2CK68MMoY3+Bt3Oaz0Ow3iPHsiIiIisiEG7MjjrrhCNQtPTQXWrQN+/x1ITFT9lTp00L06IiJrCwkBPv+8CHFxeVizJgBjxqgeov7C3e/U3b+OiIiIiMiOGLAjrxg0CFi1CrjmGqBtWxWsa9dO96qIiOwhPR146KElCA524YsvgKeegt+QlglSyisDiS66SPdqiIiIiIj0YKEJeY1k1X36qe5VEBHZU+vWh/Hii0W4884gjBunhlLIcCBPCwgIQJs2bUr2a+vjj9VW2ilERdX64YiITMPT50siIrI2BuyIiIgs6pZbXNi2DXj2WeDmm1UvUQmEeVJERATWrFnjkccqKgI+/FDt33ijRx6SiMg0Tj1fOp1OreshIiJzY0ksERGRhf3rX8CVVwIFBapdwXXXwQjimdHMmcCePWo67LBhuldDRERERKQPA3ZEREQWFhiostZuuklKsFSrgubNgfPOA/72NzW92ywmTlRbKd2VHnZERERERHbFgB0REZHFhYerYNiyZcCAAar0dNEi4Omnge7dVfDuyy9rNk02JycHbdu2NW6yX1NHjgCTJ6v90aNr/DBERKblqfMlERHZA3vYERER2UTnzqrsdPt24KefgB9+ACZNUsE7uT30EPDvf1fvMV0uF9bKaNeT+zUlmX9Sttuxo1onEZHVeOp8SURE9sAMOyIiIptp1EhlsX32GbBzJ/DII+rjzzwDfP2179eTmwu88oral9JdIiIiIiK7Y8COiIjIxlJTVWnsAw+UBszWr/fd95ckkzFjgHXrgMREYNQo331vIiIiIiKzYsCOiIiIMGEC0K8fkJUFXH45cOKEb76vZPVJOWxQEPDVV0BCgm++LxERERGRmTFgR0REREbATEpk09NVttvNN9dsCEVVyWO/8EJpOe5LLwF9+3rv+xERERER+RMG7IiIiMiQkqKy3IKD1VYCat5w+DBw6aXA/ferwN1ddwF33OGd70VERERE5I8YsCMiIqIS554L/Oc/av+vfwVeew1wOiu/f0BAABo2bGjcZP9MiouBDz8E2rYFvvsOCA1Vj//yyx7+IYiITKg650siIiIG7IiIiKicO+9Uwx+KilT2W7t2wOTJFd83IiIC27dvN26yXxF5nClTgF69gBtvBDIzgZYtgV9/VZl1fN9KRHZQlfMlERGRGwN2REREVI4E0N59V/WVk8mtGzcCl10GXHedKmc9Gylzzc4G5swB/v53oGlTVQIrAbqoKODf/wZWrAA6dfLFT0NERERE5H8YsCMiIqLTSB+7P/0J2LIFePhhwOFQ01zbtwe++KL8QIoDB4DXXwd69wZiYtTXSmDuwguBf/4T2LEDiI8HHnwQ2LABeOghVQ5LREREREQVC6rk40RERERGAG7CBGDECFUmu2kTcPXVwHPPAUOHAj/8kItFi/qcvPd8AOElXysTZ/v1Ay66CBg5Eggv/RQRke3k5uaiTx91vpw/fz6CZDw3ERFRJfhXgoiIiM6qRw9g+XLg2WfVbckSdQOKASw17vP008VG6WudOkBkpAr2sT8dEZFSXFyMpUuXluwTERGdCUtiiYiIqEqkR/r48apM9v77Vdbcf/9b+vk//xlo00Zl1sXGMlhHRERERFRTzLAjIiKiaklJUSWxQoZL/OUvuldERERERGQtzLAjIiIiIiIiIiIyEQbsiIiIiIiIiIiITIQBOyIiIiIiIiIiIhNhDzsiIiKqlcTERN1LICLyCzxfEhFRVTFgR0RERDUWGRmJAwcO6F4GEZHfnS+dTqfW9RARkbmxJJaIiIiIiIiIiMhEGLAjIiIiIiIiIiIyEQbsiIiIqMZyc3PRr18/4yb7RERUMZ4viYioOtjDjoiIiGqsuLgY8+bNK9knIqKK8XxJRETVwQw7IiIiIiIiIiIiE2HAjoiIiIiIiIiIyEQYsCMiIiIiIiIiIjIRBuyIiIiIiIiIiIhMhAE7IiIiIiIiIiIiE+GUWCIiIqqViIgI3UsgIvILPF8SEVFVMWBHRERENRYZGYns7GzdyyAi8rvzpdPp1LoeIiIyN5bEEhERERERERERmQgDdkRERERERERERCbCgB0RERHVWF5eHoYOHWrcZJ+IiCrG8yUREVUHe9gRERFRjRUVFWH69Okl+0REVLXzpcPh0L0kIiIyMWbYERERERERERERmQgDdkRERERERERERCbCgB0REREREREREZGJMGBHRERERERERERkIgzYERERERERERERmQinxHqRy+UytsePH4dVOJ1O5OTkGD9TcHCw7uWQF/AYWx+PsfX58hhnZ2eX7Mv346RY3+Dz2Pp4jK3n1PNlSEgIj7HF8XlsfTzG1uf08DF2x4fc8aIzCXBV5V5UI7t370b9+vV1L4OIiIiIiIiIiExi165dqFev3hnvw4CdFxUXF2Pv3r2Ijo5GQEAArECiwRKElF+umJgY3cshL+Axtj4eY+vjMbY+HmPr4zG2Ph5j6+Mxtj4eY+s77uFjLCG4EydOID09HYGBZ+5Sx5JYL5L/+GeLmPor+UXlCcnaeIytj8fY+niMrY/H2Pp4jK2Px9j6eIytj8fY+mI8eIxjY2OrdD8OnSAiIiIiIiIiIjIRBuyIiIiIiIiIiIhMhAE7qpbQ0FCMHz/e2JI18RhbH4+x9fEYWx+PsfXxGFsfj7H18RhbH4+x9YVqPMYcOkFERERERERERGQizLAjIiIiIiIiIiIyEQbsiIiIiIiIiIiITIQBOyIiIiIiIiIiIhNhwI6IiIiIiIiIiMhEGLCzmfnz52PYsGFIT09HQEAAJk+eXO7z+/btw0033WR8PiIiAhdffDE2bdpU7j5btmzBZZddhqSkJMTExOCqq64yvu5U06ZNQ48ePRAeHo64uDiMGDHC6z8fARMmTED37t0RHR2N5ORk47/7hg0byt0nLy8Pd911FxISEhAVFYUrrrjitGO4c+dODB061Pg9kMd58MEHUVhYWO4+c+fORZcuXYyJOc2aNcP777/vk5/R7nx5jN1+/vlnBAUFoVOnTl792cj3x/jjjz9Gx44djfukpaXh5ptvxqFDh3zyc9qZp47xn//8Z3Tt2tU4D1f0/JTz9KWXXmoc28jISOM+cszJOsdYyAy55557Di1atDDuV7duXTz11FNe/fnIc8d5xYoVuPbaa1G/fn3jdXPr1q3x4osvnva9+LrL+sfYja+7rHuM+brLf4/xoUOHjPiIxErkPCzH+u6778bx48dL7jNp0iQMHDiwJFZy7rnn4ocffqjxuhmws5ns7GzjBPHqq69W+GJPfnG3bt2Kb7/9Fn/88QcaNmyIAQMGGF/n/vpBgwYZwb45c+YYf0wKCgqMIGBxcXHJY3399dcYNWoURo8ebZy85H7XXXedT39Wu5o3b55xovn1118xc+ZMOJ1O45i5j6G499578d133+HLL7807r93715cfvnlJZ8vKioy3uTLsf3ll1/wwQcfGC8K//73v5fcZ9u2bcZ9+vfvj+XLl+Mvf/kLbrnlllqdkMhcx9jt6NGjuOGGG3DhhRf67Ge0O18dYzk3y7EdM2YM1qxZYzzW4sWLceutt/r8Z7YbTxxjN3mxf/XVV1f4feTYd+jQwfi7vHLlSuPvshzzqVOnevXnI98dY3HPPffgnXfeMYJ269evx5QpU3DOOed47Wcjzx7nZcuWGW8g//e//xnn4r/97W945JFH8Morr5Tch6+7rH+M3fi6y7rHmK+7/PsYBwYGGhdB5W/sxo0bjdfVs2bNwtixY8slSEnAbvr06cbvhJyzJVYisZUacZFtyeH/5ptvSv69YcMG42OrV68u+VhRUZErKSnJ9fbbbxv//uGHH1yBgYGuY8eOldzn6NGjroCAANfMmTONfzudTlfdunVd77zzjk9/HqrY/v37jeM6b968kuMVHBzs+vLLL0vus27dOuM+ixYtMv49ffp04zhnZmaW3Of11193xcTEuPLz841/P/TQQ662bduW+15XX32166KLLvLRT0bePsZlj+tjjz3mGj9+vKtjx44++7nI+8f42WefdTVp0qTc93rppZeMcziZ/xiXVZ3n55AhQ1yjR4/24OpJ5zFeu3atKygoyLV+/Xov/wTki+Psduedd7r69+9f8m++7rL+MXbj6y7rHmO+7rLeMX7xxRdd9erVO+P3atOmjeuJJ56o0TqZYUcl8vPzjW1YWFi5KLKkey5cuLDkPpJdJx9zk/vL/dz3+f3337Fnzx7jY507dzZSfQcPHozVq1f7/Gci4NixY8Y2Pj7e2EqkX64oSOakW6tWrdCgQQMsWrTI+Lds27dvj5SUlJL7XHTRRUa6r1wNct+n7GO47+N+DPL/YywmTpxoZN2OHz/ehz8R+eoYS5r+rl27jKuAch1H0v6/+uorDBkyxMc/IdXkGNfme7m/D/n/MZZsgCZNmhhZk40bN0ajRo2MzKvDhw974acgXx3nU5+nfN1l/WMs+LrL2seYr7usdYwlA09KYPv27Vvp95EqxBMnTtT4dRcDdnTaL6Sk7h45csQoo/r3v/+N3bt3IyMjw7hPz549jR44f/3rX5GTk2OkkD7wwANG6ZX7PvJHRjz++ON47LHHjBeQ0sOuX79+fPHoY3KCkJKJXr16oV27dsbHMjMzERISgjp16pS7r7ypl8+571P2Tb778+7Pnek+EgzIzc316s9FvjnG0r/y4YcfNlL7pY8KWe8Yy2NKLxUptZPHS01NRWxsbIVtE8h8x7gmvvjiCyxZssQojSVrHGN53bVjxw6jhOfDDz80SnTkjceVV17p8Z+DfHOcpZT9888/x2233VbyMb7usv4x5usu6x9jvu6yxjG+9tprjR6E0i9W+tRJS4rKSKuKrKwso+9/TTBgRyWCg4ONCLHUY0sEWH4Jf/rpJyM7TrLlhDRPlBeEcjVXGjHKCUb6LEgDXPd93L3spG5fGjVKo2S5WiSZefK15DtSpy+ZjZ999pnupZCfHWMJwkvfySeeeMJoYk7WfB6vXbvW6H0lfe3kDf7333+P7du3l+vFQdY5V8vfdAnUvf3222jbtq1Xvxf57hjL6y6pgJBgXe/evY0LpO+++65xvE9tqE3mP87y9dIjSTKspL8S2eMY83WXPZ7HfN1ljWP8n//8x6gqlL7/MpDzvvvuq/B+n3zyifGcloul0t+wJhi6p3IkuCaNbCVFVDLsJEAnk167detWch856cgv5sGDB42rPxKFlqsDUo4hpARWtGnTpuRrpIRWPi8TC8k3ZGKNZDdK48t69eqVfFyOlRxbCbSWvYIgKdnyOfd9pAFqWe4JOWXvc+okO/m3XGWQyUjk38dYUreXLl1qNEiV7+N+Uyjp+/K8//HHH3HBBRf46Ce1L28/j2VillxdlOmxQoYTSBa1vOl/8sknS87nZM5jXB3SPFmaHsuLTGl4TdY5xvI8lfNy2Tf5Mp1QyOuuli1beuxnIe8eZ3kzL4MGJCNHqlTK4usuax9jvu6yx/OYr7uscYxTU1ONm1QoSqKTHL9x48aVO34SDJT2FJKwdGo7g+pghh1VSDLnJFgnqdnyx0OuEJwqMTHR+GWWabH79+/H8OHDS4J+EqAre1VX6sHl6oFMnSXvkj/sciL65ptvjGMj/WzKkuMj2ZSzZ88u+ZgcK3lRL30VhGxXrVplHFc3maYjLwrdgVi5T9nHcN/H/Rjk38dYtvJ5CeC7b3L1T974yb4E8sn/n8fS2sCdHe3mcDhK1kDmPsZVNXfuXGO6pLS5KFuaQ9Y4xvLmr7Cw0LiY6ibVEoKvu/znOEtvUZkmeOONN+Kpp5467fvwdZe1jzFfd9njeczXXdb7m1x8srrQPQ9AfPrpp0ZFg2zl9VdtF042cuLECdcff/xh3OTwv/DCC8b+jh07jM9/8cUXrp9++sm1ZcsW1+TJk10NGzZ0XX755eUe47333jMmpWzevNn10UcfueLj41333Xdfufvcc889xrQbmSorU8vGjBnjSk5Odh0+fNinP68d3XHHHa7Y2FjX3LlzXRkZGSW3nJyckvuMHTvW1aBBA9ecOXNcS5cudZ177rnGza2wsNDVrl0716BBg1zLly93ff/998a04EceeaTkPlu3bnVFRES4HnzwQWOCzquvvupyOBzGfckax/hUnFZmvWM8ceJEY7rka6+9Zpz3Fy5c6OrWrZvrnHPO8fnPbDeeOMZi06ZNxt/x22+/3dWiRYuSv/HuScDytXKuluNe9vscOnTI5z+z3fjqGBcVFbm6dOni6tOnj+v33383HqdHjx6ugQMH+vxntiNPHOdVq1YZ5+f/+7//K/cYMsXQja+7rH+MT8XXXdY7xnzd5d/HeNq0aUYsRI71tm3bXFOnTnW1bt3a1atXr5L7fPzxx8YxlnN02e8jU2hrggE7m5FgnATqTr3deOON5cYSy0hj+WWVkeLuF4Ruf/3rX10pKSnGfZo3b+56/vnnXcXFxeXuU1BQ4Lr//vuNIF10dLRrwIABrtWrV/v0Z7Wrio6v3OQPhFtubq4xZjwuLs548XfZZZcZJ5Kytm/f7ho8eLArPDzclZiYaBxPp9N52u9Tp06dXCEhIcaI8rLfg6xxjMviC0drHuOXXnrJGDcv90lLS3Ndf/31rt27d/vsZ7UrTx3jvn37Vvg48kJSyN/3ij4vX0fWOMZiz549xgXWqKgo4zXaTTfdxKCsHx1n+fta0WPIhfOy+LrL+se4LL7usuYx5usu/z3Gc+bMMQJ4EvgLCwszYiESGzly5MhZ/2a74y3VFXBy8URERERERERERGQC7GFHRERERERERERkIgzYERERERERERERmQgDdkRERERERERERCbCgB0REREREREREZGJMGBHRERERERERERkIgzYERERERERERERmQgDdkRERERERERERCbCgB0REREREREREZGJMGBHRERERERERERkIgzYEREREVGV3HTTTQgICDBuwcHBSElJwcCBA/Hee++huLi4yo/z/vvvo06dOl5dKxEREZE/Y8COiIiIiKrs4osvRkZGBrZv344ZM2agf//+uOeee3DJJZegsLBQ9/KIiIiILIEBOyIiIiKqstDQUKSmpqJu3bro0qULHn30UXz77bdG8E4y58QLL7yA9u3bIzIyEvXr18edd96JrKws43Nz587F6NGjcezYsZJsvccff9z4XH5+Ph544AHjseVre/ToYdyfiIiIyG4YsCMiIiKiWrngggvQsWNHTJo0yfh3YGAgXnrpJaxZswYffPAB5syZg4ceesj43HnnnYf//ve/iImJMTL15CZBOnH33Xdj0aJF+Oyzz7By5UqMHDnSyOjbtGmT1p+PiIiIyNcCXC6Xy+fflYiIiIj8sofd0aNHMXny5NM+d8011xhBtrVr1572ua+++gpjx47FwYMHjX9LJt5f/vIX47Hcdu7ciSZNmhjb9PT0ko8PGDAA55xzDp5++mmv/VxEREREZhOkewFERERE5P/kGrCUt4pZs2ZhwoQJWL9+PY4fP270tsvLy0NOTg4iIiIq/PpVq1ahqKgILVq0KPdxKZNNSEjwyc9AREREZBYM2BERERFRra1btw6NGzc2hlHIAIo77rgDTz31FOLj47Fw4UKMGTMGBQUFlQbspMedw+HAsmXLjG1ZUVFRPvopiIiIiMyBATsiIiIiqhXpUScZcvfee68RcCsuLsbzzz9v9LITX3zxRbn7h4SEGNl0ZXXu3Nn42P79+9G7d2+frp+IiIjIbBiwIyIiIqIqkxLVzMxMI7i2b98+fP/990b5q2TV3XDDDVi9ejWcTidefvllDBs2DD///DPeeOONco/RqFEjI6Nu9uzZxrAKybqTUtjrr7/eeAwJ9kkA78CBA8Z9OnTogKFDh2r7mYmIiIh8jVNiiYiIiKjKJECXlpZmBN1kgutPP/1kTIT99ttvjVJWCcC98MIL+Pe//4127drh448/NgJ6ZcmkWBlCcfXVVyMpKQnPPPOM8fGJEycaAbv7778fLVu2xIgRI7BkyRI0aNBA009LREREpAenxBIREREREREREZkIM+yIiIiIiIiIiIhMhAE7IiIiIiIiIiIiE2HAjoiIiIiIiIiIyEQYsCMiIiIiIiIiIjIRBuyIiIiIiIiIiIhMhAE7IiIiIiIiIiIiE2HAjoiIiIiIiIiIyEQYsCMiIiIiIiIiIjIRBuyIiIiIiIiIiIhMhAE7IiIiIiIiIiIiE2HAjoiIiIiIiIiICObx/4y3fRuU+BulAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1500x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forecasting process completed successfully\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "if len(physical_devices) > 0:\n",
    "    tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "\n",
    "def load_data(file_path):\n",
    "    df = pd.read_csv(file_path)\n",
    "    df['date'] = pd.to_datetime(df[['year', 'month']].assign(day=1))\n",
    "    df = df.set_index('date')\n",
    "    return df\n",
    "\n",
    "def create_forecast_sequences(data, seq_length, forecast_horizon):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - seq_length - forecast_horizon + 1):\n",
    "        X.append(data[i:i+seq_length])\n",
    "        y.append(data[i+seq_length:i+seq_length+forecast_horizon])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "def calculate_metrics(y_true, y_pred, y_lower, y_upper):\n",
    "    y_true = y_true.flatten()\n",
    "    y_pred = y_pred.flatten()\n",
    "    y_lower = y_lower.flatten()\n",
    "    y_upper = y_upper.flatten()\n",
    "    \n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    within_interval = np.logical_and(y_true >= y_lower, y_true <= y_upper)\n",
    "    picp = np.mean(within_interval)\n",
    "    mpiw = np.mean(y_upper - y_lower)\n",
    "    \n",
    "    return rmse, picp, mpiw\n",
    "\n",
    "def create_train_model(X_train, y_train, forecast_horizon, n_features, model_dir, bootstrap_id):\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "    \n",
    "    model = Sequential([\n",
    "        LSTM(64, return_sequences=True, input_shape=(X_train.shape[1], n_features)),\n",
    "        Dropout(0.2),\n",
    "        LSTM(32),\n",
    "        Dropout(0.2),\n",
    "        Dense(forecast_horizon * 2)  # Output both SSN and TSI predictions\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "    checkpoint_path = os.path.join(model_dir, f\"model_{bootstrap_id}.keras\")\n",
    "    \n",
    "    checkpoint = ModelCheckpoint(\n",
    "        checkpoint_path,\n",
    "        monitor='val_loss',\n",
    "        save_best_only=True,\n",
    "        mode='min',\n",
    "        save_weights_only=False,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=10,\n",
    "        restore_best_weights=True,\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        epochs=100,\n",
    "        batch_size=32,\n",
    "        validation_split=0.2,\n",
    "        callbacks=[checkpoint, early_stopping],\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    return model, history\n",
    "\n",
    "def generate_bootstrap_forecasts(X_train, y_train, X_val, forecast_horizon, num_bootstraps=10, save_results=True):\n",
    "    model_dir = \"model_checkpoints\"\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "    \n",
    "    results_dir = \"forecast_results\"\n",
    "    os.makedirs(results_dir, exist_ok=True)\n",
    "    \n",
    "    forecasts = []\n",
    "    models = []\n",
    "\n",
    "    for i in range(num_bootstraps):\n",
    "        indices = np.random.choice(len(X_train), len(X_train), replace=True)\n",
    "        X_bootstrap = X_train[indices]\n",
    "        y_bootstrap = y_train[indices]\n",
    "\n",
    "        model, _ = create_train_model(X_bootstrap, y_bootstrap, forecast_horizon, X_train.shape[2], model_dir, i)\n",
    "        models.append(model)\n",
    "\n",
    "        forecast = model.predict(X_val, verbose=1)\n",
    "        forecasts.append(forecast)\n",
    "\n",
    "    forecasts = np.array(forecasts)\n",
    "\n",
    "    mean_forecast = np.mean(forecasts, axis=0)\n",
    "    lower_bound = np.quantile(forecasts, 0.05, axis=0)\n",
    "    upper_bound = np.quantile(forecasts, 0.95, axis=0)\n",
    "\n",
    "    if save_results:\n",
    "        results = {\n",
    "            'mean_forecast': mean_forecast,\n",
    "            'lower_bound': lower_bound,\n",
    "            'upper_bound': upper_bound,\n",
    "            'forecasts': forecasts\n",
    "        }\n",
    "        \n",
    "        results_path = os.path.join(results_dir, 'forecast_results.pkl')\n",
    "        with open(results_path, 'wb') as f:\n",
    "            pickle.dump(results, f)\n",
    "\n",
    "    return mean_forecast, lower_bound, upper_bound, models, forecasts\n",
    "\n",
    "def load_forecast_results(results_dir=\"forecast_results\"):\n",
    "    results_path = os.path.join(results_dir, 'forecast_results.pkl')\n",
    "    \n",
    "    if not os.path.exists(results_path):\n",
    "        raise FileNotFoundError(f\"Results file not found at {results_path}\")\n",
    "    \n",
    "    with open(results_path, 'rb') as f:\n",
    "        results = pickle.load(f)\n",
    "    \n",
    "    return results['mean_forecast'], results['lower_bound'], results['upper_bound'], results['forecasts']\n",
    "\n",
    "def load_trained_models(num_bootstraps, model_dir=\"model_checkpoints\"):\n",
    "    if not os.path.exists(model_dir):\n",
    "        raise FileNotFoundError(f\"Model directory {model_dir} not found\")\n",
    "    \n",
    "    models = []\n",
    "    for i in range(num_bootstraps):\n",
    "        model_path = os.path.join(model_dir, f\"model_{i}.keras\")\n",
    "        if os.path.exists(model_path):\n",
    "            model = load_model(model_path)\n",
    "            models.append(model)\n",
    "    \n",
    "    return models\n",
    "\n",
    "def predict_future(model, last_sequence, future_steps, forecast_horizon, ssn_scaler, tsi_scaler, model_id):\n",
    "    future_predictions_ssn = []\n",
    "    future_predictions_tsi = []\n",
    "    curr_sequence = last_sequence.copy()\n",
    "\n",
    "    steps_completed = 0\n",
    "    while steps_completed < future_steps:\n",
    "        curr_sequence_reshaped = curr_sequence.reshape(1, curr_sequence.shape[0], curr_sequence.shape[1])\n",
    "        next_preds = model.predict(curr_sequence_reshaped, verbose=0)[0]\n",
    "        \n",
    "        # Split the predictions into SSN and TSI\n",
    "        ssn_preds = next_preds[:forecast_horizon]\n",
    "        tsi_preds = next_preds[forecast_horizon:]\n",
    "        \n",
    "        steps_to_add = min(forecast_horizon, future_steps - steps_completed)\n",
    "        future_predictions_ssn.extend(ssn_preds[:steps_to_add])\n",
    "        future_predictions_tsi.extend(tsi_preds[:steps_to_add])\n",
    "        \n",
    "        curr_sequence = np.roll(curr_sequence, -steps_to_add, axis=0)\n",
    "        \n",
    "        for i in range(steps_to_add):\n",
    "            curr_sequence[-steps_to_add+i][0] = ssn_preds[i]  # Update SSN\n",
    "            curr_sequence[-steps_to_add+i][1] = tsi_preds[i]  # Update TSI\n",
    "        \n",
    "        steps_completed += steps_to_add\n",
    "\n",
    "    future_predictions_ssn = np.array(future_predictions_ssn).reshape(-1, 1)\n",
    "    future_predictions_tsi = np.array(future_predictions_tsi).reshape(-1, 1)\n",
    "    \n",
    "    future_predictions_ssn = ssn_scaler.inverse_transform(future_predictions_ssn)\n",
    "    future_predictions_tsi = tsi_scaler.inverse_transform(future_predictions_tsi)\n",
    "\n",
    "    return future_predictions_ssn, future_predictions_tsi\n",
    "\n",
    "def generate_future_dates(last_date, num_months):\n",
    "    future_dates = pd.date_range(start=last_date, periods=num_months+1, freq='MS')[1:]\n",
    "    return future_dates\n",
    "\n",
    "def calculate_evaluation_metrics(actual_values, mean_forecast_inv, lower_bound_inv, upper_bound_inv):\n",
    "    rmse_values = []\n",
    "    picp_values = []\n",
    "    mpiw_values = []\n",
    "\n",
    "    for i in range(len(actual_values)):\n",
    "        rmse, picp, mpiw = calculate_metrics(\n",
    "            actual_values[i],\n",
    "            mean_forecast_inv[i],\n",
    "            lower_bound_inv[i],\n",
    "            upper_bound_inv[i]\n",
    "        )\n",
    "        rmse_values.append(rmse)\n",
    "        picp_values.append(picp)\n",
    "        mpiw_values.append(mpiw)\n",
    "\n",
    "    return np.mean(rmse_values), np.mean(picp_values), np.mean(mpiw_values)\n",
    "\n",
    "def plot_forecast(df, val_dates, mean_forecast_inv, lower_bound_inv, upper_bound_inv, \n",
    "                 future_dates, future_mean, future_lower, future_upper,\n",
    "                 cycle_24_start, cycle_25_start, forecast_horizon, target_var):\n",
    "    start_date = pd.to_datetime('1996-01-01')\n",
    "    plt.figure(figsize=(15, 8))\n",
    "\n",
    "    historical_mask = df.index >= start_date\n",
    "    plt.plot(df.index[historical_mask], df[target_var][historical_mask], 'b-', label=f'Historical {target_var} Data')\n",
    "\n",
    "    for i in range(len(mean_forecast_inv)):\n",
    "        pred_dates = val_dates[i:i+forecast_horizon]\n",
    "        if len(pred_dates) == len(mean_forecast_inv[i]):\n",
    "            plt.plot(pred_dates, mean_forecast_inv[i], 'r-', alpha=0.5, label=f'Validation {target_var} Predictions' if i == 0 else \"\")\n",
    "            plt.fill_between(pred_dates, lower_bound_inv[i], upper_bound_inv[i], color='r', alpha=0.2, label='90% Confidence Interval' if i == 0 else \"\")\n",
    "\n",
    "    plt.plot(future_dates, future_mean, 'g-', label=f'Future {target_var} Predictions')\n",
    "    plt.fill_between(future_dates, future_lower.flatten(), future_upper.flatten(), color='g', alpha=0.2, label='Future 90% Confidence Interval')\n",
    "    plt.axvline(x=cycle_24_start, color='k', linestyle='--', label='Cycle 24 Start')\n",
    "    plt.axvline(x=cycle_25_start, color='k', linestyle='--', label='Cycle 25 Start')\n",
    "    plt.title(f'{target_var} Forecast with Uncertainty')\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel(f'{target_var}')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "    plt.savefig(f'{target_var.lower()}_forecast.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    TRAIN_MODELS = True\n",
    "    \n",
    "    ssn_df = load_data('/Users/suryatejachalla/Projects/Solar-Data-Analysis/Data/processed/sunspot.csv')\n",
    "    tsi_df = load_data('/Users/suryatejachalla/Projects/Solar-Data-Analysis/Data/processed/tsi.csv')\n",
    "    \n",
    "    df = pd.merge(ssn_df, tsi_df, left_index=True, right_index=True, suffixes=('', '_tsi'))\n",
    "    df = df.rename(columns={'tsi_tsi': 'tsi'})\n",
    "    \n",
    "    print(\"Data summary:\")\n",
    "    print(df.describe())\n",
    "    print(f\"Correlation between SSN and TSI: {df['ssn'].corr(df['tsi']):.4f}\")\n",
    "    \n",
    "    ssn = df['ssn'].values.reshape(-1, 1)\n",
    "    tsi = df['tsi'].values.reshape(-1, 1)\n",
    "    \n",
    "    ssn_scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    tsi_scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    \n",
    "    ssn_scaled = ssn_scaler.fit_transform(ssn)\n",
    "    tsi_scaled = tsi_scaler.fit_transform(tsi)\n",
    "    \n",
    "    with open('ssn_scaler.pkl', 'wb') as f:\n",
    "        pickle.dump(ssn_scaler, f)\n",
    "    with open('tsi_scaler.pkl', 'wb') as f:\n",
    "        pickle.dump(tsi_scaler, f)\n",
    "    \n",
    "    cycle_24_start = pd.to_datetime('2008-12-01')\n",
    "    cycle_25_start = pd.to_datetime('2019-12-01')\n",
    "    validation_start = pd.to_datetime('2021-01-01')\n",
    "\n",
    "    combined_scaled = np.hstack((ssn_scaled, tsi_scaled))\n",
    "    \n",
    "    train_data = combined_scaled[df.index < cycle_25_start]\n",
    "    val_data = combined_scaled[(df.index >= validation_start)]\n",
    "    val_dates = df.index[(df.index >= validation_start)]\n",
    "    \n",
    "    forecast_horizon = 1\n",
    "    seq_length = 8 * 12\n",
    "    \n",
    "    X_train, y_train_raw = create_forecast_sequences(train_data, seq_length, forecast_horizon)\n",
    "    X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], 2)\n",
    "    \n",
    "    # Flatten the forecast horizon dimension and feature dimension for both SSN and TSI\n",
    "    y_train = np.zeros((y_train_raw.shape[0], y_train_raw.shape[1] * 2))\n",
    "    for i in range(y_train_raw.shape[0]):\n",
    "        y_train[i, :forecast_horizon] = y_train_raw[i, :, 0]  # SSN values\n",
    "        y_train[i, forecast_horizon:] = y_train_raw[i, :, 1]  # TSI values\n",
    "    \n",
    "    X_val = []\n",
    "    y_val_ssn = []\n",
    "    y_val_tsi = []\n",
    "\n",
    "    for i in range(len(val_dates) - forecast_horizon + 1):\n",
    "        start_idx = df.index.get_loc(val_dates[i]) - seq_length\n",
    "        end_idx = df.index.get_loc(val_dates[i])\n",
    "        forecast_end_idx = df.index.get_loc(val_dates[i]) + forecast_horizon\n",
    "\n",
    "        if start_idx >= 0:\n",
    "            X_val.append(combined_scaled[start_idx:end_idx])\n",
    "            y_val_ssn.append(ssn_scaled[end_idx:forecast_end_idx])\n",
    "            y_val_tsi.append(tsi_scaled[end_idx:forecast_end_idx])\n",
    "\n",
    "    X_val = np.array(X_val)\n",
    "    y_val_ssn = np.array(y_val_ssn)\n",
    "    y_val_tsi = np.array(y_val_tsi)\n",
    "    X_val = X_val.reshape(X_val.shape[0], X_val.shape[1], 2)\n",
    "    \n",
    "    num_bootstraps = 10  # Reduced to 10 as requested\n",
    "    if TRAIN_MODELS:\n",
    "        mean_forecast, lower_bound, upper_bound, models, forecasts = generate_bootstrap_forecasts(\n",
    "            X_train, y_train, X_val, forecast_horizon, num_bootstraps=num_bootstraps\n",
    "        )\n",
    "    else:\n",
    "        mean_forecast, lower_bound, upper_bound, forecasts = load_forecast_results()\n",
    "        models = load_trained_models(num_bootstraps)\n",
    "\n",
    "    # Split forecasts into SSN and TSI components\n",
    "    ssn_mean_forecast = mean_forecast[:, :forecast_horizon]\n",
    "    tsi_mean_forecast = mean_forecast[:, forecast_horizon:]\n",
    "    \n",
    "    ssn_lower_bound = lower_bound[:, :forecast_horizon]\n",
    "    tsi_lower_bound = lower_bound[:, forecast_horizon:]\n",
    "    \n",
    "    ssn_upper_bound = upper_bound[:, :forecast_horizon]\n",
    "    tsi_upper_bound = upper_bound[:, forecast_horizon:]\n",
    "    \n",
    "    # Reshape\n",
    "    ssn_mean_forecast_reshaped = ssn_mean_forecast.reshape(-1, forecast_horizon)\n",
    "    ssn_lower_bound_reshaped = ssn_lower_bound.reshape(-1, forecast_horizon)\n",
    "    ssn_upper_bound_reshaped = ssn_upper_bound.reshape(-1, forecast_horizon)\n",
    "    \n",
    "    tsi_mean_forecast_reshaped = tsi_mean_forecast.reshape(-1, forecast_horizon)\n",
    "    tsi_lower_bound_reshaped = tsi_lower_bound.reshape(-1, forecast_horizon)\n",
    "    tsi_upper_bound_reshaped = tsi_upper_bound.reshape(-1, forecast_horizon)\n",
    "\n",
    "    # Inverse transform to original scale\n",
    "    ssn_mean_forecast_inv = np.array([ssn_scaler.inverse_transform(f.reshape(-1, 1)).flatten() for f in ssn_mean_forecast_reshaped])\n",
    "    ssn_lower_bound_inv = np.array([ssn_scaler.inverse_transform(f.reshape(-1, 1)).flatten() for f in ssn_lower_bound_reshaped])\n",
    "    ssn_upper_bound_inv = np.array([ssn_scaler.inverse_transform(f.reshape(-1, 1)).flatten() for f in ssn_upper_bound_reshaped])\n",
    "    \n",
    "    tsi_mean_forecast_inv = np.array([tsi_scaler.inverse_transform(f.reshape(-1, 1)).flatten() for f in tsi_mean_forecast_reshaped])\n",
    "    tsi_lower_bound_inv = np.array([tsi_scaler.inverse_transform(f.reshape(-1, 1)).flatten() for f in tsi_lower_bound_reshaped])\n",
    "    tsi_upper_bound_inv = np.array([tsi_scaler.inverse_transform(f.reshape(-1, 1)).flatten() for f in tsi_upper_bound_reshaped])\n",
    "\n",
    "    # Get actual values for evaluation\n",
    "    ssn_actual_values = []\n",
    "    tsi_actual_values = []\n",
    "    for i in range(len(y_val_ssn)):\n",
    "        ssn_inv_y = ssn_scaler.inverse_transform(y_val_ssn[i].reshape(-1, 1)).flatten()\n",
    "        tsi_inv_y = tsi_scaler.inverse_transform(y_val_tsi[i].reshape(-1, 1)).flatten()\n",
    "        ssn_actual_values.append(ssn_inv_y)\n",
    "        tsi_actual_values.append(tsi_inv_y)\n",
    "\n",
    "    ssn_actual_values = np.array(ssn_actual_values)\n",
    "    tsi_actual_values = np.array(tsi_actual_values)\n",
    "\n",
    "    # Calculate evaluation metrics\n",
    "    ssn_avg_rmse, ssn_avg_picp, ssn_avg_mpiw = calculate_evaluation_metrics(\n",
    "        ssn_actual_values, ssn_mean_forecast_inv, ssn_lower_bound_inv, ssn_upper_bound_inv\n",
    "    )\n",
    "    \n",
    "    tsi_avg_rmse, tsi_avg_picp, tsi_avg_mpiw = calculate_evaluation_metrics(\n",
    "        tsi_actual_values, tsi_mean_forecast_inv, tsi_lower_bound_inv, tsi_upper_bound_inv\n",
    "    )\n",
    "\n",
    "    # Print metrics\n",
    "    print(\"\\n===== SSN EVALUATION METRICS =====\")\n",
    "    print(f\"Average RMSE: {ssn_avg_rmse:.4f}\")\n",
    "    print(f\"Average PICP: {ssn_avg_picp:.4f}\")\n",
    "    print(f\"Average MPIW: {ssn_avg_mpiw:.4f}\")\n",
    "    print(\"==============================\\n\")\n",
    "    \n",
    "    print(\"\\n===== TSI EVALUATION METRICS =====\")\n",
    "    print(f\"Average RMSE: {tsi_avg_rmse:.4f}\")\n",
    "    print(f\"Average PICP: {tsi_avg_picp:.4f}\")\n",
    "    print(f\"Average MPIW: {tsi_avg_mpiw:.4f}\")\n",
    "    print(\"==============================\\n\")\n",
    "\n",
    "    # Generate future predictions\n",
    "    last_sequence = combined_scaled[-seq_length:].reshape(seq_length, 2)\n",
    "    last_date = df.index[-1]\n",
    "    future_steps = (2030 - last_date.year) * 12 + (12 - last_date.month)\n",
    "    future_dates = generate_future_dates(last_date, future_steps)\n",
    "\n",
    "    future_ssn_forecasts = []\n",
    "    future_tsi_forecasts = []\n",
    "    for i, model in enumerate(models):\n",
    "        future_ssn, future_tsi = predict_future(model, last_sequence, future_steps, forecast_horizon, ssn_scaler, tsi_scaler, i)\n",
    "        future_ssn_forecasts.append(future_ssn)\n",
    "        future_tsi_forecasts.append(future_tsi)\n",
    "\n",
    "    future_ssn_forecasts = np.array(future_ssn_forecasts)\n",
    "    future_tsi_forecasts = np.array(future_tsi_forecasts)\n",
    "    \n",
    "    future_ssn_mean = np.mean(future_ssn_forecasts, axis=0)\n",
    "    future_ssn_lower = np.quantile(future_ssn_forecasts, 0.05, axis=0)\n",
    "    future_ssn_upper = np.quantile(future_ssn_forecasts, 0.95, axis=0)\n",
    "    \n",
    "    future_tsi_mean = np.mean(future_tsi_forecasts, axis=0)\n",
    "    future_tsi_lower = np.quantile(future_tsi_forecasts, 0.05, axis=0)\n",
    "    future_tsi_upper = np.quantile(future_tsi_forecasts, 0.95, axis=0)\n",
    "\n",
    "    # Save future predictions\n",
    "    future_results = {\n",
    "        'future_ssn_mean': future_ssn_mean,\n",
    "        'future_ssn_lower': future_ssn_lower,\n",
    "        'future_ssn_upper': future_ssn_upper,\n",
    "        'future_tsi_mean': future_tsi_mean,\n",
    "        'future_tsi_lower': future_tsi_lower,\n",
    "        'future_tsi_upper': future_tsi_upper,\n",
    "        'future_dates': future_dates\n",
    "    }\n",
    "    with open('future_predictions.pkl', 'wb') as f:\n",
    "        pickle.dump(future_results, f)\n",
    "\n",
    "    # Plot results\n",
    "    plot_forecast(\n",
    "        df, val_dates, ssn_mean_forecast_inv, ssn_lower_bound_inv, ssn_upper_bound_inv,\n",
    "        future_dates, future_ssn_mean, future_ssn_lower, future_ssn_upper,\n",
    "        cycle_24_start, cycle_25_start, forecast_horizon, 'ssn'\n",
    "    )\n",
    "    \n",
    "    plot_forecast(\n",
    "        df, val_dates, tsi_mean_forecast_inv, tsi_lower_bound_inv, tsi_upper_bound_inv,\n",
    "        future_dates, future_tsi_mean, future_tsi_lower, future_tsi_upper,\n",
    "        cycle_24_start, cycle_25_start, forecast_horizon, 'tsi'\n",
    "    )\n",
    "    \n",
    "    print(\"Forecasting process completed successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ssn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
